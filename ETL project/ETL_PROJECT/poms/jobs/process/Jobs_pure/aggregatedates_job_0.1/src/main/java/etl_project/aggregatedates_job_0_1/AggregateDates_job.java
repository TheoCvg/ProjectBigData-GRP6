// ============================================================================
//
// Copyright (c) 2006-2015, Talend Inc.
//
// This source code has been automatically generated by_Talend Open Studio for Big Data
// / Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
// http://www.apache.org/licenses/LICENSE-2.0
// 
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

package etl_project.aggregatedates_job_0_1;

import routines.Numeric;
import routines.DataOperation;
import routines.TalendDataGenerator;
import routines.TalendStringUtil;
import routines.TalendString;
import routines.StringHandling;
import routines.Relational;
import routines.TalendDate;
import routines.Mathematical;
import routines.system.*;
import routines.system.api.*;
import java.text.ParseException;
import java.text.SimpleDateFormat;
import java.util.Date;
import java.util.List;
import java.math.BigDecimal;
import java.io.ByteArrayOutputStream;
import java.io.ByteArrayInputStream;
import java.io.DataInputStream;
import java.io.DataOutputStream;
import java.io.ObjectOutputStream;
import java.io.ObjectInputStream;
import java.io.IOException;
import java.util.Comparator;

@SuppressWarnings("unused")

/**
 * Job: AggregateDates_job Purpose: <br>
 * Description: <br>
 * 
 * @author user@talend.com
 * @version 7.3.1.20200219_1130
 * @status
 */
public class AggregateDates_job implements TalendJob {

	protected static void logIgnoredError(String message, Throwable cause) {
		System.err.println(message);
		if (cause != null) {
			cause.printStackTrace();
		}

	}

	public final Object obj = new Object();

	// for transmiting parameters purpose
	private Object valueObject = null;

	public Object getValueObject() {
		return this.valueObject;
	}

	public void setValueObject(Object valueObject) {
		this.valueObject = valueObject;
	}

	private final static String defaultCharset = java.nio.charset.Charset.defaultCharset().name();

	private final static String utf8Charset = "UTF-8";

	// contains type for every context property
	public class PropertiesWithType extends java.util.Properties {
		private static final long serialVersionUID = 1L;
		private java.util.Map<String, String> propertyTypes = new java.util.HashMap<>();

		public PropertiesWithType(java.util.Properties properties) {
			super(properties);
		}

		public PropertiesWithType() {
			super();
		}

		public void setContextType(String key, String type) {
			propertyTypes.put(key, type);
		}

		public String getContextType(String key) {
			return propertyTypes.get(key);
		}
	}

	// create and load default properties
	private java.util.Properties defaultProps = new java.util.Properties();

	// create application properties with default
	public class ContextProperties extends PropertiesWithType {

		private static final long serialVersionUID = 1L;

		public ContextProperties(java.util.Properties properties) {
			super(properties);
		}

		public ContextProperties() {
			super();
		}

		public void synchronizeContext() {

			if (postgres_DB_input_Login != null) {

				this.setProperty("postgres_DB_input_Login", postgres_DB_input_Login.toString());

			}

			if (postgres_DB_input_Database != null) {

				this.setProperty("postgres_DB_input_Database", postgres_DB_input_Database.toString());

			}

			if (postgres_DB_input_Password != null) {

				this.setProperty("postgres_DB_input_Password", postgres_DB_input_Password.toString());

			}

			if (postgres_DB_input_Server != null) {

				this.setProperty("postgres_DB_input_Server", postgres_DB_input_Server.toString());

			}

			if (postgres_DB_input_Schema != null) {

				this.setProperty("postgres_DB_input_Schema", postgres_DB_input_Schema.toString());

			}

			if (postgres_DB_input_Port != null) {

				this.setProperty("postgres_DB_input_Port", postgres_DB_input_Port.toString());

			}

			if (postgres_DB_input_AdditionalParams != null) {

				this.setProperty("postgres_DB_input_AdditionalParams", postgres_DB_input_AdditionalParams.toString());

			}

			if (INPUT_PATH != null) {

				this.setProperty("INPUT_PATH", INPUT_PATH.toString());

			}

			if (ClusterHadopp_User != null) {

				this.setProperty("ClusterHadopp_User", ClusterHadopp_User.toString());

			}

			if (ClusterHadopp_NameNodeUri != null) {

				this.setProperty("ClusterHadopp_NameNodeUri", ClusterHadopp_NameNodeUri.toString());

			}

			if (ClusterHadopp_hadoopConfSpecificJar != null) {

				this.setProperty("ClusterHadopp_hadoopConfSpecificJar", ClusterHadopp_hadoopConfSpecificJar.toString());

			}

			if (ClusterHadopp_ResourceManager != null) {

				this.setProperty("ClusterHadopp_ResourceManager", ClusterHadopp_ResourceManager.toString());

			}

			if (ClusterHadopp_ResourceManagerScheduler != null) {

				this.setProperty("ClusterHadopp_ResourceManagerScheduler",
						ClusterHadopp_ResourceManagerScheduler.toString());

			}

			if (ClusterHadopp_JobHistory != null) {

				this.setProperty("ClusterHadopp_JobHistory", ClusterHadopp_JobHistory.toString());

			}

		}

		public String postgres_DB_input_Login;

		public String getPostgres_DB_input_Login() {
			return this.postgres_DB_input_Login;
		}

		public String postgres_DB_input_Database;

		public String getPostgres_DB_input_Database() {
			return this.postgres_DB_input_Database;
		}

		public java.lang.String postgres_DB_input_Password;

		public java.lang.String getPostgres_DB_input_Password() {
			return this.postgres_DB_input_Password;
		}

		public String postgres_DB_input_Server;

		public String getPostgres_DB_input_Server() {
			return this.postgres_DB_input_Server;
		}

		public String postgres_DB_input_Schema;

		public String getPostgres_DB_input_Schema() {
			return this.postgres_DB_input_Schema;
		}

		public String postgres_DB_input_Port;

		public String getPostgres_DB_input_Port() {
			return this.postgres_DB_input_Port;
		}

		public String postgres_DB_input_AdditionalParams;

		public String getPostgres_DB_input_AdditionalParams() {
			return this.postgres_DB_input_AdditionalParams;
		}

		public String INPUT_PATH;

		public String getINPUT_PATH() {
			return this.INPUT_PATH;
		}

		public String ClusterHadopp_User;

		public String getClusterHadopp_User() {
			return this.ClusterHadopp_User;
		}

		public String ClusterHadopp_NameNodeUri;

		public String getClusterHadopp_NameNodeUri() {
			return this.ClusterHadopp_NameNodeUri;
		}

		public String ClusterHadopp_hadoopConfSpecificJar;

		public String getClusterHadopp_hadoopConfSpecificJar() {
			return this.ClusterHadopp_hadoopConfSpecificJar;
		}

		public String ClusterHadopp_ResourceManager;

		public String getClusterHadopp_ResourceManager() {
			return this.ClusterHadopp_ResourceManager;
		}

		public String ClusterHadopp_ResourceManagerScheduler;

		public String getClusterHadopp_ResourceManagerScheduler() {
			return this.ClusterHadopp_ResourceManagerScheduler;
		}

		public String ClusterHadopp_JobHistory;

		public String getClusterHadopp_JobHistory() {
			return this.ClusterHadopp_JobHistory;
		}
	}

	protected ContextProperties context = new ContextProperties(); // will be instanciated by MS.

	public ContextProperties getContext() {
		return this.context;
	}

	private final String jobVersion = "0.1";
	private final String jobName = "AggregateDates_job";
	private final String projectName = "ETL_PROJECT";
	public Integer errorCode = null;
	private String currentComponent = "";

	private final java.util.Map<String, Object> globalMap = new java.util.HashMap<String, Object>();
	private final static java.util.Map<String, Object> junitGlobalMap = new java.util.HashMap<String, Object>();

	private final java.util.Map<String, Long> start_Hash = new java.util.HashMap<String, Long>();
	private final java.util.Map<String, Long> end_Hash = new java.util.HashMap<String, Long>();
	private final java.util.Map<String, Boolean> ok_Hash = new java.util.HashMap<String, Boolean>();
	public final java.util.List<String[]> globalBuffer = new java.util.ArrayList<String[]>();

	private RunStat runStat = new RunStat();

	// OSGi DataSource
	private final static String KEY_DB_DATASOURCES = "KEY_DB_DATASOURCES";

	private final static String KEY_DB_DATASOURCES_RAW = "KEY_DB_DATASOURCES_RAW";

	public void setDataSources(java.util.Map<String, javax.sql.DataSource> dataSources) {
		java.util.Map<String, routines.system.TalendDataSource> talendDataSources = new java.util.HashMap<String, routines.system.TalendDataSource>();
		for (java.util.Map.Entry<String, javax.sql.DataSource> dataSourceEntry : dataSources.entrySet()) {
			talendDataSources.put(dataSourceEntry.getKey(),
					new routines.system.TalendDataSource(dataSourceEntry.getValue()));
		}
		globalMap.put(KEY_DB_DATASOURCES, talendDataSources);
		globalMap.put(KEY_DB_DATASOURCES_RAW, new java.util.HashMap<String, javax.sql.DataSource>(dataSources));
	}

	private final java.io.ByteArrayOutputStream baos = new java.io.ByteArrayOutputStream();
	private final java.io.PrintStream errorMessagePS = new java.io.PrintStream(new java.io.BufferedOutputStream(baos));

	public String getExceptionStackTrace() {
		if ("failure".equals(this.getStatus())) {
			errorMessagePS.flush();
			return baos.toString();
		}
		return null;
	}

	private Exception exception;

	public Exception getException() {
		if ("failure".equals(this.getStatus())) {
			return this.exception;
		}
		return null;
	}

	private class TalendException extends Exception {

		private static final long serialVersionUID = 1L;

		private java.util.Map<String, Object> globalMap = null;
		private Exception e = null;
		private String currentComponent = null;
		private String virtualComponentName = null;

		public void setVirtualComponentName(String virtualComponentName) {
			this.virtualComponentName = virtualComponentName;
		}

		private TalendException(Exception e, String errorComponent, final java.util.Map<String, Object> globalMap) {
			this.currentComponent = errorComponent;
			this.globalMap = globalMap;
			this.e = e;
		}

		public Exception getException() {
			return this.e;
		}

		public String getCurrentComponent() {
			return this.currentComponent;
		}

		public String getExceptionCauseMessage(Exception e) {
			Throwable cause = e;
			String message = null;
			int i = 10;
			while (null != cause && 0 < i--) {
				message = cause.getMessage();
				if (null == message) {
					cause = cause.getCause();
				} else {
					break;
				}
			}
			if (null == message) {
				message = e.getClass().getName();
			}
			return message;
		}

		@Override
		public void printStackTrace() {
			if (!(e instanceof TalendException || e instanceof TDieException)) {
				if (virtualComponentName != null && currentComponent.indexOf(virtualComponentName + "_") == 0) {
					globalMap.put(virtualComponentName + "_ERROR_MESSAGE", getExceptionCauseMessage(e));
				}
				globalMap.put(currentComponent + "_ERROR_MESSAGE", getExceptionCauseMessage(e));
				System.err.println("Exception in component " + currentComponent + " (" + jobName + ")");
			}
			if (!(e instanceof TDieException)) {
				if (e instanceof TalendException) {
					e.printStackTrace();
				} else {
					e.printStackTrace();
					e.printStackTrace(errorMessagePS);
					AggregateDates_job.this.exception = e;
				}
			}
			if (!(e instanceof TalendException)) {
				try {
					for (java.lang.reflect.Method m : this.getClass().getEnclosingClass().getMethods()) {
						if (m.getName().compareTo(currentComponent + "_error") == 0) {
							m.invoke(AggregateDates_job.this, new Object[] { e, currentComponent, globalMap });
							break;
						}
					}

					if (!(e instanceof TDieException)) {
					}
				} catch (Exception e) {
					this.e.printStackTrace();
				}
			}
		}
	}

	public void Implicit_Context_Regex_error(Exception exception, String errorComponent,
			final java.util.Map<String, Object> globalMap) throws TalendException {

		Implicit_Context_Context_error(exception, errorComponent, globalMap);

	}

	public void Implicit_Context_Context_error(Exception exception, String errorComponent,
			final java.util.Map<String, Object> globalMap) throws TalendException {

		end_Hash.put(errorComponent, System.currentTimeMillis());

		status = "failure";

		Implicit_Context_Regex_onSubJobError(exception, errorComponent, globalMap);
	}

	public void tDBInput_1_error(Exception exception, String errorComponent,
			final java.util.Map<String, Object> globalMap) throws TalendException {

		end_Hash.put(errorComponent, System.currentTimeMillis());

		status = "failure";

		tDBInput_1_onSubJobError(exception, errorComponent, globalMap);
	}

	public void tUnite_1_error(Exception exception, String errorComponent,
			final java.util.Map<String, Object> globalMap) throws TalendException {

		end_Hash.put(errorComponent, System.currentTimeMillis());

		status = "failure";

		tDBInput_1_onSubJobError(exception, errorComponent, globalMap);
	}

	public void tUniqRow_1_error(Exception exception, String errorComponent,
			final java.util.Map<String, Object> globalMap) throws TalendException {

		end_Hash.put(errorComponent, System.currentTimeMillis());

		status = "failure";

		tDBInput_1_onSubJobError(exception, errorComponent, globalMap);
	}

	public void tMap_2_error(Exception exception, String errorComponent, final java.util.Map<String, Object> globalMap)
			throws TalendException {

		end_Hash.put(errorComponent, System.currentTimeMillis());

		status = "failure";

		tDBInput_1_onSubJobError(exception, errorComponent, globalMap);
	}

	public void tLogRow_1_error(Exception exception, String errorComponent,
			final java.util.Map<String, Object> globalMap) throws TalendException {

		end_Hash.put(errorComponent, System.currentTimeMillis());

		status = "failure";

		tDBInput_1_onSubJobError(exception, errorComponent, globalMap);
	}

	public void tFileInputDelimited_1_error(Exception exception, String errorComponent,
			final java.util.Map<String, Object> globalMap) throws TalendException {

		end_Hash.put(errorComponent, System.currentTimeMillis());

		status = "failure";

		tDBInput_1_onSubJobError(exception, errorComponent, globalMap);
	}

	public void tMap_1_error(Exception exception, String errorComponent, final java.util.Map<String, Object> globalMap)
			throws TalendException {

		end_Hash.put(errorComponent, System.currentTimeMillis());

		status = "failure";

		tDBInput_1_onSubJobError(exception, errorComponent, globalMap);
	}

	public void tFileInputDelimited_2_error(Exception exception, String errorComponent,
			final java.util.Map<String, Object> globalMap) throws TalendException {

		end_Hash.put(errorComponent, System.currentTimeMillis());

		status = "failure";

		tDBInput_1_onSubJobError(exception, errorComponent, globalMap);
	}

	public void tMap_3_error(Exception exception, String errorComponent, final java.util.Map<String, Object> globalMap)
			throws TalendException {

		end_Hash.put(errorComponent, System.currentTimeMillis());

		status = "failure";

		tDBInput_1_onSubJobError(exception, errorComponent, globalMap);
	}

	public void tHDFSOutput_1_error(Exception exception, String errorComponent,
			final java.util.Map<String, Object> globalMap) throws TalendException {

		end_Hash.put(errorComponent, System.currentTimeMillis());

		status = "failure";

		tHDFSOutput_1_onSubJobError(exception, errorComponent, globalMap);
	}

	public void tHiveCreateTable_1_error(Exception exception, String errorComponent,
			final java.util.Map<String, Object> globalMap) throws TalendException {

		end_Hash.put(errorComponent, System.currentTimeMillis());

		status = "failure";

		tHiveCreateTable_1_onSubJobError(exception, errorComponent, globalMap);
	}

	public void tHadoopConfManager_tHDFSOutput_1_error(Exception exception, String errorComponent,
			final java.util.Map<String, Object> globalMap) throws TalendException {

		end_Hash.put(errorComponent, System.currentTimeMillis());

		status = "failure";

		tHadoopConfManager_tHDFSOutput_1_onSubJobError(exception, errorComponent, globalMap);
	}

	public void tHadoopConfManager_tHiveCreateTable_1_error(Exception exception, String errorComponent,
			final java.util.Map<String, Object> globalMap) throws TalendException {

		end_Hash.put(errorComponent, System.currentTimeMillis());

		status = "failure";

		tHadoopConfManager_tHiveCreateTable_1_onSubJobError(exception, errorComponent, globalMap);
	}

	public void Implicit_Context_Regex_onSubJobError(Exception exception, String errorComponent,
			final java.util.Map<String, Object> globalMap) throws TalendException {

		resumeUtil.addLog("SYSTEM_LOG", "NODE:" + errorComponent, "", Thread.currentThread().getId() + "", "FATAL", "",
				exception.getMessage(), ResumeUtil.getExceptionStackTrace(exception), "");

	}

	public void tDBInput_1_onSubJobError(Exception exception, String errorComponent,
			final java.util.Map<String, Object> globalMap) throws TalendException {

		resumeUtil.addLog("SYSTEM_LOG", "NODE:" + errorComponent, "", Thread.currentThread().getId() + "", "FATAL", "",
				exception.getMessage(), ResumeUtil.getExceptionStackTrace(exception), "");

	}

	public void tHDFSOutput_1_onSubJobError(Exception exception, String errorComponent,
			final java.util.Map<String, Object> globalMap) throws TalendException {

		resumeUtil.addLog("SYSTEM_LOG", "NODE:" + errorComponent, "", Thread.currentThread().getId() + "", "FATAL", "",
				exception.getMessage(), ResumeUtil.getExceptionStackTrace(exception), "");

	}

	public void tHiveCreateTable_1_onSubJobError(Exception exception, String errorComponent,
			final java.util.Map<String, Object> globalMap) throws TalendException {

		resumeUtil.addLog("SYSTEM_LOG", "NODE:" + errorComponent, "", Thread.currentThread().getId() + "", "FATAL", "",
				exception.getMessage(), ResumeUtil.getExceptionStackTrace(exception), "");

	}

	public void tHadoopConfManager_tHDFSOutput_1_onSubJobError(Exception exception, String errorComponent,
			final java.util.Map<String, Object> globalMap) throws TalendException {

		resumeUtil.addLog("SYSTEM_LOG", "NODE:" + errorComponent, "", Thread.currentThread().getId() + "", "FATAL", "",
				exception.getMessage(), ResumeUtil.getExceptionStackTrace(exception), "");

	}

	public void tHadoopConfManager_tHiveCreateTable_1_onSubJobError(Exception exception, String errorComponent,
			final java.util.Map<String, Object> globalMap) throws TalendException {

		resumeUtil.addLog("SYSTEM_LOG", "NODE:" + errorComponent, "", Thread.currentThread().getId() + "", "FATAL", "",
				exception.getMessage(), ResumeUtil.getExceptionStackTrace(exception), "");

	}

	public static class row_Implicit_Context_RegexStruct
			implements routines.system.IPersistableRow<row_Implicit_Context_RegexStruct> {
		final static byte[] commonByteArrayLock_ETL_PROJECT_AggregateDates_job = new byte[0];
		static byte[] commonByteArray_ETL_PROJECT_AggregateDates_job = new byte[0];

		public String key;

		public String getKey() {
			return this.key;
		}

		public String value;

		public String getValue() {
			return this.value;
		}

		private String readString(ObjectInputStream dis) throws IOException {
			String strReturn = null;
			int length = 0;
			length = dis.readInt();
			if (length == -1) {
				strReturn = null;
			} else {
				if (length > commonByteArray_ETL_PROJECT_AggregateDates_job.length) {
					if (length < 1024 && commonByteArray_ETL_PROJECT_AggregateDates_job.length == 0) {
						commonByteArray_ETL_PROJECT_AggregateDates_job = new byte[1024];
					} else {
						commonByteArray_ETL_PROJECT_AggregateDates_job = new byte[2 * length];
					}
				}
				dis.readFully(commonByteArray_ETL_PROJECT_AggregateDates_job, 0, length);
				strReturn = new String(commonByteArray_ETL_PROJECT_AggregateDates_job, 0, length, utf8Charset);
			}
			return strReturn;
		}

		private void writeString(String str, ObjectOutputStream dos) throws IOException {
			if (str == null) {
				dos.writeInt(-1);
			} else {
				byte[] byteArray = str.getBytes(utf8Charset);
				dos.writeInt(byteArray.length);
				dos.write(byteArray);
			}
		}

		public void readData(ObjectInputStream dis) {

			synchronized (commonByteArrayLock_ETL_PROJECT_AggregateDates_job) {

				try {

					int length = 0;

					this.key = readString(dis);

					this.value = readString(dis);

				} catch (IOException e) {
					throw new RuntimeException(e);

				}

			}

		}

		public void writeData(ObjectOutputStream dos) {
			try {

				// String

				writeString(this.key, dos);

				// String

				writeString(this.value, dos);

			} catch (IOException e) {
				throw new RuntimeException(e);
			}

		}

		public String toString() {

			StringBuilder sb = new StringBuilder();
			sb.append(super.toString());
			sb.append("[");
			sb.append("key=" + key);
			sb.append(",value=" + value);
			sb.append("]");

			return sb.toString();
		}

		/**
		 * Compare keys
		 */
		public int compareTo(row_Implicit_Context_RegexStruct other) {

			int returnValue = -1;

			return returnValue;
		}

		private int checkNullsAndCompare(Object object1, Object object2) {
			int returnValue = 0;
			if (object1 instanceof Comparable && object2 instanceof Comparable) {
				returnValue = ((Comparable) object1).compareTo(object2);
			} else if (object1 != null && object2 != null) {
				returnValue = compareStrings(object1.toString(), object2.toString());
			} else if (object1 == null && object2 != null) {
				returnValue = 1;
			} else if (object1 != null && object2 == null) {
				returnValue = -1;
			} else {
				returnValue = 0;
			}

			return returnValue;
		}

		private int compareStrings(String string1, String string2) {
			return string1.compareTo(string2);
		}

	}

	public void Implicit_Context_RegexProcess(final java.util.Map<String, Object> globalMap) throws TalendException {
		globalMap.put("Implicit_Context_Regex_SUBPROCESS_STATE", 0);

		final boolean execStat = this.execStat;
		String currentVirtualComponent = null;

		String iterateId = "";

		String currentComponent = "";
		java.util.Map<String, Object> resourceMap = new java.util.HashMap<String, Object>();

		try {
			// TDI-39566 avoid throwing an useless Exception
			boolean resumeIt = true;
			if (globalResumeTicket == false && resumeEntryMethodName != null) {
				String currentMethodName = new java.lang.Exception().getStackTrace()[0].getMethodName();
				resumeIt = resumeEntryMethodName.equals(currentMethodName);
			}
			if (resumeIt || globalResumeTicket) { // start the resume
				globalResumeTicket = true;

				row_Implicit_Context_RegexStruct row_Implicit_Context_Regex = new row_Implicit_Context_RegexStruct();

				/**
				 * [Implicit_Context_Context begin ] start
				 */

				ok_Hash.put("Implicit_Context_Context", false);
				start_Hash.put("Implicit_Context_Context", System.currentTimeMillis());

				currentVirtualComponent = "Implicit_Context_Context";

				currentComponent = "Implicit_Context_Context";

				if (execStat) {
					runStat.updateStatOnConnection(resourceMap, iterateId, 0, 0, "Main");
				}

				int tos_count_Implicit_Context_Context = 0;

				java.util.List<String> assignList_Implicit_Context_Context = new java.util.ArrayList<String>();
				java.util.List<String> newPropertyList_Implicit_Context_Context = new java.util.ArrayList<String>();
				java.util.List<String> noAssignList_Implicit_Context_Context = new java.util.ArrayList<String>();
				int nb_line_Implicit_Context_Context = 0;

				/**
				 * [Implicit_Context_Context begin ] stop
				 */

				/**
				 * [Implicit_Context_Regex begin ] start
				 */

				ok_Hash.put("Implicit_Context_Regex", false);
				start_Hash.put("Implicit_Context_Regex", System.currentTimeMillis());

				currentVirtualComponent = "Implicit_Context_Regex";

				currentComponent = "Implicit_Context_Regex";

				int tos_count_Implicit_Context_Regex = 0;

				int nb_line_Implicit_Context_Regex = 0;

				int footer_Implicit_Context_Regex = 0;
				boolean removeEmptyRowImplicit_Context_Regex = true;
				Object source_Implicit_Context_Regex = /** Start field Implicit_Context_Regex:FILENAME */
						"D:/Big data/ProjectBigData-GRP6/ETL project/ETL_PROJECT/resources/config/config.properties"/**
																													 * End
																													 * field
																													 * Implicit_Context_Regex:FILENAME
																													 */
				;

				org.talend.fileprocess.TOSDelimitedReader inImplicit_Context_Regex = null;
				if (source_Implicit_Context_Regex instanceof String
						|| source_Implicit_Context_Regex instanceof java.io.InputStream) {
					inImplicit_Context_Regex = new org.talend.fileprocess.TOSDelimitedReader(/**
																								 * Start field
																								 * Implicit_Context_Regex:FILENAME
																								 */
							"D:/Big data/ProjectBigData-GRP6/ETL project/ETL_PROJECT/resources/config/config.properties"/**
																														 * End
																														 * field
																														 * Implicit_Context_Regex:FILENAME
																														 */
							, "UTF-8", "", "\n", removeEmptyRowImplicit_Context_Regex);
				} else {
					throw new java.lang.Exception(
							"The source data should be specified as File Path or InputStream or java.io.Reader!");
				}
				String strImplicit_Context_Regex;
				int totalLineImplicit_Context_Regex = 0, currentLineImplicit_Context_Regex = 0,
						beginLineImplicit_Context_Regex = 0, lastLineImplicit_Context_Regex = -1,
						validRowCountImplicit_Context_Regex = 0;
				int limitImplicit_Context_Regex = -1;

				int headerImplicit_Context_Regex = 0;
				if (headerImplicit_Context_Regex > 0) {
					beginLineImplicit_Context_Regex = headerImplicit_Context_Regex + 1;
				}

				if (footer_Implicit_Context_Regex > 0) {
					while (inImplicit_Context_Regex.readRecord()) {
						strImplicit_Context_Regex = inImplicit_Context_Regex.getRowRecord();
						totalLineImplicit_Context_Regex++;
					}
					int lastLineTempImplicit_Context_Regex = totalLineImplicit_Context_Regex
							- footer_Implicit_Context_Regex < 0 ? 0
									: totalLineImplicit_Context_Regex - footer_Implicit_Context_Regex;
					if (lastLineImplicit_Context_Regex > 0) {
						lastLineImplicit_Context_Regex = lastLineImplicit_Context_Regex < lastLineTempImplicit_Context_Regex
								? lastLineImplicit_Context_Regex
								: lastLineTempImplicit_Context_Regex;
					} else {
						lastLineImplicit_Context_Regex = lastLineTempImplicit_Context_Regex;
					}
					inImplicit_Context_Regex.close();
					inImplicit_Context_Regex = new org.talend.fileprocess.TOSDelimitedReader(/**
																								 * Start field
																								 * Implicit_Context_Regex:FILENAME
																								 */
							"D:/Big data/ProjectBigData-GRP6/ETL project/ETL_PROJECT/resources/config/config.properties"/**
																														 * End
																														 * field
																														 * Implicit_Context_Regex:FILENAME
																														 */
							, "UTF-8", "", "\n", removeEmptyRowImplicit_Context_Regex);
				}
				java.util.StringTokenizer strTokenImplicit_Context_Regex;
				java.util.regex.Pattern patternImplicit_Context_Regex = java.util.regex.Pattern
						.compile("^([^" + "=" + "]*)" + "=" + "(.*)$");
				java.util.regex.Matcher matcherImplicit_Context_Regex = null;

				while (inImplicit_Context_Regex.readRecord()) {
					strImplicit_Context_Regex = inImplicit_Context_Regex.getRowRecord();

					currentLineImplicit_Context_Regex++;
					if (currentLineImplicit_Context_Regex < beginLineImplicit_Context_Regex) {
						continue;
					}
					if (lastLineImplicit_Context_Regex > -1
							&& currentLineImplicit_Context_Regex > lastLineImplicit_Context_Regex) {
						break;
					}
					if (removeEmptyRowImplicit_Context_Regex && ("").equals(strImplicit_Context_Regex)) {
						continue;
					}
					if (limitImplicit_Context_Regex != -1
							&& validRowCountImplicit_Context_Regex >= limitImplicit_Context_Regex) {
						break;
					}

					matcherImplicit_Context_Regex = patternImplicit_Context_Regex.matcher(strImplicit_Context_Regex);
					int groupCountImplicit_Context_Regex = 0;
					boolean isMatchImplicit_Context_Regex = matcherImplicit_Context_Regex.find();
					if (isMatchImplicit_Context_Regex) {
						groupCountImplicit_Context_Regex = matcherImplicit_Context_Regex.groupCount();
					}
					row_Implicit_Context_Regex = null;

					boolean lineIsEmptyImplicit_Context_Regex = strImplicit_Context_Regex.length() == 0;

					String[] valueImplicit_Context_Regex = new String[2];
					String frontCharImplicit_Context_Regex, behindCharImplicit_Context_Regex;
					for (int i = 0; i < 2; i++) {
						valueImplicit_Context_Regex[i] = "";
						if (lineIsEmptyImplicit_Context_Regex) {
							continue;
						}
						if (i < groupCountImplicit_Context_Regex) {
							valueImplicit_Context_Regex[i] = matcherImplicit_Context_Regex.group(i + 1);
						}
					}
					validRowCountImplicit_Context_Regex++;

					boolean whetherReject_Implicit_Context_Regex = false;
					row_Implicit_Context_Regex = new row_Implicit_Context_RegexStruct();
					try {
						if (!isMatchImplicit_Context_Regex) {// line data not matched with given regex parameter
							throw new java.lang.Exception("Line doesn't match: " + strImplicit_Context_Regex);
						}

						if (valueImplicit_Context_Regex[0] != null && valueImplicit_Context_Regex[0].length() > 0) {
							row_Implicit_Context_Regex.key = valueImplicit_Context_Regex[0];
						} else {
							row_Implicit_Context_Regex.key = "";
						}

						if (valueImplicit_Context_Regex[1] != null && valueImplicit_Context_Regex[1].length() > 0) {
							row_Implicit_Context_Regex.value = valueImplicit_Context_Regex[1];
						} else {
							row_Implicit_Context_Regex.value = "";
						}

					} catch (java.lang.Exception e) {
						whetherReject_Implicit_Context_Regex = true;
						if (isMatchImplicit_Context_Regex) {
							System.err.println(e.getMessage());
						}
						row_Implicit_Context_Regex = null;
					}

					nb_line_Implicit_Context_Regex++;

					/**
					 * [Implicit_Context_Regex begin ] stop
					 */

					/**
					 * [Implicit_Context_Regex main ] start
					 */

					currentVirtualComponent = "Implicit_Context_Regex";

					currentComponent = "Implicit_Context_Regex";

					tos_count_Implicit_Context_Regex++;

					/**
					 * [Implicit_Context_Regex main ] stop
					 */

					/**
					 * [Implicit_Context_Regex process_data_begin ] start
					 */

					currentVirtualComponent = "Implicit_Context_Regex";

					currentComponent = "Implicit_Context_Regex";

					/**
					 * [Implicit_Context_Regex process_data_begin ] stop
					 */
// Start of branch "row_Implicit_Context_Regex"
					if (row_Implicit_Context_Regex != null) {

						/**
						 * [Implicit_Context_Context main ] start
						 */

						currentVirtualComponent = "Implicit_Context_Context";

						currentComponent = "Implicit_Context_Context";

						if (execStat) {
							runStat.updateStatOnConnection(iterateId, 1, 1, "Main");
						}

						//////////////////////////
						String tmp_key_Implicit_Context_Context = null;
						String key_Implicit_Context_Context = null;
						if (row_Implicit_Context_Regex.key != null) {
							tmp_key_Implicit_Context_Context = row_Implicit_Context_Regex.key.trim();
							if ((tmp_key_Implicit_Context_Context.startsWith("#")
									|| tmp_key_Implicit_Context_Context.startsWith("!"))) {
								tmp_key_Implicit_Context_Context = null;
							} else {
								row_Implicit_Context_Regex.key = tmp_key_Implicit_Context_Context;
							}
						}
						if (row_Implicit_Context_Regex.key != null) {
							key_Implicit_Context_Context = row_Implicit_Context_Regex.key;
						}
						String value_Implicit_Context_Context = null;
						if (row_Implicit_Context_Regex.value != null) {
							value_Implicit_Context_Context = row_Implicit_Context_Regex.value;
						}

						String currentValue_Implicit_Context_Context = value_Implicit_Context_Context;

						if ((key_Implicit_Context_Context != null)
								&& ("postgres_DB_input_Password".equals(key_Implicit_Context_Context)))
							currentValue_Implicit_Context_Context = currentValue_Implicit_Context_Context
									.replaceAll(".", "*");

						if (tmp_key_Implicit_Context_Context != null) {
							try {
								if (key_Implicit_Context_Context != null
										&& "postgres_DB_input_Login".equals(key_Implicit_Context_Context)) {
									context.postgres_DB_input_Login = value_Implicit_Context_Context;
								}

								if (key_Implicit_Context_Context != null
										&& "postgres_DB_input_Database".equals(key_Implicit_Context_Context)) {
									context.postgres_DB_input_Database = value_Implicit_Context_Context;
								}

								if (key_Implicit_Context_Context != null
										&& "postgres_DB_input_Password".equals(key_Implicit_Context_Context)) {
									context.postgres_DB_input_Password = value_Implicit_Context_Context;
								}

								if (key_Implicit_Context_Context != null
										&& "postgres_DB_input_Server".equals(key_Implicit_Context_Context)) {
									context.postgres_DB_input_Server = value_Implicit_Context_Context;
								}

								if (key_Implicit_Context_Context != null
										&& "postgres_DB_input_Schema".equals(key_Implicit_Context_Context)) {
									context.postgres_DB_input_Schema = value_Implicit_Context_Context;
								}

								if (key_Implicit_Context_Context != null
										&& "postgres_DB_input_Port".equals(key_Implicit_Context_Context)) {
									context.postgres_DB_input_Port = value_Implicit_Context_Context;
								}

								if (key_Implicit_Context_Context != null
										&& "postgres_DB_input_AdditionalParams".equals(key_Implicit_Context_Context)) {
									context.postgres_DB_input_AdditionalParams = value_Implicit_Context_Context;
								}

								if (key_Implicit_Context_Context != null
										&& "INPUT_PATH".equals(key_Implicit_Context_Context)) {
									context.INPUT_PATH = value_Implicit_Context_Context;
								}

								if (key_Implicit_Context_Context != null
										&& "ClusterHadopp_User".equals(key_Implicit_Context_Context)) {
									context.ClusterHadopp_User = value_Implicit_Context_Context;
								}

								if (key_Implicit_Context_Context != null
										&& "ClusterHadopp_NameNodeUri".equals(key_Implicit_Context_Context)) {
									context.ClusterHadopp_NameNodeUri = value_Implicit_Context_Context;
								}

								if (key_Implicit_Context_Context != null
										&& "ClusterHadopp_hadoopConfSpecificJar".equals(key_Implicit_Context_Context)) {
									context.ClusterHadopp_hadoopConfSpecificJar = value_Implicit_Context_Context;
								}

								if (key_Implicit_Context_Context != null
										&& "ClusterHadopp_ResourceManager".equals(key_Implicit_Context_Context)) {
									context.ClusterHadopp_ResourceManager = value_Implicit_Context_Context;
								}

								if (key_Implicit_Context_Context != null && "ClusterHadopp_ResourceManagerScheduler"
										.equals(key_Implicit_Context_Context)) {
									context.ClusterHadopp_ResourceManagerScheduler = value_Implicit_Context_Context;
								}

								if (key_Implicit_Context_Context != null
										&& "ClusterHadopp_JobHistory".equals(key_Implicit_Context_Context)) {
									context.ClusterHadopp_JobHistory = value_Implicit_Context_Context;
								}

								if (context.getProperty(key_Implicit_Context_Context) != null) {
									assignList_Implicit_Context_Context.add(key_Implicit_Context_Context);
								} else {
									newPropertyList_Implicit_Context_Context.add(key_Implicit_Context_Context);
								}
								if (value_Implicit_Context_Context == null) {
									context.setProperty(key_Implicit_Context_Context, "");
								} else {
									context.setProperty(key_Implicit_Context_Context, value_Implicit_Context_Context);
								}
							} catch (java.lang.Exception e) {
								System.err.println("Setting a value for the key \"" + key_Implicit_Context_Context
										+ "\" has failed. Error message: " + e.getMessage());
							}
							nb_line_Implicit_Context_Context++;
						}
						//////////////////////////

						tos_count_Implicit_Context_Context++;

						/**
						 * [Implicit_Context_Context main ] stop
						 */

						/**
						 * [Implicit_Context_Context process_data_begin ] start
						 */

						currentVirtualComponent = "Implicit_Context_Context";

						currentComponent = "Implicit_Context_Context";

						/**
						 * [Implicit_Context_Context process_data_begin ] stop
						 */

						/**
						 * [Implicit_Context_Context process_data_end ] start
						 */

						currentVirtualComponent = "Implicit_Context_Context";

						currentComponent = "Implicit_Context_Context";

						/**
						 * [Implicit_Context_Context process_data_end ] stop
						 */

					} // End of branch "row_Implicit_Context_Regex"

					/**
					 * [Implicit_Context_Regex process_data_end ] start
					 */

					currentVirtualComponent = "Implicit_Context_Regex";

					currentComponent = "Implicit_Context_Regex";

					/**
					 * [Implicit_Context_Regex process_data_end ] stop
					 */

					/**
					 * [Implicit_Context_Regex end ] start
					 */

					currentVirtualComponent = "Implicit_Context_Regex";

					currentComponent = "Implicit_Context_Regex";

				}
				if (!(source_Implicit_Context_Regex instanceof java.io.InputStream)) {
					inImplicit_Context_Regex.close();
				}
				inImplicit_Context_Regex = null;
				globalMap.put("Implicit_Context_Regex_NB_LINE", nb_line_Implicit_Context_Regex);

				ok_Hash.put("Implicit_Context_Regex", true);
				end_Hash.put("Implicit_Context_Regex", System.currentTimeMillis());

				/**
				 * [Implicit_Context_Regex end ] stop
				 */

				/**
				 * [Implicit_Context_Context end ] start
				 */

				currentVirtualComponent = "Implicit_Context_Context";

				currentComponent = "Implicit_Context_Context";

				java.util.Enumeration<?> enu_Implicit_Context_Context = context.propertyNames();
				while (enu_Implicit_Context_Context.hasMoreElements()) {
					String key_Implicit_Context_Context = (String) enu_Implicit_Context_Context.nextElement();
					if (!assignList_Implicit_Context_Context.contains(key_Implicit_Context_Context)
							&& !newPropertyList_Implicit_Context_Context.contains(key_Implicit_Context_Context)) {
						noAssignList_Implicit_Context_Context.add(key_Implicit_Context_Context);
					}
				}
				for (Object obj_Implicit_Context_Context : newPropertyList_Implicit_Context_Context) {

					System.out.println("Warning: Parameter \"" + obj_Implicit_Context_Context
							+ "\" is a new parameter of Implicit_Context_Context");
				}
				for (Object obj_Implicit_Context_Context : noAssignList_Implicit_Context_Context) {

					System.out.println("Warning: Parameter \"" + obj_Implicit_Context_Context
							+ "\" has not been set by Implicit_Context_Context");

				}

				String newPropertyStr_Implicit_Context_Context = newPropertyList_Implicit_Context_Context.toString();
				String newProperty_Implicit_Context_Context = newPropertyStr_Implicit_Context_Context.substring(1,
						newPropertyStr_Implicit_Context_Context.length() - 1);

				String noAssignStr_Implicit_Context_Context = noAssignList_Implicit_Context_Context.toString();
				String noAssign_Implicit_Context_Context = noAssignStr_Implicit_Context_Context.substring(1,
						noAssignStr_Implicit_Context_Context.length() - 1);

				globalMap.put("Implicit_Context_Context_KEY_NOT_INCONTEXT", newProperty_Implicit_Context_Context);
				globalMap.put("Implicit_Context_Context_KEY_NOT_LOADED", noAssign_Implicit_Context_Context);

				globalMap.put("Implicit_Context_Context_NB_LINE", nb_line_Implicit_Context_Context);

				List<String> parametersToEncrypt_Implicit_Context_Context = new java.util.ArrayList<String>();

				parametersToEncrypt_Implicit_Context_Context.add("postgres_DB_input_Password");

				resumeUtil.addLog("NODE", "NODE:Implicit_Context_Context", "", Thread.currentThread().getId() + "", "",
						"", "", "",
						resumeUtil.convertToJsonText(context, parametersToEncrypt_Implicit_Context_Context));

				if (execStat) {
					runStat.updateStat(resourceMap, iterateId, 2, 0, "Main");
				}

				ok_Hash.put("Implicit_Context_Context", true);
				end_Hash.put("Implicit_Context_Context", System.currentTimeMillis());

				/**
				 * [Implicit_Context_Context end ] stop
				 */

			} // end the resume

		} catch (java.lang.Exception e) {

			TalendException te = new TalendException(e, currentComponent, globalMap);

			te.setVirtualComponentName(currentVirtualComponent);

			throw te;
		} catch (java.lang.Error error) {

			runStat.stopThreadStat();

			throw error;
		} finally {

			try {

				/**
				 * [Implicit_Context_Regex finally ] start
				 */

				currentVirtualComponent = "Implicit_Context_Regex";

				currentComponent = "Implicit_Context_Regex";

				/**
				 * [Implicit_Context_Regex finally ] stop
				 */

				/**
				 * [Implicit_Context_Context finally ] start
				 */

				currentVirtualComponent = "Implicit_Context_Context";

				currentComponent = "Implicit_Context_Context";

				/**
				 * [Implicit_Context_Context finally ] stop
				 */

			} catch (java.lang.Exception e) {
				// ignore
			} catch (java.lang.Error error) {
				// ignore
			}
			resourceMap = null;
		}

		globalMap.put("Implicit_Context_Regex_SUBPROCESS_STATE", 1);
	}

	public static class d_dates_outputStruct implements routines.system.IPersistableRow<d_dates_outputStruct> {
		final static byte[] commonByteArrayLock_ETL_PROJECT_AggregateDates_job = new byte[0];
		static byte[] commonByteArray_ETL_PROJECT_AggregateDates_job = new byte[0];
		protected static final int DEFAULT_HASHCODE = 1;
		protected static final int PRIME = 31;
		protected int hashCode = DEFAULT_HASHCODE;
		public boolean hashCodeDirty = true;

		public String loopKey;

		public int Id_date;

		public int getId_date() {
			return this.Id_date;
		}

		public java.util.Date Date;

		public java.util.Date getDate() {
			return this.Date;
		}

		public int Year;

		public int getYear() {
			return this.Year;
		}

		@Override
		public int hashCode() {
			if (this.hashCodeDirty) {
				final int prime = PRIME;
				int result = DEFAULT_HASHCODE;

				result = prime * result + (int) this.Id_date;

				this.hashCode = result;
				this.hashCodeDirty = false;
			}
			return this.hashCode;
		}

		@Override
		public boolean equals(Object obj) {
			if (this == obj)
				return true;
			if (obj == null)
				return false;
			if (getClass() != obj.getClass())
				return false;
			final d_dates_outputStruct other = (d_dates_outputStruct) obj;

			if (this.Id_date != other.Id_date)
				return false;

			return true;
		}

		public void copyDataTo(d_dates_outputStruct other) {

			other.Id_date = this.Id_date;
			other.Date = this.Date;
			other.Year = this.Year;

		}

		public void copyKeysDataTo(d_dates_outputStruct other) {

			other.Id_date = this.Id_date;

		}

		private java.util.Date readDate(ObjectInputStream dis) throws IOException {
			java.util.Date dateReturn = null;
			int length = 0;
			length = dis.readByte();
			if (length == -1) {
				dateReturn = null;
			} else {
				dateReturn = new Date(dis.readLong());
			}
			return dateReturn;
		}

		private void writeDate(java.util.Date date1, ObjectOutputStream dos) throws IOException {
			if (date1 == null) {
				dos.writeByte(-1);
			} else {
				dos.writeByte(0);
				dos.writeLong(date1.getTime());
			}
		}

		public void readData(ObjectInputStream dis) {

			synchronized (commonByteArrayLock_ETL_PROJECT_AggregateDates_job) {

				try {

					int length = 0;

					this.Id_date = dis.readInt();

					this.Date = readDate(dis);

					this.Year = dis.readInt();

				} catch (IOException e) {
					throw new RuntimeException(e);

				}

			}

		}

		public void writeData(ObjectOutputStream dos) {
			try {

				// int

				dos.writeInt(this.Id_date);

				// java.util.Date

				writeDate(this.Date, dos);

				// int

				dos.writeInt(this.Year);

			} catch (IOException e) {
				throw new RuntimeException(e);
			}

		}

		public String toString() {

			StringBuilder sb = new StringBuilder();
			sb.append(super.toString());
			sb.append("[");
			sb.append("Id_date=" + String.valueOf(Id_date));
			sb.append(",Date=" + String.valueOf(Date));
			sb.append(",Year=" + String.valueOf(Year));
			sb.append("]");

			return sb.toString();
		}

		/**
		 * Compare keys
		 */
		public int compareTo(d_dates_outputStruct other) {

			int returnValue = -1;

			returnValue = checkNullsAndCompare(this.Id_date, other.Id_date);
			if (returnValue != 0) {
				return returnValue;
			}

			return returnValue;
		}

		private int checkNullsAndCompare(Object object1, Object object2) {
			int returnValue = 0;
			if (object1 instanceof Comparable && object2 instanceof Comparable) {
				returnValue = ((Comparable) object1).compareTo(object2);
			} else if (object1 != null && object2 != null) {
				returnValue = compareStrings(object1.toString(), object2.toString());
			} else if (object1 == null && object2 != null) {
				returnValue = 1;
			} else if (object1 != null && object2 == null) {
				returnValue = -1;
			} else {
				returnValue = 0;
			}

			return returnValue;
		}

		private int compareStrings(String string1, String string2) {
			return string1.compareTo(string2);
		}

	}

	public static class row5Struct implements routines.system.IPersistableRow<row5Struct> {
		final static byte[] commonByteArrayLock_ETL_PROJECT_AggregateDates_job = new byte[0];
		static byte[] commonByteArray_ETL_PROJECT_AggregateDates_job = new byte[0];

		public java.util.Date Date;

		public java.util.Date getDate() {
			return this.Date;
		}

		private java.util.Date readDate(ObjectInputStream dis) throws IOException {
			java.util.Date dateReturn = null;
			int length = 0;
			length = dis.readByte();
			if (length == -1) {
				dateReturn = null;
			} else {
				dateReturn = new Date(dis.readLong());
			}
			return dateReturn;
		}

		private void writeDate(java.util.Date date1, ObjectOutputStream dos) throws IOException {
			if (date1 == null) {
				dos.writeByte(-1);
			} else {
				dos.writeByte(0);
				dos.writeLong(date1.getTime());
			}
		}

		public void readData(ObjectInputStream dis) {

			synchronized (commonByteArrayLock_ETL_PROJECT_AggregateDates_job) {

				try {

					int length = 0;

					this.Date = readDate(dis);

				} catch (IOException e) {
					throw new RuntimeException(e);

				}

			}

		}

		public void writeData(ObjectOutputStream dos) {
			try {

				// java.util.Date

				writeDate(this.Date, dos);

			} catch (IOException e) {
				throw new RuntimeException(e);
			}

		}

		public String toString() {

			StringBuilder sb = new StringBuilder();
			sb.append(super.toString());
			sb.append("[");
			sb.append("Date=" + String.valueOf(Date));
			sb.append("]");

			return sb.toString();
		}

		/**
		 * Compare keys
		 */
		public int compareTo(row5Struct other) {

			int returnValue = -1;

			return returnValue;
		}

		private int checkNullsAndCompare(Object object1, Object object2) {
			int returnValue = 0;
			if (object1 instanceof Comparable && object2 instanceof Comparable) {
				returnValue = ((Comparable) object1).compareTo(object2);
			} else if (object1 != null && object2 != null) {
				returnValue = compareStrings(object1.toString(), object2.toString());
			} else if (object1 == null && object2 != null) {
				returnValue = 1;
			} else if (object1 != null && object2 == null) {
				returnValue = -1;
			} else {
				returnValue = 0;
			}

			return returnValue;
		}

		private int compareStrings(String string1, String string2) {
			return string1.compareTo(string2);
		}

	}

	public static class row4Struct implements routines.system.IPersistableRow<row4Struct> {
		final static byte[] commonByteArrayLock_ETL_PROJECT_AggregateDates_job = new byte[0];
		static byte[] commonByteArray_ETL_PROJECT_AggregateDates_job = new byte[0];

		public java.util.Date Date;

		public java.util.Date getDate() {
			return this.Date;
		}

		private java.util.Date readDate(ObjectInputStream dis) throws IOException {
			java.util.Date dateReturn = null;
			int length = 0;
			length = dis.readByte();
			if (length == -1) {
				dateReturn = null;
			} else {
				dateReturn = new Date(dis.readLong());
			}
			return dateReturn;
		}

		private void writeDate(java.util.Date date1, ObjectOutputStream dos) throws IOException {
			if (date1 == null) {
				dos.writeByte(-1);
			} else {
				dos.writeByte(0);
				dos.writeLong(date1.getTime());
			}
		}

		public void readData(ObjectInputStream dis) {

			synchronized (commonByteArrayLock_ETL_PROJECT_AggregateDates_job) {

				try {

					int length = 0;

					this.Date = readDate(dis);

				} catch (IOException e) {
					throw new RuntimeException(e);

				}

			}

		}

		public void writeData(ObjectOutputStream dos) {
			try {

				// java.util.Date

				writeDate(this.Date, dos);

			} catch (IOException e) {
				throw new RuntimeException(e);
			}

		}

		public String toString() {

			StringBuilder sb = new StringBuilder();
			sb.append(super.toString());
			sb.append("[");
			sb.append("Date=" + String.valueOf(Date));
			sb.append("]");

			return sb.toString();
		}

		/**
		 * Compare keys
		 */
		public int compareTo(row4Struct other) {

			int returnValue = -1;

			return returnValue;
		}

		private int checkNullsAndCompare(Object object1, Object object2) {
			int returnValue = 0;
			if (object1 instanceof Comparable && object2 instanceof Comparable) {
				returnValue = ((Comparable) object1).compareTo(object2);
			} else if (object1 != null && object2 != null) {
				returnValue = compareStrings(object1.toString(), object2.toString());
			} else if (object1 == null && object2 != null) {
				returnValue = 1;
			} else if (object1 != null && object2 == null) {
				returnValue = -1;
			} else {
				returnValue = 0;
			}

			return returnValue;
		}

		private int compareStrings(String string1, String string2) {
			return string1.compareTo(string2);
		}

	}

	public static class row1Struct implements routines.system.IPersistableRow<row1Struct> {
		final static byte[] commonByteArrayLock_ETL_PROJECT_AggregateDates_job = new byte[0];
		static byte[] commonByteArray_ETL_PROJECT_AggregateDates_job = new byte[0];

		public java.util.Date Date;

		public java.util.Date getDate() {
			return this.Date;
		}

		private java.util.Date readDate(ObjectInputStream dis) throws IOException {
			java.util.Date dateReturn = null;
			int length = 0;
			length = dis.readByte();
			if (length == -1) {
				dateReturn = null;
			} else {
				dateReturn = new Date(dis.readLong());
			}
			return dateReturn;
		}

		private void writeDate(java.util.Date date1, ObjectOutputStream dos) throws IOException {
			if (date1 == null) {
				dos.writeByte(-1);
			} else {
				dos.writeByte(0);
				dos.writeLong(date1.getTime());
			}
		}

		public void readData(ObjectInputStream dis) {

			synchronized (commonByteArrayLock_ETL_PROJECT_AggregateDates_job) {

				try {

					int length = 0;

					this.Date = readDate(dis);

				} catch (IOException e) {
					throw new RuntimeException(e);

				}

			}

		}

		public void writeData(ObjectOutputStream dos) {
			try {

				// java.util.Date

				writeDate(this.Date, dos);

			} catch (IOException e) {
				throw new RuntimeException(e);
			}

		}

		public String toString() {

			StringBuilder sb = new StringBuilder();
			sb.append(super.toString());
			sb.append("[");
			sb.append("Date=" + String.valueOf(Date));
			sb.append("]");

			return sb.toString();
		}

		/**
		 * Compare keys
		 */
		public int compareTo(row1Struct other) {

			int returnValue = -1;

			return returnValue;
		}

		private int checkNullsAndCompare(Object object1, Object object2) {
			int returnValue = 0;
			if (object1 instanceof Comparable && object2 instanceof Comparable) {
				returnValue = ((Comparable) object1).compareTo(object2);
			} else if (object1 != null && object2 != null) {
				returnValue = compareStrings(object1.toString(), object2.toString());
			} else if (object1 == null && object2 != null) {
				returnValue = 1;
			} else if (object1 != null && object2 == null) {
				returnValue = -1;
			} else {
				returnValue = 0;
			}

			return returnValue;
		}

		private int compareStrings(String string1, String string2) {
			return string1.compareTo(string2);
		}

	}

	public static class date_naissance_outputStruct
			implements routines.system.IPersistableRow<date_naissance_outputStruct> {
		final static byte[] commonByteArrayLock_ETL_PROJECT_AggregateDates_job = new byte[0];
		static byte[] commonByteArray_ETL_PROJECT_AggregateDates_job = new byte[0];

		public java.util.Date Date;

		public java.util.Date getDate() {
			return this.Date;
		}

		private java.util.Date readDate(ObjectInputStream dis) throws IOException {
			java.util.Date dateReturn = null;
			int length = 0;
			length = dis.readByte();
			if (length == -1) {
				dateReturn = null;
			} else {
				dateReturn = new Date(dis.readLong());
			}
			return dateReturn;
		}

		private void writeDate(java.util.Date date1, ObjectOutputStream dos) throws IOException {
			if (date1 == null) {
				dos.writeByte(-1);
			} else {
				dos.writeByte(0);
				dos.writeLong(date1.getTime());
			}
		}

		public void readData(ObjectInputStream dis) {

			synchronized (commonByteArrayLock_ETL_PROJECT_AggregateDates_job) {

				try {

					int length = 0;

					this.Date = readDate(dis);

				} catch (IOException e) {
					throw new RuntimeException(e);

				}

			}

		}

		public void writeData(ObjectOutputStream dos) {
			try {

				// java.util.Date

				writeDate(this.Date, dos);

			} catch (IOException e) {
				throw new RuntimeException(e);
			}

		}

		public String toString() {

			StringBuilder sb = new StringBuilder();
			sb.append(super.toString());
			sb.append("[");
			sb.append("Date=" + String.valueOf(Date));
			sb.append("]");

			return sb.toString();
		}

		/**
		 * Compare keys
		 */
		public int compareTo(date_naissance_outputStruct other) {

			int returnValue = -1;

			return returnValue;
		}

		private int checkNullsAndCompare(Object object1, Object object2) {
			int returnValue = 0;
			if (object1 instanceof Comparable && object2 instanceof Comparable) {
				returnValue = ((Comparable) object1).compareTo(object2);
			} else if (object1 != null && object2 != null) {
				returnValue = compareStrings(object1.toString(), object2.toString());
			} else if (object1 == null && object2 != null) {
				returnValue = 1;
			} else if (object1 != null && object2 == null) {
				returnValue = -1;
			} else {
				returnValue = 0;
			}

			return returnValue;
		}

		private int compareStrings(String string1, String string2) {
			return string1.compareTo(string2);
		}

	}

	public static class row2Struct implements routines.system.IPersistableRow<row2Struct> {
		final static byte[] commonByteArrayLock_ETL_PROJECT_AggregateDates_job = new byte[0];
		static byte[] commonByteArray_ETL_PROJECT_AggregateDates_job = new byte[0];

		public String nom;

		public String getNom() {
			return this.nom;
		}

		public String prenom;

		public String getPrenom() {
			return this.prenom;
		}

		public Integer sexe;

		public Integer getSexe() {
			return this.sexe;
		}

		public String date_naissance;

		public String getDate_naissance() {
			return this.date_naissance;
		}

		public String code_lieu_naissance;

		public String getCode_lieu_naissance() {
			return this.code_lieu_naissance;
		}

		public String lieu_naissance;

		public String getLieu_naissance() {
			return this.lieu_naissance;
		}

		public String pays_naissance;

		public String getPays_naissance() {
			return this.pays_naissance;
		}

		public String date_deces;

		public String getDate_deces() {
			return this.date_deces;
		}

		public String code_lieu_deces;

		public String getCode_lieu_deces() {
			return this.code_lieu_deces;
		}

		public String numero_acte_deces;

		public String getNumero_acte_deces() {
			return this.numero_acte_deces;
		}

		private String readString(ObjectInputStream dis) throws IOException {
			String strReturn = null;
			int length = 0;
			length = dis.readInt();
			if (length == -1) {
				strReturn = null;
			} else {
				if (length > commonByteArray_ETL_PROJECT_AggregateDates_job.length) {
					if (length < 1024 && commonByteArray_ETL_PROJECT_AggregateDates_job.length == 0) {
						commonByteArray_ETL_PROJECT_AggregateDates_job = new byte[1024];
					} else {
						commonByteArray_ETL_PROJECT_AggregateDates_job = new byte[2 * length];
					}
				}
				dis.readFully(commonByteArray_ETL_PROJECT_AggregateDates_job, 0, length);
				strReturn = new String(commonByteArray_ETL_PROJECT_AggregateDates_job, 0, length, utf8Charset);
			}
			return strReturn;
		}

		private void writeString(String str, ObjectOutputStream dos) throws IOException {
			if (str == null) {
				dos.writeInt(-1);
			} else {
				byte[] byteArray = str.getBytes(utf8Charset);
				dos.writeInt(byteArray.length);
				dos.write(byteArray);
			}
		}

		private Integer readInteger(ObjectInputStream dis) throws IOException {
			Integer intReturn;
			int length = 0;
			length = dis.readByte();
			if (length == -1) {
				intReturn = null;
			} else {
				intReturn = dis.readInt();
			}
			return intReturn;
		}

		private void writeInteger(Integer intNum, ObjectOutputStream dos) throws IOException {
			if (intNum == null) {
				dos.writeByte(-1);
			} else {
				dos.writeByte(0);
				dos.writeInt(intNum);
			}
		}

		public void readData(ObjectInputStream dis) {

			synchronized (commonByteArrayLock_ETL_PROJECT_AggregateDates_job) {

				try {

					int length = 0;

					this.nom = readString(dis);

					this.prenom = readString(dis);

					this.sexe = readInteger(dis);

					this.date_naissance = readString(dis);

					this.code_lieu_naissance = readString(dis);

					this.lieu_naissance = readString(dis);

					this.pays_naissance = readString(dis);

					this.date_deces = readString(dis);

					this.code_lieu_deces = readString(dis);

					this.numero_acte_deces = readString(dis);

				} catch (IOException e) {
					throw new RuntimeException(e);

				}

			}

		}

		public void writeData(ObjectOutputStream dos) {
			try {

				// String

				writeString(this.nom, dos);

				// String

				writeString(this.prenom, dos);

				// Integer

				writeInteger(this.sexe, dos);

				// String

				writeString(this.date_naissance, dos);

				// String

				writeString(this.code_lieu_naissance, dos);

				// String

				writeString(this.lieu_naissance, dos);

				// String

				writeString(this.pays_naissance, dos);

				// String

				writeString(this.date_deces, dos);

				// String

				writeString(this.code_lieu_deces, dos);

				// String

				writeString(this.numero_acte_deces, dos);

			} catch (IOException e) {
				throw new RuntimeException(e);
			}

		}

		public String toString() {

			StringBuilder sb = new StringBuilder();
			sb.append(super.toString());
			sb.append("[");
			sb.append("nom=" + nom);
			sb.append(",prenom=" + prenom);
			sb.append(",sexe=" + String.valueOf(sexe));
			sb.append(",date_naissance=" + date_naissance);
			sb.append(",code_lieu_naissance=" + code_lieu_naissance);
			sb.append(",lieu_naissance=" + lieu_naissance);
			sb.append(",pays_naissance=" + pays_naissance);
			sb.append(",date_deces=" + date_deces);
			sb.append(",code_lieu_deces=" + code_lieu_deces);
			sb.append(",numero_acte_deces=" + numero_acte_deces);
			sb.append("]");

			return sb.toString();
		}

		/**
		 * Compare keys
		 */
		public int compareTo(row2Struct other) {

			int returnValue = -1;

			return returnValue;
		}

		private int checkNullsAndCompare(Object object1, Object object2) {
			int returnValue = 0;
			if (object1 instanceof Comparable && object2 instanceof Comparable) {
				returnValue = ((Comparable) object1).compareTo(object2);
			} else if (object1 != null && object2 != null) {
				returnValue = compareStrings(object1.toString(), object2.toString());
			} else if (object1 == null && object2 != null) {
				returnValue = 1;
			} else if (object1 != null && object2 == null) {
				returnValue = -1;
			} else {
				returnValue = 0;
			}

			return returnValue;
		}

		private int compareStrings(String string1, String string2) {
			return string1.compareTo(string2);
		}

	}

	public static class dates_hospitalization_outputStruct
			implements routines.system.IPersistableRow<dates_hospitalization_outputStruct> {
		final static byte[] commonByteArrayLock_ETL_PROJECT_AggregateDates_job = new byte[0];
		static byte[] commonByteArray_ETL_PROJECT_AggregateDates_job = new byte[0];

		public java.util.Date Date;

		public java.util.Date getDate() {
			return this.Date;
		}

		private java.util.Date readDate(ObjectInputStream dis) throws IOException {
			java.util.Date dateReturn = null;
			int length = 0;
			length = dis.readByte();
			if (length == -1) {
				dateReturn = null;
			} else {
				dateReturn = new Date(dis.readLong());
			}
			return dateReturn;
		}

		private void writeDate(java.util.Date date1, ObjectOutputStream dos) throws IOException {
			if (date1 == null) {
				dos.writeByte(-1);
			} else {
				dos.writeByte(0);
				dos.writeLong(date1.getTime());
			}
		}

		public void readData(ObjectInputStream dis) {

			synchronized (commonByteArrayLock_ETL_PROJECT_AggregateDates_job) {

				try {

					int length = 0;

					this.Date = readDate(dis);

				} catch (IOException e) {
					throw new RuntimeException(e);

				}

			}

		}

		public void writeData(ObjectOutputStream dos) {
			try {

				// java.util.Date

				writeDate(this.Date, dos);

			} catch (IOException e) {
				throw new RuntimeException(e);
			}

		}

		public String toString() {

			StringBuilder sb = new StringBuilder();
			sb.append(super.toString());
			sb.append("[");
			sb.append("Date=" + String.valueOf(Date));
			sb.append("]");

			return sb.toString();
		}

		/**
		 * Compare keys
		 */
		public int compareTo(dates_hospitalization_outputStruct other) {

			int returnValue = -1;

			return returnValue;
		}

		private int checkNullsAndCompare(Object object1, Object object2) {
			int returnValue = 0;
			if (object1 instanceof Comparable && object2 instanceof Comparable) {
				returnValue = ((Comparable) object1).compareTo(object2);
			} else if (object1 != null && object2 != null) {
				returnValue = compareStrings(object1.toString(), object2.toString());
			} else if (object1 == null && object2 != null) {
				returnValue = 1;
			} else if (object1 != null && object2 == null) {
				returnValue = -1;
			} else {
				returnValue = 0;
			}

			return returnValue;
		}

		private int compareStrings(String string1, String string2) {
			return string1.compareTo(string2);
		}

	}

	public static class row3Struct implements routines.system.IPersistableRow<row3Struct> {
		final static byte[] commonByteArrayLock_ETL_PROJECT_AggregateDates_job = new byte[0];
		static byte[] commonByteArray_ETL_PROJECT_AggregateDates_job = new byte[0];

		public Integer Num_Hospitalisation;

		public Integer getNum_Hospitalisation() {
			return this.Num_Hospitalisation;
		}

		public Integer Id_patient;

		public Integer getId_patient() {
			return this.Id_patient;
		}

		public String identifiant_organisation;

		public String getIdentifiant_organisation() {
			return this.identifiant_organisation;
		}

		public String Code_diagnostic;

		public String getCode_diagnostic() {
			return this.Code_diagnostic;
		}

		public String Suite_diagnostic_consultation;

		public String getSuite_diagnostic_consultation() {
			return this.Suite_diagnostic_consultation;
		}

		public String Date_Entree;

		public String getDate_Entree() {
			return this.Date_Entree;
		}

		public Integer Jour_Hospitalisation;

		public Integer getJour_Hospitalisation() {
			return this.Jour_Hospitalisation;
		}

		private Integer readInteger(ObjectInputStream dis) throws IOException {
			Integer intReturn;
			int length = 0;
			length = dis.readByte();
			if (length == -1) {
				intReturn = null;
			} else {
				intReturn = dis.readInt();
			}
			return intReturn;
		}

		private void writeInteger(Integer intNum, ObjectOutputStream dos) throws IOException {
			if (intNum == null) {
				dos.writeByte(-1);
			} else {
				dos.writeByte(0);
				dos.writeInt(intNum);
			}
		}

		private String readString(ObjectInputStream dis) throws IOException {
			String strReturn = null;
			int length = 0;
			length = dis.readInt();
			if (length == -1) {
				strReturn = null;
			} else {
				if (length > commonByteArray_ETL_PROJECT_AggregateDates_job.length) {
					if (length < 1024 && commonByteArray_ETL_PROJECT_AggregateDates_job.length == 0) {
						commonByteArray_ETL_PROJECT_AggregateDates_job = new byte[1024];
					} else {
						commonByteArray_ETL_PROJECT_AggregateDates_job = new byte[2 * length];
					}
				}
				dis.readFully(commonByteArray_ETL_PROJECT_AggregateDates_job, 0, length);
				strReturn = new String(commonByteArray_ETL_PROJECT_AggregateDates_job, 0, length, utf8Charset);
			}
			return strReturn;
		}

		private void writeString(String str, ObjectOutputStream dos) throws IOException {
			if (str == null) {
				dos.writeInt(-1);
			} else {
				byte[] byteArray = str.getBytes(utf8Charset);
				dos.writeInt(byteArray.length);
				dos.write(byteArray);
			}
		}

		public void readData(ObjectInputStream dis) {

			synchronized (commonByteArrayLock_ETL_PROJECT_AggregateDates_job) {

				try {

					int length = 0;

					this.Num_Hospitalisation = readInteger(dis);

					this.Id_patient = readInteger(dis);

					this.identifiant_organisation = readString(dis);

					this.Code_diagnostic = readString(dis);

					this.Suite_diagnostic_consultation = readString(dis);

					this.Date_Entree = readString(dis);

					this.Jour_Hospitalisation = readInteger(dis);

				} catch (IOException e) {
					throw new RuntimeException(e);

				}

			}

		}

		public void writeData(ObjectOutputStream dos) {
			try {

				// Integer

				writeInteger(this.Num_Hospitalisation, dos);

				// Integer

				writeInteger(this.Id_patient, dos);

				// String

				writeString(this.identifiant_organisation, dos);

				// String

				writeString(this.Code_diagnostic, dos);

				// String

				writeString(this.Suite_diagnostic_consultation, dos);

				// String

				writeString(this.Date_Entree, dos);

				// Integer

				writeInteger(this.Jour_Hospitalisation, dos);

			} catch (IOException e) {
				throw new RuntimeException(e);
			}

		}

		public String toString() {

			StringBuilder sb = new StringBuilder();
			sb.append(super.toString());
			sb.append("[");
			sb.append("Num_Hospitalisation=" + String.valueOf(Num_Hospitalisation));
			sb.append(",Id_patient=" + String.valueOf(Id_patient));
			sb.append(",identifiant_organisation=" + identifiant_organisation);
			sb.append(",Code_diagnostic=" + Code_diagnostic);
			sb.append(",Suite_diagnostic_consultation=" + Suite_diagnostic_consultation);
			sb.append(",Date_Entree=" + Date_Entree);
			sb.append(",Jour_Hospitalisation=" + String.valueOf(Jour_Hospitalisation));
			sb.append("]");

			return sb.toString();
		}

		/**
		 * Compare keys
		 */
		public int compareTo(row3Struct other) {

			int returnValue = -1;

			return returnValue;
		}

		private int checkNullsAndCompare(Object object1, Object object2) {
			int returnValue = 0;
			if (object1 instanceof Comparable && object2 instanceof Comparable) {
				returnValue = ((Comparable) object1).compareTo(object2);
			} else if (object1 != null && object2 != null) {
				returnValue = compareStrings(object1.toString(), object2.toString());
			} else if (object1 == null && object2 != null) {
				returnValue = 1;
			} else if (object1 != null && object2 == null) {
				returnValue = -1;
			} else {
				returnValue = 0;
			}

			return returnValue;
		}

		private int compareStrings(String string1, String string2) {
			return string1.compareTo(string2);
		}

	}

	public void tDBInput_1Process(final java.util.Map<String, Object> globalMap) throws TalendException {
		globalMap.put("tDBInput_1_SUBPROCESS_STATE", 0);

		final boolean execStat = this.execStat;

		String iterateId = "";

		String currentComponent = "";
		java.util.Map<String, Object> resourceMap = new java.util.HashMap<String, Object>();

		try {
			// TDI-39566 avoid throwing an useless Exception
			boolean resumeIt = true;
			if (globalResumeTicket == false && resumeEntryMethodName != null) {
				String currentMethodName = new java.lang.Exception().getStackTrace()[0].getMethodName();
				resumeIt = resumeEntryMethodName.equals(currentMethodName);
			}
			if (resumeIt || globalResumeTicket) { // start the resume
				globalResumeTicket = true;

				row1Struct row1 = new row1Struct();

				row3Struct row3 = new row3Struct();
				dates_hospitalization_outputStruct dates_hospitalization_output = new dates_hospitalization_outputStruct();

				row2Struct row2 = new row2Struct();
				date_naissance_outputStruct date_naissance_output = new date_naissance_outputStruct();

				row4Struct row4 = new row4Struct();
				row5Struct row5 = new row5Struct();
				d_dates_outputStruct d_dates_output = new d_dates_outputStruct();

				/**
				 * [tLogRow_1 begin ] start
				 */

				ok_Hash.put("tLogRow_1", false);
				start_Hash.put("tLogRow_1", System.currentTimeMillis());

				currentComponent = "tLogRow_1";

				if (execStat) {
					runStat.updateStatOnConnection(resourceMap, iterateId, 0, 0, "d_dates_output");
				}

				int tos_count_tLogRow_1 = 0;

				///////////////////////

				final String OUTPUT_FIELD_SEPARATOR_tLogRow_1 = "|";
				java.io.PrintStream consoleOut_tLogRow_1 = null;

				StringBuilder strBuffer_tLogRow_1 = null;
				int nb_line_tLogRow_1 = 0;
///////////////////////    			

				/**
				 * [tLogRow_1 begin ] stop
				 */

				/**
				 * [tMap_2 begin ] start
				 */

				ok_Hash.put("tMap_2", false);
				start_Hash.put("tMap_2", System.currentTimeMillis());

				currentComponent = "tMap_2";

				if (execStat) {
					runStat.updateStatOnConnection(resourceMap, iterateId, 0, 0, "row5");
				}

				int tos_count_tMap_2 = 0;

// ###############################
// # Lookup's keys initialization
// ###############################        

// ###############################
// # Vars initialization
				class Var__tMap_2__Struct {
				}
				Var__tMap_2__Struct Var__tMap_2 = new Var__tMap_2__Struct();
// ###############################

// ###############################
// # Outputs initialization
				d_dates_outputStruct d_dates_output_tmp = new d_dates_outputStruct();
// ###############################

				/**
				 * [tMap_2 begin ] stop
				 */

				/**
				 * [tUniqRow_1 begin ] start
				 */

				ok_Hash.put("tUniqRow_1", false);
				start_Hash.put("tUniqRow_1", System.currentTimeMillis());

				currentComponent = "tUniqRow_1";

				if (execStat) {
					runStat.updateStatOnConnection(resourceMap, iterateId, 0, 0, "row4");
				}

				int tos_count_tUniqRow_1 = 0;

				int nb_uniques_tUniqRow_1 = 0;
				int nb_duplicates_tUniqRow_1 = 0;

				/**
				 * [tUniqRow_1 begin ] stop
				 */

				/**
				 * [tUnite_1 begin ] start
				 */

				ok_Hash.put("tUnite_1", false);
				start_Hash.put("tUnite_1", System.currentTimeMillis());

				currentComponent = "tUnite_1";

				if (execStat) {
					runStat.updateStatOnConnection(resourceMap, iterateId, 0, 0, "row1", "dates_hospitalization_output",
							"date_naissance_output");
				}

				int tos_count_tUnite_1 = 0;

				int nb_line_tUnite_1 = 0;

				/**
				 * [tUnite_1 begin ] stop
				 */

				/**
				 * [tDBInput_1 begin ] start
				 */

				ok_Hash.put("tDBInput_1", false);
				start_Hash.put("tDBInput_1", System.currentTimeMillis());

				currentComponent = "tDBInput_1";

				int tos_count_tDBInput_1 = 0;

				int nb_line_tDBInput_1 = 0;
				java.sql.Connection conn_tDBInput_1 = null;
				String driverClass_tDBInput_1 = "org.postgresql.Driver";
				java.lang.Class jdbcclazz_tDBInput_1 = java.lang.Class.forName(driverClass_tDBInput_1);
				String dbUser_tDBInput_1 = context.postgres_DB_input_Login;

				final String decryptedPassword_tDBInput_1 = context.postgres_DB_input_Password;

				String dbPwd_tDBInput_1 = decryptedPassword_tDBInput_1;

				String url_tDBInput_1 = "jdbc:postgresql://" + context.postgres_DB_input_Server + ":"
						+ context.postgres_DB_input_Port + "/" + context.postgres_DB_input_Database + "?"
						+ context.postgres_DB_input_AdditionalParams;

				conn_tDBInput_1 = java.sql.DriverManager.getConnection(url_tDBInput_1, dbUser_tDBInput_1,
						dbPwd_tDBInput_1);

				conn_tDBInput_1.setAutoCommit(false);

				java.sql.Statement stmt_tDBInput_1 = conn_tDBInput_1.createStatement();

				String dbquery_tDBInput_1 = "SELECT \"Date\" FROM \"Consultation\"";

				globalMap.put("tDBInput_1_QUERY", dbquery_tDBInput_1);
				java.sql.ResultSet rs_tDBInput_1 = null;

				try {
					rs_tDBInput_1 = stmt_tDBInput_1.executeQuery(dbquery_tDBInput_1);
					java.sql.ResultSetMetaData rsmd_tDBInput_1 = rs_tDBInput_1.getMetaData();
					int colQtyInRs_tDBInput_1 = rsmd_tDBInput_1.getColumnCount();

					String tmpContent_tDBInput_1 = null;

					while (rs_tDBInput_1.next()) {
						nb_line_tDBInput_1++;

						if (colQtyInRs_tDBInput_1 < 1) {
							row1.Date = null;
						} else {

							row1.Date = routines.system.JDBCUtil.getDate(rs_tDBInput_1, 1);
						}

						/**
						 * [tDBInput_1 begin ] stop
						 */

						/**
						 * [tDBInput_1 main ] start
						 */

						currentComponent = "tDBInput_1";

						tos_count_tDBInput_1++;

						/**
						 * [tDBInput_1 main ] stop
						 */

						/**
						 * [tDBInput_1 process_data_begin ] start
						 */

						currentComponent = "tDBInput_1";

						/**
						 * [tDBInput_1 process_data_begin ] stop
						 */

						/**
						 * [tUnite_1 main ] start
						 */

						currentComponent = "tUnite_1";

						if (execStat) {
							runStat.updateStatOnConnection(iterateId, 1, 1, "row1");
						}

//////////

// for output
						row4 = new row4Struct();

						row4.Date = row1.Date;

						nb_line_tUnite_1++;

//////////

						tos_count_tUnite_1++;

						/**
						 * [tUnite_1 main ] stop
						 */

						/**
						 * [tUnite_1 process_data_begin ] start
						 */

						currentComponent = "tUnite_1";

						/**
						 * [tUnite_1 process_data_begin ] stop
						 */

						/**
						 * [tUniqRow_1 main ] start
						 */

						currentComponent = "tUniqRow_1";

						if (execStat) {
							runStat.updateStatOnConnection(iterateId, 1, 1, "row4");
						}

						row5.Date = row4.Date;

						tos_count_tUniqRow_1++;

						/**
						 * [tUniqRow_1 main ] stop
						 */

						/**
						 * [tUniqRow_1 process_data_begin ] start
						 */

						currentComponent = "tUniqRow_1";

						/**
						 * [tUniqRow_1 process_data_begin ] stop
						 */
// Start of branch "row5"
						if (row5 != null) {

							/**
							 * [tMap_2 main ] start
							 */

							currentComponent = "tMap_2";

							if (execStat) {
								runStat.updateStatOnConnection(iterateId, 1, 1, "row5");
							}

							boolean hasCasePrimitiveKeyWithNull_tMap_2 = false;

							// ###############################
							// # Input tables (lookups)
							boolean rejectedInnerJoin_tMap_2 = false;
							boolean mainRowRejected_tMap_2 = false;

							// ###############################
							{ // start of Var scope

								// ###############################
								// # Vars tables

								Var__tMap_2__Struct Var = Var__tMap_2;// ###############################
								// ###############################
								// # Output tables

								d_dates_output = null;

// # Output table : 'd_dates_output'
								d_dates_output_tmp.Id_date = Numeric.sequence("id_seq", 1, 1);
								d_dates_output_tmp.Date = row5.Date;
								d_dates_output_tmp.Year = TalendDate.getPartOfDate("YEAR", row5.Date);
								d_dates_output = d_dates_output_tmp;
// ###############################

							} // end of Var scope

							rejectedInnerJoin_tMap_2 = false;

							tos_count_tMap_2++;

							/**
							 * [tMap_2 main ] stop
							 */

							/**
							 * [tMap_2 process_data_begin ] start
							 */

							currentComponent = "tMap_2";

							/**
							 * [tMap_2 process_data_begin ] stop
							 */
// Start of branch "d_dates_output"
							if (d_dates_output != null) {

								/**
								 * [tLogRow_1 main ] start
								 */

								currentComponent = "tLogRow_1";

								if (execStat) {
									runStat.updateStatOnConnection(iterateId, 1, 1, "d_dates_output");
								}

///////////////////////		

								strBuffer_tLogRow_1 = new StringBuilder();

								strBuffer_tLogRow_1.append(String.valueOf(d_dates_output.Id_date));

								strBuffer_tLogRow_1.append("|");

								if (d_dates_output.Date != null) { //

									strBuffer_tLogRow_1
											.append(FormatterUtils.format_Date(d_dates_output.Date, "yyyy-MM-dd"));

								} //

								strBuffer_tLogRow_1.append("|");

								strBuffer_tLogRow_1.append(String.valueOf(d_dates_output.Year));

								if (globalMap.get("tLogRow_CONSOLE") != null) {
									consoleOut_tLogRow_1 = (java.io.PrintStream) globalMap.get("tLogRow_CONSOLE");
								} else {
									consoleOut_tLogRow_1 = new java.io.PrintStream(
											new java.io.BufferedOutputStream(System.out));
									globalMap.put("tLogRow_CONSOLE", consoleOut_tLogRow_1);
								}
								consoleOut_tLogRow_1.println(strBuffer_tLogRow_1.toString());
								consoleOut_tLogRow_1.flush();
								nb_line_tLogRow_1++;
//////

//////                    

///////////////////////    			

								tos_count_tLogRow_1++;

								/**
								 * [tLogRow_1 main ] stop
								 */

								/**
								 * [tLogRow_1 process_data_begin ] start
								 */

								currentComponent = "tLogRow_1";

								/**
								 * [tLogRow_1 process_data_begin ] stop
								 */

								/**
								 * [tLogRow_1 process_data_end ] start
								 */

								currentComponent = "tLogRow_1";

								/**
								 * [tLogRow_1 process_data_end ] stop
								 */

							} // End of branch "d_dates_output"

							/**
							 * [tMap_2 process_data_end ] start
							 */

							currentComponent = "tMap_2";

							/**
							 * [tMap_2 process_data_end ] stop
							 */

						} // End of branch "row5"

						/**
						 * [tUniqRow_1 process_data_end ] start
						 */

						currentComponent = "tUniqRow_1";

						/**
						 * [tUniqRow_1 process_data_end ] stop
						 */

						/**
						 * [tUnite_1 process_data_end ] start
						 */

						currentComponent = "tUnite_1";

						/**
						 * [tUnite_1 process_data_end ] stop
						 */

						/**
						 * [tDBInput_1 process_data_end ] start
						 */

						currentComponent = "tDBInput_1";

						/**
						 * [tDBInput_1 process_data_end ] stop
						 */

						/**
						 * [tDBInput_1 end ] start
						 */

						currentComponent = "tDBInput_1";

					}
				} finally {
					if (rs_tDBInput_1 != null) {
						rs_tDBInput_1.close();
					}
					if (stmt_tDBInput_1 != null) {
						stmt_tDBInput_1.close();
					}
					if (conn_tDBInput_1 != null && !conn_tDBInput_1.isClosed()) {

						conn_tDBInput_1.commit();

						conn_tDBInput_1.close();

						if ("com.mysql.cj.jdbc.Driver".equals((String) globalMap.get("driverClass_"))
								&& routines.system.BundleUtils.inOSGi()) {
							Class.forName("com.mysql.cj.jdbc.AbandonedConnectionCleanupThread")
									.getMethod("checkedShutdown").invoke(null, (Object[]) null);
						}

					}

				}
				globalMap.put("tDBInput_1_NB_LINE", nb_line_tDBInput_1);

				ok_Hash.put("tDBInput_1", true);
				end_Hash.put("tDBInput_1", System.currentTimeMillis());

				/**
				 * [tDBInput_1 end ] stop
				 */

				/**
				 * [tMap_3 begin ] start
				 */

				ok_Hash.put("tMap_3", false);
				start_Hash.put("tMap_3", System.currentTimeMillis());

				currentComponent = "tMap_3";

				if (execStat) {
					runStat.updateStatOnConnection(resourceMap, iterateId, 0, 0, "row3");
				}

				int tos_count_tMap_3 = 0;

// ###############################
// # Lookup's keys initialization
// ###############################        

// ###############################
// # Vars initialization
				class Var__tMap_3__Struct {
				}
				Var__tMap_3__Struct Var__tMap_3 = new Var__tMap_3__Struct();
// ###############################

// ###############################
// # Outputs initialization
				dates_hospitalization_outputStruct dates_hospitalization_output_tmp = new dates_hospitalization_outputStruct();
// ###############################

				/**
				 * [tMap_3 begin ] stop
				 */

				/**
				 * [tFileInputDelimited_2 begin ] start
				 */

				ok_Hash.put("tFileInputDelimited_2", false);
				start_Hash.put("tFileInputDelimited_2", System.currentTimeMillis());

				currentComponent = "tFileInputDelimited_2";

				int tos_count_tFileInputDelimited_2 = 0;

				final routines.system.RowState rowstate_tFileInputDelimited_2 = new routines.system.RowState();

				int nb_line_tFileInputDelimited_2 = 0;
				org.talend.fileprocess.FileInputDelimited fid_tFileInputDelimited_2 = null;
				int limit_tFileInputDelimited_2 = -1;
				try {

					Object filename_tFileInputDelimited_2 = context.INPUT_PATH + "Hospitalisations.csv";
					if (filename_tFileInputDelimited_2 instanceof java.io.InputStream) {

						int footer_value_tFileInputDelimited_2 = 0, random_value_tFileInputDelimited_2 = -1;
						if (footer_value_tFileInputDelimited_2 > 0 || random_value_tFileInputDelimited_2 > 0) {
							throw new java.lang.Exception(
									"When the input source is a stream,footer and random shouldn't be bigger than 0.");
						}

					}
					try {
						fid_tFileInputDelimited_2 = new org.talend.fileprocess.FileInputDelimited(
								context.INPUT_PATH + "Hospitalisations.csv", "ISO-8859-15", ";", "\n", true, 1, 0,
								limit_tFileInputDelimited_2, -1, false);
					} catch (java.lang.Exception e) {

						System.err.println(e.getMessage());

					}

					while (fid_tFileInputDelimited_2 != null && fid_tFileInputDelimited_2.nextRecord()) {
						rowstate_tFileInputDelimited_2.reset();

						row3 = null;

						boolean whetherReject_tFileInputDelimited_2 = false;
						row3 = new row3Struct();
						try {

							int columnIndexWithD_tFileInputDelimited_2 = 0;

							String temp = "";

							columnIndexWithD_tFileInputDelimited_2 = 0;

							temp = fid_tFileInputDelimited_2.get(columnIndexWithD_tFileInputDelimited_2);
							if (temp.length() > 0) {

								try {

									row3.Num_Hospitalisation = ParserUtils.parseTo_Integer(temp);

								} catch (java.lang.Exception ex_tFileInputDelimited_2) {
									rowstate_tFileInputDelimited_2.setException(new RuntimeException(String.format(
											"Couldn't parse value for column '%s' in '%s', value is '%s'. Details: %s",
											"Num_Hospitalisation", "row3", temp, ex_tFileInputDelimited_2),
											ex_tFileInputDelimited_2));
								}

							} else {

								row3.Num_Hospitalisation = null;

							}

							columnIndexWithD_tFileInputDelimited_2 = 1;

							temp = fid_tFileInputDelimited_2.get(columnIndexWithD_tFileInputDelimited_2);
							if (temp.length() > 0) {

								try {

									row3.Id_patient = ParserUtils.parseTo_Integer(temp);

								} catch (java.lang.Exception ex_tFileInputDelimited_2) {
									rowstate_tFileInputDelimited_2.setException(new RuntimeException(String.format(
											"Couldn't parse value for column '%s' in '%s', value is '%s'. Details: %s",
											"Id_patient", "row3", temp, ex_tFileInputDelimited_2),
											ex_tFileInputDelimited_2));
								}

							} else {

								row3.Id_patient = null;

							}

							columnIndexWithD_tFileInputDelimited_2 = 2;

							row3.identifiant_organisation = fid_tFileInputDelimited_2
									.get(columnIndexWithD_tFileInputDelimited_2);

							columnIndexWithD_tFileInputDelimited_2 = 3;

							row3.Code_diagnostic = fid_tFileInputDelimited_2
									.get(columnIndexWithD_tFileInputDelimited_2);

							columnIndexWithD_tFileInputDelimited_2 = 4;

							row3.Suite_diagnostic_consultation = fid_tFileInputDelimited_2
									.get(columnIndexWithD_tFileInputDelimited_2);

							columnIndexWithD_tFileInputDelimited_2 = 5;

							row3.Date_Entree = fid_tFileInputDelimited_2.get(columnIndexWithD_tFileInputDelimited_2);

							columnIndexWithD_tFileInputDelimited_2 = 6;

							temp = fid_tFileInputDelimited_2.get(columnIndexWithD_tFileInputDelimited_2);
							if (temp.length() > 0) {

								try {

									row3.Jour_Hospitalisation = ParserUtils.parseTo_Integer(temp);

								} catch (java.lang.Exception ex_tFileInputDelimited_2) {
									rowstate_tFileInputDelimited_2.setException(new RuntimeException(String.format(
											"Couldn't parse value for column '%s' in '%s', value is '%s'. Details: %s",
											"Jour_Hospitalisation", "row3", temp, ex_tFileInputDelimited_2),
											ex_tFileInputDelimited_2));
								}

							} else {

								row3.Jour_Hospitalisation = null;

							}

							if (rowstate_tFileInputDelimited_2.getException() != null) {
								throw rowstate_tFileInputDelimited_2.getException();
							}

						} catch (java.lang.Exception e) {
							whetherReject_tFileInputDelimited_2 = true;

							System.err.println(e.getMessage());
							row3 = null;

						}

						/**
						 * [tFileInputDelimited_2 begin ] stop
						 */

						/**
						 * [tFileInputDelimited_2 main ] start
						 */

						currentComponent = "tFileInputDelimited_2";

						tos_count_tFileInputDelimited_2++;

						/**
						 * [tFileInputDelimited_2 main ] stop
						 */

						/**
						 * [tFileInputDelimited_2 process_data_begin ] start
						 */

						currentComponent = "tFileInputDelimited_2";

						/**
						 * [tFileInputDelimited_2 process_data_begin ] stop
						 */
// Start of branch "row3"
						if (row3 != null) {

							/**
							 * [tMap_3 main ] start
							 */

							currentComponent = "tMap_3";

							if (execStat) {
								runStat.updateStatOnConnection(iterateId, 1, 1, "row3");
							}

							boolean hasCasePrimitiveKeyWithNull_tMap_3 = false;

							// ###############################
							// # Input tables (lookups)
							boolean rejectedInnerJoin_tMap_3 = false;
							boolean mainRowRejected_tMap_3 = false;

							// ###############################
							{ // start of Var scope

								// ###############################
								// # Vars tables

								Var__tMap_3__Struct Var = Var__tMap_3;// ###############################
								// ###############################
								// # Output tables

								dates_hospitalization_output = null;

// # Output table : 'dates_hospitalization_output'
								dates_hospitalization_output_tmp.Date = row3.Date_Entree == null
										|| row3.Date_Entree.trim().isEmpty()
												? null
												: (!row3.Date_Entree.replaceAll("/", "-")
														.matches("^\\d{4}-\\d{2}-\\d{2}$")
																? (row3.Date_Entree.replaceAll("-", "/")
																		.matches("^\\d{4}$")
																				? TalendDate.parseDate("yyyy-MM-dd",
																						row3.Date_Entree.replaceAll("/",
																								"-") + "-01-01")
																				: (row3.Date_Entree.replaceAll("-", "/")
																						.matches("^\\d{4}/\\d{2}$")
																								? TalendDate.parseDate(
																										"yyyy-MM-dd",
																										row3.Date_Entree
																												.replaceAll(
																														"/",
																														"-")
																												+ "-01")
																								: null))
																: TalendDate.parseDate("yyyy/MM/dd",
																		row3.Date_Entree.replaceAll("/", "-")));
								dates_hospitalization_output = dates_hospitalization_output_tmp;
// ###############################

							} // end of Var scope

							rejectedInnerJoin_tMap_3 = false;

							tos_count_tMap_3++;

							/**
							 * [tMap_3 main ] stop
							 */

							/**
							 * [tMap_3 process_data_begin ] start
							 */

							currentComponent = "tMap_3";

							/**
							 * [tMap_3 process_data_begin ] stop
							 */
// Start of branch "dates_hospitalization_output"
							if (dates_hospitalization_output != null) {

								/**
								 * [tUnite_1 main ] start
								 */

								currentComponent = "tUnite_1";

								if (execStat) {
									runStat.updateStatOnConnection(iterateId, 1, 1, "dates_hospitalization_output");
								}

//////////

// for output
								row4 = new row4Struct();

								row4.Date = dates_hospitalization_output.Date;

								nb_line_tUnite_1++;

//////////

								tos_count_tUnite_1++;

								/**
								 * [tUnite_1 main ] stop
								 */

								/**
								 * [tUnite_1 process_data_begin ] start
								 */

								currentComponent = "tUnite_1";

								/**
								 * [tUnite_1 process_data_begin ] stop
								 */

								/**
								 * [tUniqRow_1 main ] start
								 */

								currentComponent = "tUniqRow_1";

								if (execStat) {
									runStat.updateStatOnConnection(iterateId, 1, 1, "row4");
								}

								row5.Date = row4.Date;

								tos_count_tUniqRow_1++;

								/**
								 * [tUniqRow_1 main ] stop
								 */

								/**
								 * [tUniqRow_1 process_data_begin ] start
								 */

								currentComponent = "tUniqRow_1";

								/**
								 * [tUniqRow_1 process_data_begin ] stop
								 */
// Start of branch "row5"
								if (row5 != null) {

									/**
									 * [tMap_2 main ] start
									 */

									currentComponent = "tMap_2";

									if (execStat) {
										runStat.updateStatOnConnection(iterateId, 1, 1, "row5");
									}

									boolean hasCasePrimitiveKeyWithNull_tMap_2 = false;

									// ###############################
									// # Input tables (lookups)
									boolean rejectedInnerJoin_tMap_2 = false;
									boolean mainRowRejected_tMap_2 = false;

									// ###############################
									{ // start of Var scope

										// ###############################
										// # Vars tables

										Var__tMap_2__Struct Var = Var__tMap_2;// ###############################
										// ###############################
										// # Output tables

										d_dates_output = null;

// # Output table : 'd_dates_output'
										d_dates_output_tmp.Id_date = Numeric.sequence("id_seq", 1, 1);
										d_dates_output_tmp.Date = row5.Date;
										d_dates_output_tmp.Year = TalendDate.getPartOfDate("YEAR", row5.Date);
										d_dates_output = d_dates_output_tmp;
// ###############################

									} // end of Var scope

									rejectedInnerJoin_tMap_2 = false;

									tos_count_tMap_2++;

									/**
									 * [tMap_2 main ] stop
									 */

									/**
									 * [tMap_2 process_data_begin ] start
									 */

									currentComponent = "tMap_2";

									/**
									 * [tMap_2 process_data_begin ] stop
									 */
// Start of branch "d_dates_output"
									if (d_dates_output != null) {

										/**
										 * [tLogRow_1 main ] start
										 */

										currentComponent = "tLogRow_1";

										if (execStat) {
											runStat.updateStatOnConnection(iterateId, 1, 1, "d_dates_output");
										}

///////////////////////		

										strBuffer_tLogRow_1 = new StringBuilder();

										strBuffer_tLogRow_1.append(String.valueOf(d_dates_output.Id_date));

										strBuffer_tLogRow_1.append("|");

										if (d_dates_output.Date != null) { //

											strBuffer_tLogRow_1.append(
													FormatterUtils.format_Date(d_dates_output.Date, "yyyy-MM-dd"));

										} //

										strBuffer_tLogRow_1.append("|");

										strBuffer_tLogRow_1.append(String.valueOf(d_dates_output.Year));

										if (globalMap.get("tLogRow_CONSOLE") != null) {
											consoleOut_tLogRow_1 = (java.io.PrintStream) globalMap
													.get("tLogRow_CONSOLE");
										} else {
											consoleOut_tLogRow_1 = new java.io.PrintStream(
													new java.io.BufferedOutputStream(System.out));
											globalMap.put("tLogRow_CONSOLE", consoleOut_tLogRow_1);
										}
										consoleOut_tLogRow_1.println(strBuffer_tLogRow_1.toString());
										consoleOut_tLogRow_1.flush();
										nb_line_tLogRow_1++;
//////

//////                    

///////////////////////    			

										tos_count_tLogRow_1++;

										/**
										 * [tLogRow_1 main ] stop
										 */

										/**
										 * [tLogRow_1 process_data_begin ] start
										 */

										currentComponent = "tLogRow_1";

										/**
										 * [tLogRow_1 process_data_begin ] stop
										 */

										/**
										 * [tLogRow_1 process_data_end ] start
										 */

										currentComponent = "tLogRow_1";

										/**
										 * [tLogRow_1 process_data_end ] stop
										 */

									} // End of branch "d_dates_output"

									/**
									 * [tMap_2 process_data_end ] start
									 */

									currentComponent = "tMap_2";

									/**
									 * [tMap_2 process_data_end ] stop
									 */

								} // End of branch "row5"

								/**
								 * [tUniqRow_1 process_data_end ] start
								 */

								currentComponent = "tUniqRow_1";

								/**
								 * [tUniqRow_1 process_data_end ] stop
								 */

								/**
								 * [tUnite_1 process_data_end ] start
								 */

								currentComponent = "tUnite_1";

								/**
								 * [tUnite_1 process_data_end ] stop
								 */

							} // End of branch "dates_hospitalization_output"

							/**
							 * [tMap_3 process_data_end ] start
							 */

							currentComponent = "tMap_3";

							/**
							 * [tMap_3 process_data_end ] stop
							 */

						} // End of branch "row3"

						/**
						 * [tFileInputDelimited_2 process_data_end ] start
						 */

						currentComponent = "tFileInputDelimited_2";

						/**
						 * [tFileInputDelimited_2 process_data_end ] stop
						 */

						/**
						 * [tFileInputDelimited_2 end ] start
						 */

						currentComponent = "tFileInputDelimited_2";

					}
				} finally {
					if (!((Object) (context.INPUT_PATH + "Hospitalisations.csv") instanceof java.io.InputStream)) {
						if (fid_tFileInputDelimited_2 != null) {
							fid_tFileInputDelimited_2.close();
						}
					}
					if (fid_tFileInputDelimited_2 != null) {
						globalMap.put("tFileInputDelimited_2_NB_LINE", fid_tFileInputDelimited_2.getRowNumber());

					}
				}

				ok_Hash.put("tFileInputDelimited_2", true);
				end_Hash.put("tFileInputDelimited_2", System.currentTimeMillis());

				/**
				 * [tFileInputDelimited_2 end ] stop
				 */

				/**
				 * [tMap_3 end ] start
				 */

				currentComponent = "tMap_3";

// ###############################
// # Lookup hashes releasing
// ###############################      

				if (execStat) {
					runStat.updateStat(resourceMap, iterateId, 2, 0, "row3");
				}

				ok_Hash.put("tMap_3", true);
				end_Hash.put("tMap_3", System.currentTimeMillis());

				/**
				 * [tMap_3 end ] stop
				 */

				/**
				 * [tMap_1 begin ] start
				 */

				ok_Hash.put("tMap_1", false);
				start_Hash.put("tMap_1", System.currentTimeMillis());

				currentComponent = "tMap_1";

				if (execStat) {
					runStat.updateStatOnConnection(resourceMap, iterateId, 0, 0, "row2");
				}

				int tos_count_tMap_1 = 0;

// ###############################
// # Lookup's keys initialization
// ###############################        

// ###############################
// # Vars initialization
				class Var__tMap_1__Struct {
				}
				Var__tMap_1__Struct Var__tMap_1 = new Var__tMap_1__Struct();
// ###############################

// ###############################
// # Outputs initialization
				date_naissance_outputStruct date_naissance_output_tmp = new date_naissance_outputStruct();
// ###############################

				/**
				 * [tMap_1 begin ] stop
				 */

				/**
				 * [tFileInputDelimited_1 begin ] start
				 */

				ok_Hash.put("tFileInputDelimited_1", false);
				start_Hash.put("tFileInputDelimited_1", System.currentTimeMillis());

				currentComponent = "tFileInputDelimited_1";

				int tos_count_tFileInputDelimited_1 = 0;

				final routines.system.RowState rowstate_tFileInputDelimited_1 = new routines.system.RowState();

				int nb_line_tFileInputDelimited_1 = 0;
				org.talend.fileprocess.FileInputDelimited fid_tFileInputDelimited_1 = null;
				int limit_tFileInputDelimited_1 = -1;
				try {

					Object filename_tFileInputDelimited_1 = context.INPUT_PATH + "deces.csv";
					if (filename_tFileInputDelimited_1 instanceof java.io.InputStream) {

						int footer_value_tFileInputDelimited_1 = 0, random_value_tFileInputDelimited_1 = -1;
						if (footer_value_tFileInputDelimited_1 > 0 || random_value_tFileInputDelimited_1 > 0) {
							throw new java.lang.Exception(
									"When the input source is a stream,footer and random shouldn't be bigger than 0.");
						}

					}
					try {
						fid_tFileInputDelimited_1 = new org.talend.fileprocess.FileInputDelimited(
								context.INPUT_PATH + "deces.csv", "ISO-8859-15", ",", "\n", true, 1, 0,
								limit_tFileInputDelimited_1, -1, false);
					} catch (java.lang.Exception e) {

						System.err.println(e.getMessage());

					}

					while (fid_tFileInputDelimited_1 != null && fid_tFileInputDelimited_1.nextRecord()) {
						rowstate_tFileInputDelimited_1.reset();

						row2 = null;

						boolean whetherReject_tFileInputDelimited_1 = false;
						row2 = new row2Struct();
						try {

							int columnIndexWithD_tFileInputDelimited_1 = 0;

							String temp = "";

							columnIndexWithD_tFileInputDelimited_1 = 0;

							row2.nom = fid_tFileInputDelimited_1.get(columnIndexWithD_tFileInputDelimited_1);

							columnIndexWithD_tFileInputDelimited_1 = 1;

							row2.prenom = fid_tFileInputDelimited_1.get(columnIndexWithD_tFileInputDelimited_1);

							columnIndexWithD_tFileInputDelimited_1 = 2;

							temp = fid_tFileInputDelimited_1.get(columnIndexWithD_tFileInputDelimited_1);
							if (temp.length() > 0) {

								try {

									row2.sexe = ParserUtils.parseTo_Integer(temp);

								} catch (java.lang.Exception ex_tFileInputDelimited_1) {
									rowstate_tFileInputDelimited_1.setException(new RuntimeException(String.format(
											"Couldn't parse value for column '%s' in '%s', value is '%s'. Details: %s",
											"sexe", "row2", temp, ex_tFileInputDelimited_1), ex_tFileInputDelimited_1));
								}

							} else {

								row2.sexe = null;

							}

							columnIndexWithD_tFileInputDelimited_1 = 3;

							row2.date_naissance = fid_tFileInputDelimited_1.get(columnIndexWithD_tFileInputDelimited_1);

							columnIndexWithD_tFileInputDelimited_1 = 4;

							row2.code_lieu_naissance = fid_tFileInputDelimited_1
									.get(columnIndexWithD_tFileInputDelimited_1);

							columnIndexWithD_tFileInputDelimited_1 = 5;

							row2.lieu_naissance = fid_tFileInputDelimited_1.get(columnIndexWithD_tFileInputDelimited_1);

							columnIndexWithD_tFileInputDelimited_1 = 6;

							row2.pays_naissance = fid_tFileInputDelimited_1.get(columnIndexWithD_tFileInputDelimited_1);

							columnIndexWithD_tFileInputDelimited_1 = 7;

							row2.date_deces = fid_tFileInputDelimited_1.get(columnIndexWithD_tFileInputDelimited_1);

							columnIndexWithD_tFileInputDelimited_1 = 8;

							row2.code_lieu_deces = fid_tFileInputDelimited_1
									.get(columnIndexWithD_tFileInputDelimited_1);

							columnIndexWithD_tFileInputDelimited_1 = 9;

							row2.numero_acte_deces = fid_tFileInputDelimited_1
									.get(columnIndexWithD_tFileInputDelimited_1);

							if (rowstate_tFileInputDelimited_1.getException() != null) {
								throw rowstate_tFileInputDelimited_1.getException();
							}

						} catch (java.lang.Exception e) {
							whetherReject_tFileInputDelimited_1 = true;

							System.err.println(e.getMessage());
							row2 = null;

						}

						/**
						 * [tFileInputDelimited_1 begin ] stop
						 */

						/**
						 * [tFileInputDelimited_1 main ] start
						 */

						currentComponent = "tFileInputDelimited_1";

						tos_count_tFileInputDelimited_1++;

						/**
						 * [tFileInputDelimited_1 main ] stop
						 */

						/**
						 * [tFileInputDelimited_1 process_data_begin ] start
						 */

						currentComponent = "tFileInputDelimited_1";

						/**
						 * [tFileInputDelimited_1 process_data_begin ] stop
						 */
// Start of branch "row2"
						if (row2 != null) {

							/**
							 * [tMap_1 main ] start
							 */

							currentComponent = "tMap_1";

							if (execStat) {
								runStat.updateStatOnConnection(iterateId, 1, 1, "row2");
							}

							boolean hasCasePrimitiveKeyWithNull_tMap_1 = false;

							// ###############################
							// # Input tables (lookups)
							boolean rejectedInnerJoin_tMap_1 = false;
							boolean mainRowRejected_tMap_1 = false;

							// ###############################
							{ // start of Var scope

								// ###############################
								// # Vars tables

								Var__tMap_1__Struct Var = Var__tMap_1;// ###############################
								// ###############################
								// # Output tables

								date_naissance_output = null;

// # Output table : 'date_naissance_output'
								date_naissance_output_tmp.Date = row2.date_naissance == null
										|| row2.date_naissance.trim().isEmpty()
												? null
												: (!row2.date_naissance.replaceAll("/", "-")
														.matches("^\\d{4}-\\d{2}-\\d{2}$")
																? (row2.date_naissance.replaceAll("-", "/")
																		.matches("^\\d{4}$")
																				? TalendDate.parseDate("yyyy-MM-dd",
																						row2.date_naissance.replaceAll(
																								"/", "-") + "-01-01")
																				: (row2.date_naissance
																						.replaceAll("-", "/")
																						.matches("^\\d{4}/\\d{2}$")
																								? TalendDate.parseDate(
																										"yyyy-MM-dd",
																										row2.date_naissance
																												.replaceAll(
																														"/",
																														"-")
																												+ "-01")
																								: null))
																: TalendDate.parseDate("yyyy-MM-dd",
																		row2.date_naissance.replaceAll("/", "-")));
								date_naissance_output = date_naissance_output_tmp;
// ###############################

							} // end of Var scope

							rejectedInnerJoin_tMap_1 = false;

							tos_count_tMap_1++;

							/**
							 * [tMap_1 main ] stop
							 */

							/**
							 * [tMap_1 process_data_begin ] start
							 */

							currentComponent = "tMap_1";

							/**
							 * [tMap_1 process_data_begin ] stop
							 */
// Start of branch "date_naissance_output"
							if (date_naissance_output != null) {

								/**
								 * [tUnite_1 main ] start
								 */

								currentComponent = "tUnite_1";

								if (execStat) {
									runStat.updateStatOnConnection(iterateId, 1, 1, "date_naissance_output");
								}

//////////

// for output
								row4 = new row4Struct();

								row4.Date = date_naissance_output.Date;

								nb_line_tUnite_1++;

//////////

								tos_count_tUnite_1++;

								/**
								 * [tUnite_1 main ] stop
								 */

								/**
								 * [tUnite_1 process_data_begin ] start
								 */

								currentComponent = "tUnite_1";

								/**
								 * [tUnite_1 process_data_begin ] stop
								 */

								/**
								 * [tUniqRow_1 main ] start
								 */

								currentComponent = "tUniqRow_1";

								if (execStat) {
									runStat.updateStatOnConnection(iterateId, 1, 1, "row4");
								}

								row5.Date = row4.Date;

								tos_count_tUniqRow_1++;

								/**
								 * [tUniqRow_1 main ] stop
								 */

								/**
								 * [tUniqRow_1 process_data_begin ] start
								 */

								currentComponent = "tUniqRow_1";

								/**
								 * [tUniqRow_1 process_data_begin ] stop
								 */
// Start of branch "row5"
								if (row5 != null) {

									/**
									 * [tMap_2 main ] start
									 */

									currentComponent = "tMap_2";

									if (execStat) {
										runStat.updateStatOnConnection(iterateId, 1, 1, "row5");
									}

									boolean hasCasePrimitiveKeyWithNull_tMap_2 = false;

									// ###############################
									// # Input tables (lookups)
									boolean rejectedInnerJoin_tMap_2 = false;
									boolean mainRowRejected_tMap_2 = false;

									// ###############################
									{ // start of Var scope

										// ###############################
										// # Vars tables

										Var__tMap_2__Struct Var = Var__tMap_2;// ###############################
										// ###############################
										// # Output tables

										d_dates_output = null;

// # Output table : 'd_dates_output'
										d_dates_output_tmp.Id_date = Numeric.sequence("id_seq", 1, 1);
										d_dates_output_tmp.Date = row5.Date;
										d_dates_output_tmp.Year = TalendDate.getPartOfDate("YEAR", row5.Date);
										d_dates_output = d_dates_output_tmp;
// ###############################

									} // end of Var scope

									rejectedInnerJoin_tMap_2 = false;

									tos_count_tMap_2++;

									/**
									 * [tMap_2 main ] stop
									 */

									/**
									 * [tMap_2 process_data_begin ] start
									 */

									currentComponent = "tMap_2";

									/**
									 * [tMap_2 process_data_begin ] stop
									 */
// Start of branch "d_dates_output"
									if (d_dates_output != null) {

										/**
										 * [tLogRow_1 main ] start
										 */

										currentComponent = "tLogRow_1";

										if (execStat) {
											runStat.updateStatOnConnection(iterateId, 1, 1, "d_dates_output");
										}

///////////////////////		

										strBuffer_tLogRow_1 = new StringBuilder();

										strBuffer_tLogRow_1.append(String.valueOf(d_dates_output.Id_date));

										strBuffer_tLogRow_1.append("|");

										if (d_dates_output.Date != null) { //

											strBuffer_tLogRow_1.append(
													FormatterUtils.format_Date(d_dates_output.Date, "yyyy-MM-dd"));

										} //

										strBuffer_tLogRow_1.append("|");

										strBuffer_tLogRow_1.append(String.valueOf(d_dates_output.Year));

										if (globalMap.get("tLogRow_CONSOLE") != null) {
											consoleOut_tLogRow_1 = (java.io.PrintStream) globalMap
													.get("tLogRow_CONSOLE");
										} else {
											consoleOut_tLogRow_1 = new java.io.PrintStream(
													new java.io.BufferedOutputStream(System.out));
											globalMap.put("tLogRow_CONSOLE", consoleOut_tLogRow_1);
										}
										consoleOut_tLogRow_1.println(strBuffer_tLogRow_1.toString());
										consoleOut_tLogRow_1.flush();
										nb_line_tLogRow_1++;
//////

//////                    

///////////////////////    			

										tos_count_tLogRow_1++;

										/**
										 * [tLogRow_1 main ] stop
										 */

										/**
										 * [tLogRow_1 process_data_begin ] start
										 */

										currentComponent = "tLogRow_1";

										/**
										 * [tLogRow_1 process_data_begin ] stop
										 */

										/**
										 * [tLogRow_1 process_data_end ] start
										 */

										currentComponent = "tLogRow_1";

										/**
										 * [tLogRow_1 process_data_end ] stop
										 */

									} // End of branch "d_dates_output"

									/**
									 * [tMap_2 process_data_end ] start
									 */

									currentComponent = "tMap_2";

									/**
									 * [tMap_2 process_data_end ] stop
									 */

								} // End of branch "row5"

								/**
								 * [tUniqRow_1 process_data_end ] start
								 */

								currentComponent = "tUniqRow_1";

								/**
								 * [tUniqRow_1 process_data_end ] stop
								 */

								/**
								 * [tUnite_1 process_data_end ] start
								 */

								currentComponent = "tUnite_1";

								/**
								 * [tUnite_1 process_data_end ] stop
								 */

							} // End of branch "date_naissance_output"

							/**
							 * [tMap_1 process_data_end ] start
							 */

							currentComponent = "tMap_1";

							/**
							 * [tMap_1 process_data_end ] stop
							 */

						} // End of branch "row2"

						/**
						 * [tFileInputDelimited_1 process_data_end ] start
						 */

						currentComponent = "tFileInputDelimited_1";

						/**
						 * [tFileInputDelimited_1 process_data_end ] stop
						 */

						/**
						 * [tFileInputDelimited_1 end ] start
						 */

						currentComponent = "tFileInputDelimited_1";

					}
				} finally {
					if (!((Object) (context.INPUT_PATH + "deces.csv") instanceof java.io.InputStream)) {
						if (fid_tFileInputDelimited_1 != null) {
							fid_tFileInputDelimited_1.close();
						}
					}
					if (fid_tFileInputDelimited_1 != null) {
						globalMap.put("tFileInputDelimited_1_NB_LINE", fid_tFileInputDelimited_1.getRowNumber());

					}
				}

				ok_Hash.put("tFileInputDelimited_1", true);
				end_Hash.put("tFileInputDelimited_1", System.currentTimeMillis());

				/**
				 * [tFileInputDelimited_1 end ] stop
				 */

				/**
				 * [tMap_1 end ] start
				 */

				currentComponent = "tMap_1";

// ###############################
// # Lookup hashes releasing
// ###############################      

				if (execStat) {
					runStat.updateStat(resourceMap, iterateId, 2, 0, "row2");
				}

				ok_Hash.put("tMap_1", true);
				end_Hash.put("tMap_1", System.currentTimeMillis());

				/**
				 * [tMap_1 end ] stop
				 */

				/**
				 * [tUnite_1 end ] start
				 */

				currentComponent = "tUnite_1";

				globalMap.put("tUnite_1_NB_LINE", nb_line_tUnite_1);
				if (execStat) {
					runStat.updateStat(resourceMap, iterateId, 2, 0, "row1", "dates_hospitalization_output",
							"date_naissance_output");
				}

				ok_Hash.put("tUnite_1", true);
				end_Hash.put("tUnite_1", System.currentTimeMillis());

				/**
				 * [tUnite_1 end ] stop
				 */

				/**
				 * [tUniqRow_1 end ] start
				 */

				currentComponent = "tUniqRow_1";

				globalMap.put("tUniqRow_1_NB_UNIQUES", nb_uniques_tUniqRow_1);
				globalMap.put("tUniqRow_1_NB_DUPLICATES", nb_duplicates_tUniqRow_1);

				if (execStat) {
					runStat.updateStat(resourceMap, iterateId, 2, 0, "row4");
				}

				ok_Hash.put("tUniqRow_1", true);
				end_Hash.put("tUniqRow_1", System.currentTimeMillis());

				/**
				 * [tUniqRow_1 end ] stop
				 */

				/**
				 * [tMap_2 end ] start
				 */

				currentComponent = "tMap_2";

// ###############################
// # Lookup hashes releasing
// ###############################      

				if (execStat) {
					runStat.updateStat(resourceMap, iterateId, 2, 0, "row5");
				}

				ok_Hash.put("tMap_2", true);
				end_Hash.put("tMap_2", System.currentTimeMillis());

				/**
				 * [tMap_2 end ] stop
				 */

				/**
				 * [tLogRow_1 end ] start
				 */

				currentComponent = "tLogRow_1";

//////
//////
				globalMap.put("tLogRow_1_NB_LINE", nb_line_tLogRow_1);

///////////////////////    			

				if (execStat) {
					runStat.updateStat(resourceMap, iterateId, 2, 0, "d_dates_output");
				}

				ok_Hash.put("tLogRow_1", true);
				end_Hash.put("tLogRow_1", System.currentTimeMillis());

				/**
				 * [tLogRow_1 end ] stop
				 */

			} // end the resume

		} catch (java.lang.Exception e) {

			TalendException te = new TalendException(e, currentComponent, globalMap);

			throw te;
		} catch (java.lang.Error error) {

			runStat.stopThreadStat();

			throw error;
		} finally {

			try {

				/**
				 * [tDBInput_1 finally ] start
				 */

				currentComponent = "tDBInput_1";

				/**
				 * [tDBInput_1 finally ] stop
				 */

				/**
				 * [tFileInputDelimited_2 finally ] start
				 */

				currentComponent = "tFileInputDelimited_2";

				/**
				 * [tFileInputDelimited_2 finally ] stop
				 */

				/**
				 * [tMap_3 finally ] start
				 */

				currentComponent = "tMap_3";

				/**
				 * [tMap_3 finally ] stop
				 */

				/**
				 * [tFileInputDelimited_1 finally ] start
				 */

				currentComponent = "tFileInputDelimited_1";

				/**
				 * [tFileInputDelimited_1 finally ] stop
				 */

				/**
				 * [tMap_1 finally ] start
				 */

				currentComponent = "tMap_1";

				/**
				 * [tMap_1 finally ] stop
				 */

				/**
				 * [tUnite_1 finally ] start
				 */

				currentComponent = "tUnite_1";

				/**
				 * [tUnite_1 finally ] stop
				 */

				/**
				 * [tUniqRow_1 finally ] start
				 */

				currentComponent = "tUniqRow_1";

				/**
				 * [tUniqRow_1 finally ] stop
				 */

				/**
				 * [tMap_2 finally ] start
				 */

				currentComponent = "tMap_2";

				/**
				 * [tMap_2 finally ] stop
				 */

				/**
				 * [tLogRow_1 finally ] start
				 */

				currentComponent = "tLogRow_1";

				/**
				 * [tLogRow_1 finally ] stop
				 */

			} catch (java.lang.Exception e) {
				// ignore
			} catch (java.lang.Error error) {
				// ignore
			}
			resourceMap = null;
		}

		globalMap.put("tDBInput_1_SUBPROCESS_STATE", 1);
	}

	public void tHDFSOutput_1Process(final java.util.Map<String, Object> globalMap) throws TalendException {
		globalMap.put("tHDFSOutput_1_SUBPROCESS_STATE", 0);

		final boolean execStat = this.execStat;

		String iterateId = "";

		String currentComponent = "";
		java.util.Map<String, Object> resourceMap = new java.util.HashMap<String, Object>();

		try {
			// TDI-39566 avoid throwing an useless Exception
			boolean resumeIt = true;
			if (globalResumeTicket == false && resumeEntryMethodName != null) {
				String currentMethodName = new java.lang.Exception().getStackTrace()[0].getMethodName();
				resumeIt = resumeEntryMethodName.equals(currentMethodName);
			}
			if (resumeIt || globalResumeTicket) { // start the resume
				globalResumeTicket = true;

				/**
				 * [tHDFSOutput_1 begin ] start
				 */

				ok_Hash.put("tHDFSOutput_1", false);
				start_Hash.put("tHDFSOutput_1", System.currentTimeMillis());

				currentComponent = "tHDFSOutput_1";

				int tos_count_tHDFSOutput_1 = 0;

				String username_tHDFSOutput_1 = "";
				org.apache.hadoop.fs.FileSystem fs_tHDFSOutput_1 = null;
				org.apache.hadoop.conf.Configuration conf_tHDFSOutput_1 = new org.apache.hadoop.conf.Configuration();

				conf_tHDFSOutput_1.set("fs.default.name", context.ClusterHadopp_NameNodeUri);

				conf_tHDFSOutput_1.set("dfs.client.use.datanode.hostname", "true");

				org.apache.hadoop.security.UserGroupInformation.setConfiguration(conf_tHDFSOutput_1);
				username_tHDFSOutput_1 = "cloudera";
				if (username_tHDFSOutput_1 == null || "".equals(username_tHDFSOutput_1)) {
					fs_tHDFSOutput_1 = org.apache.hadoop.fs.FileSystem.get(conf_tHDFSOutput_1);
				} else {
					System.setProperty("HADOOP_USER_NAME", username_tHDFSOutput_1);
					fs_tHDFSOutput_1 = org.apache.hadoop.fs.FileSystem.get(
							new java.net.URI(conf_tHDFSOutput_1.get("fs.default.name")), conf_tHDFSOutput_1,
							username_tHDFSOutput_1);
				}

				/**
				 * [tHDFSOutput_1 begin ] stop
				 */

				/**
				 * [tHDFSOutput_1 main ] start
				 */

				currentComponent = "tHDFSOutput_1";

				tos_count_tHDFSOutput_1++;

				/**
				 * [tHDFSOutput_1 main ] stop
				 */

				/**
				 * [tHDFSOutput_1 process_data_begin ] start
				 */

				currentComponent = "tHDFSOutput_1";

				/**
				 * [tHDFSOutput_1 process_data_begin ] stop
				 */

				/**
				 * [tHDFSOutput_1 process_data_end ] start
				 */

				currentComponent = "tHDFSOutput_1";

				/**
				 * [tHDFSOutput_1 process_data_end ] stop
				 */

				/**
				 * [tHDFSOutput_1 end ] start
				 */

				currentComponent = "tHDFSOutput_1";

				ok_Hash.put("tHDFSOutput_1", true);
				end_Hash.put("tHDFSOutput_1", System.currentTimeMillis());

				if (execStat) {
					runStat.updateStatOnConnection("OnComponentOk1", 0, "ok");
				}
				tHiveCreateTable_1Process(globalMap);

				/**
				 * [tHDFSOutput_1 end ] stop
				 */
			} // end the resume

		} catch (java.lang.Exception e) {

			TalendException te = new TalendException(e, currentComponent, globalMap);

			throw te;
		} catch (java.lang.Error error) {

			runStat.stopThreadStat();

			throw error;
		} finally {

			try {

				/**
				 * [tHDFSOutput_1 finally ] start
				 */

				currentComponent = "tHDFSOutput_1";

				/**
				 * [tHDFSOutput_1 finally ] stop
				 */
			} catch (java.lang.Exception e) {
				// ignore
			} catch (java.lang.Error error) {
				// ignore
			}
			resourceMap = null;
		}

		globalMap.put("tHDFSOutput_1_SUBPROCESS_STATE", 1);
	}

	public void tHiveCreateTable_1Process(final java.util.Map<String, Object> globalMap) throws TalendException {
		globalMap.put("tHiveCreateTable_1_SUBPROCESS_STATE", 0);

		final boolean execStat = this.execStat;

		String iterateId = "";

		String currentComponent = "";
		java.util.Map<String, Object> resourceMap = new java.util.HashMap<String, Object>();

		try {
			// TDI-39566 avoid throwing an useless Exception
			boolean resumeIt = true;
			if (globalResumeTicket == false && resumeEntryMethodName != null) {
				String currentMethodName = new java.lang.Exception().getStackTrace()[0].getMethodName();
				resumeIt = resumeEntryMethodName.equals(currentMethodName);
			}
			if (resumeIt || globalResumeTicket) { // start the resume
				globalResumeTicket = true;

				/**
				 * [tHiveCreateTable_1 begin ] start
				 */

				ok_Hash.put("tHiveCreateTable_1", false);
				start_Hash.put("tHiveCreateTable_1", System.currentTimeMillis());

				currentComponent = "tHiveCreateTable_1";

				int tos_count_tHiveCreateTable_1 = 0;

				/**
				 * [tHiveCreateTable_1 begin ] stop
				 */

				/**
				 * [tHiveCreateTable_1 main ] start
				 */

				currentComponent = "tHiveCreateTable_1";

				java.sql.Connection conn_tHiveCreateTable_1 = null;
				globalMap.put("current_client_path_separator", System.getProperty("path.separator"));
				System.setProperty("path.separator", ":");
				String dbUser_tHiveCreateTable_1 = "cloudera";

				final String decryptedPassword_tHiveCreateTable_1 = routines.system.PasswordEncryptUtil
						.decryptPassword("enc:routine.encryption.key.v1:o9W/2MlCdWNeTl9cGIGXJgvqFCQk4UpGnVw8YQ==");

				String dbPwd_tHiveCreateTable_1 = decryptedPassword_tHiveCreateTable_1;

				globalMap.put("HADOOP_USER_NAME_tHiveCreateTable_1", System.getProperty("HADOOP_USER_NAME"));
				String url_tHiveCreateTable_1 = "jdbc:hive2://" + "quickstart.cloudera" + ":" + "10000" + "/" + "chu";
				String additionalJdbcSettings_tHiveCreateTable_1 = "";
				if (!"".equals(additionalJdbcSettings_tHiveCreateTable_1.trim())) {
					if (!additionalJdbcSettings_tHiveCreateTable_1.startsWith(";")) {
						additionalJdbcSettings_tHiveCreateTable_1 = ";" + additionalJdbcSettings_tHiveCreateTable_1;
					}
					url_tHiveCreateTable_1 += additionalJdbcSettings_tHiveCreateTable_1;
				}
				String driverClass_tHiveCreateTable_1 = "org.apache.hive.jdbc.HiveDriver";
				java.lang.Class.forName(driverClass_tHiveCreateTable_1);

				conn_tHiveCreateTable_1 = java.sql.DriverManager.getConnection(url_tHiveCreateTable_1,
						dbUser_tHiveCreateTable_1, dbPwd_tHiveCreateTable_1);

				java.sql.Statement init_tHiveCreateTable_1 = conn_tHiveCreateTable_1.createStatement();
				init_tHiveCreateTable_1.execute("SET dfs.client.use.datanode.hostname=true");

				init_tHiveCreateTable_1.close();

				String dbname_tHiveCreateTable_1 = "chu";
				if (dbname_tHiveCreateTable_1 != null && !"".equals(dbname_tHiveCreateTable_1.trim())
						&& !"default".equals(dbname_tHiveCreateTable_1.trim())) {
					java.sql.Statement goToDatabase_tHiveCreateTable_1 = conn_tHiveCreateTable_1.createStatement();
					goToDatabase_tHiveCreateTable_1.execute("use " + dbname_tHiveCreateTable_1);
					goToDatabase_tHiveCreateTable_1.close();
				}

				java.sql.Statement stmt_tHiveCreateTable_1 = conn_tHiveCreateTable_1.createStatement();
				String query_tHiveCreateTable_1 = "";
				String tableName_tHiveCreateTable_1 = "d_dates";
				String fieldChar_tHiveCreateTable_1 = ";";
				String location_tHiveCreateTable_1 = "/user/talend/output/";
				String querySQL_tHiveCreateTable_1 = "CREATE  TABLE IF NOT EXISTS " + tableName_tHiveCreateTable_1
						+ "(Id_date INT,Date TIMESTAMP,Year INT) ROW FORMAT DELIMITED  FIELDS TERMINATED BY '"
						+ fieldChar_tHiveCreateTable_1 + "' STORED AS TEXTFILE LOCATION '" + location_tHiveCreateTable_1
						+ "'";
				try {

					java.text.DateFormat dateStrFormat_tHiveCreateTable_1 = new java.text.SimpleDateFormat(
							"yyyyMMddHHmmss");
					final String queryIdentifier_tHiveCreateTable_1 = projectName + "_" + jobName + "_"
							+ jobVersion.replace(".", "_") + "_tHiveCreateTable_1_"
							+ dateStrFormat_tHiveCreateTable_1.format(new Date(startTime));
// For MapReduce Mode
					stmt_tHiveCreateTable_1.execute("set mapred.job.name=" + queryIdentifier_tHiveCreateTable_1);
					stmt_tHiveCreateTable_1.execute(querySQL_tHiveCreateTable_1);
				} catch (java.sql.SQLException e_tHiveCreateTable_1) {
					System.err.println(e_tHiveCreateTable_1.getMessage());
				}
				stmt_tHiveCreateTable_1.close();

				conn_tHiveCreateTable_1.close();

				globalMap.put("tHiveCreateTable_1_QUERY", querySQL_tHiveCreateTable_1);

				String currentClientPathSeparator_tHiveCreateTable_1 = (String) globalMap
						.get("current_client_path_separator");
				if (currentClientPathSeparator_tHiveCreateTable_1 != null) {
					System.setProperty("path.separator", currentClientPathSeparator_tHiveCreateTable_1);
					globalMap.put("current_client_path_separator", null);
				}

				String currentClientUsername_tHiveCreateTable_1 = (String) globalMap.get("current_client_user_name");
				if (currentClientUsername_tHiveCreateTable_1 != null) {
					System.setProperty("user.name", currentClientUsername_tHiveCreateTable_1);
					globalMap.put("current_client_user_name", null);
				}

				String originalHadoopUsername_tHiveCreateTable_1 = (String) globalMap
						.get("HADOOP_USER_NAME_tHiveCreateTable_1");
				if (originalHadoopUsername_tHiveCreateTable_1 != null) {
					System.setProperty("HADOOP_USER_NAME", originalHadoopUsername_tHiveCreateTable_1);
					globalMap.put("HADOOP_USER_NAME_tHiveCreateTable_1", null);
				} else {
					System.clearProperty("HADOOP_USER_NAME");
				}

				tos_count_tHiveCreateTable_1++;

				/**
				 * [tHiveCreateTable_1 main ] stop
				 */

				/**
				 * [tHiveCreateTable_1 process_data_begin ] start
				 */

				currentComponent = "tHiveCreateTable_1";

				/**
				 * [tHiveCreateTable_1 process_data_begin ] stop
				 */

				/**
				 * [tHiveCreateTable_1 process_data_end ] start
				 */

				currentComponent = "tHiveCreateTable_1";

				/**
				 * [tHiveCreateTable_1 process_data_end ] stop
				 */

				/**
				 * [tHiveCreateTable_1 end ] start
				 */

				currentComponent = "tHiveCreateTable_1";

				ok_Hash.put("tHiveCreateTable_1", true);
				end_Hash.put("tHiveCreateTable_1", System.currentTimeMillis());

				/**
				 * [tHiveCreateTable_1 end ] stop
				 */
			} // end the resume

		} catch (java.lang.Exception e) {

			TalendException te = new TalendException(e, currentComponent, globalMap);

			throw te;
		} catch (java.lang.Error error) {

			runStat.stopThreadStat();

			throw error;
		} finally {

			try {

				/**
				 * [tHiveCreateTable_1 finally ] start
				 */

				currentComponent = "tHiveCreateTable_1";

				/**
				 * [tHiveCreateTable_1 finally ] stop
				 */
			} catch (java.lang.Exception e) {
				// ignore
			} catch (java.lang.Error error) {
				// ignore
			}
			resourceMap = null;
		}

		globalMap.put("tHiveCreateTable_1_SUBPROCESS_STATE", 1);
	}

	public void tHadoopConfManager_tHDFSOutput_1Process(final java.util.Map<String, Object> globalMap)
			throws TalendException {
		globalMap.put("tHadoopConfManager_tHDFSOutput_1_SUBPROCESS_STATE", 0);

		final boolean execStat = this.execStat;

		String iterateId = "";

		String currentComponent = "";
		java.util.Map<String, Object> resourceMap = new java.util.HashMap<String, Object>();

		try {
			// TDI-39566 avoid throwing an useless Exception
			boolean resumeIt = true;
			if (globalResumeTicket == false && resumeEntryMethodName != null) {
				String currentMethodName = new java.lang.Exception().getStackTrace()[0].getMethodName();
				resumeIt = resumeEntryMethodName.equals(currentMethodName);
			}
			if (resumeIt || globalResumeTicket) { // start the resume
				globalResumeTicket = true;

				/**
				 * [tHadoopConfManager_tHDFSOutput_1 begin ] start
				 */

				ok_Hash.put("tHadoopConfManager_tHDFSOutput_1", false);
				start_Hash.put("tHadoopConfManager_tHDFSOutput_1", System.currentTimeMillis());

				currentComponent = "tHadoopConfManager_tHDFSOutput_1";

				int tos_count_tHadoopConfManager_tHDFSOutput_1 = 0;

				String libPath_tHadoopConfManager_tHDFSOutput_1 = "";

				class DealJobLibrary_tHadoopConfManager_tHDFSOutput_1 {

					public String getConfJarName(String confLib, String extraId) {
						String confJarName = confLib;
						if (extraId != null && extraId.length() > 0) {
							String jarName = confLib.substring(0, confLib.lastIndexOf("."));
							String jarExt = confLib.substring(confLib.lastIndexOf("."));
							confJarName = jarName + "_" + extraId + jarExt;
						}
						return confJarName;
					}

					public String replaceJarPathsFromCrcMap(String originalClassPathLine) throws java.lang.Exception {
						String classPathLine = "";
						String crcMapPath = new java.io.File("../crcMap").getCanonicalPath();
						if (isNeedAddLibsPath(crcMapPath)) {
							java.util.Map<String, String> crcMap = null;
							java.io.ObjectInputStream ois = new java.io.ObjectInputStream(
									new java.io.FileInputStream(crcMapPath));
							crcMap = (java.util.Map<String, String>) ois.readObject();
							ois.close();
							classPathLine = addLibsPath(originalClassPathLine, crcMap);
						} else {
							classPathLine = originalClassPathLine;
						}
						return classPathLine;
					}

					private boolean isNeedAddLibsPath(String crcMapPath) {
						if (!(new java.io.File(crcMapPath).exists())) {// when not use cache
							return false;
						}
						return true;
					}

					private String addLibsPath(String line, java.util.Map<String, String> crcMap) {
						for (java.util.Map.Entry<String, String> entry : crcMap.entrySet()) {
							line = adaptLibPaths(line, entry);
						}
						return line;
					}

					private String adaptLibPaths(String line, java.util.Map.Entry<String, String> entry) {
						String jarName = entry.getValue();
						String crc = entry.getKey();
						String libStringFinder = "../lib/" + jarName;
						if (line.contains(libStringFinder)) {
							line = line.replace(libStringFinder, "../../../cache/lib/" + crc + "/" + jarName);
						} else if (line.contains(":$ROOT_PATH/" + jarName + ":")) {
							line = line.replace(":$ROOT_PATH/" + jarName + ":",
									":$ROOT_PATH/../../../cache/lib/" + crc + "/" + jarName + ":");
						} else if (line.contains(";" + jarName + ";")) {
							line = line.replace(";" + jarName + ";",
									";../../../cache/lib/" + crc + "/" + jarName + ";");
						}
						return line;
					}

				}

				DealJobLibrary_tHadoopConfManager_tHDFSOutput_1 dealJobLibrary = new DealJobLibrary_tHadoopConfManager_tHDFSOutput_1();
				String confJarName = dealJobLibrary.getConfJarName("hadoop-conf-ClusterHadopp.jar", this.contextStr);

				libPath_tHadoopConfManager_tHDFSOutput_1 = new java.io.File(
						"D:/Big data/ProjectBigData-GRP6/ETL project/ETL_PROJECT/temp/lib/" + confJarName)
								.getAbsolutePath();
				libPath_tHadoopConfManager_tHDFSOutput_1 = dealJobLibrary
						.replaceJarPathsFromCrcMap(libPath_tHadoopConfManager_tHDFSOutput_1);

				java.net.URLClassLoader currentLoadertHadoopConfManager_tHDFSOutput_1 = (java.net.URLClassLoader) Thread
						.currentThread().getContextClassLoader();
				java.lang.reflect.Method method_tHadoopConfManager_tHDFSOutput_1 = java.net.URLClassLoader.class
						.getDeclaredMethod("addURL", new Class[] { java.net.URL.class });
				method_tHadoopConfManager_tHDFSOutput_1.setAccessible(true);
				method_tHadoopConfManager_tHDFSOutput_1.invoke(currentLoadertHadoopConfManager_tHDFSOutput_1,
						new Object[] { new java.io.File(libPath_tHadoopConfManager_tHDFSOutput_1).toURL() });

				/**
				 * [tHadoopConfManager_tHDFSOutput_1 begin ] stop
				 */

				/**
				 * [tHadoopConfManager_tHDFSOutput_1 main ] start
				 */

				currentComponent = "tHadoopConfManager_tHDFSOutput_1";

				tos_count_tHadoopConfManager_tHDFSOutput_1++;

				/**
				 * [tHadoopConfManager_tHDFSOutput_1 main ] stop
				 */

				/**
				 * [tHadoopConfManager_tHDFSOutput_1 process_data_begin ] start
				 */

				currentComponent = "tHadoopConfManager_tHDFSOutput_1";

				/**
				 * [tHadoopConfManager_tHDFSOutput_1 process_data_begin ] stop
				 */

				/**
				 * [tHadoopConfManager_tHDFSOutput_1 process_data_end ] start
				 */

				currentComponent = "tHadoopConfManager_tHDFSOutput_1";

				/**
				 * [tHadoopConfManager_tHDFSOutput_1 process_data_end ] stop
				 */

				/**
				 * [tHadoopConfManager_tHDFSOutput_1 end ] start
				 */

				currentComponent = "tHadoopConfManager_tHDFSOutput_1";

				ok_Hash.put("tHadoopConfManager_tHDFSOutput_1", true);
				end_Hash.put("tHadoopConfManager_tHDFSOutput_1", System.currentTimeMillis());

				/**
				 * [tHadoopConfManager_tHDFSOutput_1 end ] stop
				 */
			} // end the resume

		} catch (java.lang.Exception e) {

			TalendException te = new TalendException(e, currentComponent, globalMap);

			throw te;
		} catch (java.lang.Error error) {

			runStat.stopThreadStat();

			throw error;
		} finally {

			try {

				/**
				 * [tHadoopConfManager_tHDFSOutput_1 finally ] start
				 */

				currentComponent = "tHadoopConfManager_tHDFSOutput_1";

				/**
				 * [tHadoopConfManager_tHDFSOutput_1 finally ] stop
				 */
			} catch (java.lang.Exception e) {
				// ignore
			} catch (java.lang.Error error) {
				// ignore
			}
			resourceMap = null;
		}

		globalMap.put("tHadoopConfManager_tHDFSOutput_1_SUBPROCESS_STATE", 1);
	}

	public void tHadoopConfManager_tHiveCreateTable_1Process(final java.util.Map<String, Object> globalMap)
			throws TalendException {
		globalMap.put("tHadoopConfManager_tHiveCreateTable_1_SUBPROCESS_STATE", 0);

		final boolean execStat = this.execStat;

		String iterateId = "";

		String currentComponent = "";
		java.util.Map<String, Object> resourceMap = new java.util.HashMap<String, Object>();

		try {
			// TDI-39566 avoid throwing an useless Exception
			boolean resumeIt = true;
			if (globalResumeTicket == false && resumeEntryMethodName != null) {
				String currentMethodName = new java.lang.Exception().getStackTrace()[0].getMethodName();
				resumeIt = resumeEntryMethodName.equals(currentMethodName);
			}
			if (resumeIt || globalResumeTicket) { // start the resume
				globalResumeTicket = true;

				/**
				 * [tHadoopConfManager_tHiveCreateTable_1 begin ] start
				 */

				ok_Hash.put("tHadoopConfManager_tHiveCreateTable_1", false);
				start_Hash.put("tHadoopConfManager_tHiveCreateTable_1", System.currentTimeMillis());

				currentComponent = "tHadoopConfManager_tHiveCreateTable_1";

				int tos_count_tHadoopConfManager_tHiveCreateTable_1 = 0;

				String libPath_tHadoopConfManager_tHiveCreateTable_1 = "";

				class DealJobLibrary_tHadoopConfManager_tHiveCreateTable_1 {

					public String getConfJarName(String confLib, String extraId) {
						String confJarName = confLib;
						if (extraId != null && extraId.length() > 0) {
							String jarName = confLib.substring(0, confLib.lastIndexOf("."));
							String jarExt = confLib.substring(confLib.lastIndexOf("."));
							confJarName = jarName + "_" + extraId + jarExt;
						}
						return confJarName;
					}

					public String replaceJarPathsFromCrcMap(String originalClassPathLine) throws java.lang.Exception {
						String classPathLine = "";
						String crcMapPath = new java.io.File("../crcMap").getCanonicalPath();
						if (isNeedAddLibsPath(crcMapPath)) {
							java.util.Map<String, String> crcMap = null;
							java.io.ObjectInputStream ois = new java.io.ObjectInputStream(
									new java.io.FileInputStream(crcMapPath));
							crcMap = (java.util.Map<String, String>) ois.readObject();
							ois.close();
							classPathLine = addLibsPath(originalClassPathLine, crcMap);
						} else {
							classPathLine = originalClassPathLine;
						}
						return classPathLine;
					}

					private boolean isNeedAddLibsPath(String crcMapPath) {
						if (!(new java.io.File(crcMapPath).exists())) {// when not use cache
							return false;
						}
						return true;
					}

					private String addLibsPath(String line, java.util.Map<String, String> crcMap) {
						for (java.util.Map.Entry<String, String> entry : crcMap.entrySet()) {
							line = adaptLibPaths(line, entry);
						}
						return line;
					}

					private String adaptLibPaths(String line, java.util.Map.Entry<String, String> entry) {
						String jarName = entry.getValue();
						String crc = entry.getKey();
						String libStringFinder = "../lib/" + jarName;
						if (line.contains(libStringFinder)) {
							line = line.replace(libStringFinder, "../../../cache/lib/" + crc + "/" + jarName);
						} else if (line.contains(":$ROOT_PATH/" + jarName + ":")) {
							line = line.replace(":$ROOT_PATH/" + jarName + ":",
									":$ROOT_PATH/../../../cache/lib/" + crc + "/" + jarName + ":");
						} else if (line.contains(";" + jarName + ";")) {
							line = line.replace(";" + jarName + ";",
									";../../../cache/lib/" + crc + "/" + jarName + ";");
						}
						return line;
					}

				}

				DealJobLibrary_tHadoopConfManager_tHiveCreateTable_1 dealJobLibrary = new DealJobLibrary_tHadoopConfManager_tHiveCreateTable_1();
				String confJarName = dealJobLibrary.getConfJarName("hadoop-conf-ClusterHadopp.jar", this.contextStr);

				libPath_tHadoopConfManager_tHiveCreateTable_1 = new java.io.File(
						"D:/Big data/ProjectBigData-GRP6/ETL project/ETL_PROJECT/temp/lib/" + confJarName)
								.getAbsolutePath();
				libPath_tHadoopConfManager_tHiveCreateTable_1 = dealJobLibrary
						.replaceJarPathsFromCrcMap(libPath_tHadoopConfManager_tHiveCreateTable_1);

				java.net.URLClassLoader currentLoadertHadoopConfManager_tHiveCreateTable_1 = (java.net.URLClassLoader) Thread
						.currentThread().getContextClassLoader();
				java.lang.reflect.Method method_tHadoopConfManager_tHiveCreateTable_1 = java.net.URLClassLoader.class
						.getDeclaredMethod("addURL", new Class[] { java.net.URL.class });
				method_tHadoopConfManager_tHiveCreateTable_1.setAccessible(true);
				method_tHadoopConfManager_tHiveCreateTable_1.invoke(currentLoadertHadoopConfManager_tHiveCreateTable_1,
						new Object[] { new java.io.File(libPath_tHadoopConfManager_tHiveCreateTable_1).toURL() });

				/**
				 * [tHadoopConfManager_tHiveCreateTable_1 begin ] stop
				 */

				/**
				 * [tHadoopConfManager_tHiveCreateTable_1 main ] start
				 */

				currentComponent = "tHadoopConfManager_tHiveCreateTable_1";

				tos_count_tHadoopConfManager_tHiveCreateTable_1++;

				/**
				 * [tHadoopConfManager_tHiveCreateTable_1 main ] stop
				 */

				/**
				 * [tHadoopConfManager_tHiveCreateTable_1 process_data_begin ] start
				 */

				currentComponent = "tHadoopConfManager_tHiveCreateTable_1";

				/**
				 * [tHadoopConfManager_tHiveCreateTable_1 process_data_begin ] stop
				 */

				/**
				 * [tHadoopConfManager_tHiveCreateTable_1 process_data_end ] start
				 */

				currentComponent = "tHadoopConfManager_tHiveCreateTable_1";

				/**
				 * [tHadoopConfManager_tHiveCreateTable_1 process_data_end ] stop
				 */

				/**
				 * [tHadoopConfManager_tHiveCreateTable_1 end ] start
				 */

				currentComponent = "tHadoopConfManager_tHiveCreateTable_1";

				ok_Hash.put("tHadoopConfManager_tHiveCreateTable_1", true);
				end_Hash.put("tHadoopConfManager_tHiveCreateTable_1", System.currentTimeMillis());

				/**
				 * [tHadoopConfManager_tHiveCreateTable_1 end ] stop
				 */
			} // end the resume

		} catch (java.lang.Exception e) {

			TalendException te = new TalendException(e, currentComponent, globalMap);

			throw te;
		} catch (java.lang.Error error) {

			runStat.stopThreadStat();

			throw error;
		} finally {

			try {

				/**
				 * [tHadoopConfManager_tHiveCreateTable_1 finally ] start
				 */

				currentComponent = "tHadoopConfManager_tHiveCreateTable_1";

				/**
				 * [tHadoopConfManager_tHiveCreateTable_1 finally ] stop
				 */
			} catch (java.lang.Exception e) {
				// ignore
			} catch (java.lang.Error error) {
				// ignore
			}
			resourceMap = null;
		}

		globalMap.put("tHadoopConfManager_tHiveCreateTable_1_SUBPROCESS_STATE", 1);
	}

	public String resuming_logs_dir_path = null;
	public String resuming_checkpoint_path = null;
	public String parent_part_launcher = null;
	private String resumeEntryMethodName = null;
	private boolean globalResumeTicket = false;

	public boolean watch = false;
	// portStats is null, it means don't execute the statistics
	public Integer portStats = null;
	public int portTraces = 4334;
	public String clientHost;
	public String defaultClientHost = "localhost";
	public String contextStr = "Default";
	public boolean isDefaultContext = true;
	public String pid = "0";
	public String rootPid = null;
	public String fatherPid = null;
	public String fatherNode = null;
	public long startTime = 0;
	public boolean isChildJob = false;
	public String log4jLevel = "";

	private boolean enableLogStash;

	private boolean execStat = true;

	private ThreadLocal<java.util.Map<String, String>> threadLocal = new ThreadLocal<java.util.Map<String, String>>() {
		protected java.util.Map<String, String> initialValue() {
			java.util.Map<String, String> threadRunResultMap = new java.util.HashMap<String, String>();
			threadRunResultMap.put("errorCode", null);
			threadRunResultMap.put("status", "");
			return threadRunResultMap;
		};
	};

	private PropertiesWithType context_param = new PropertiesWithType();
	public java.util.Map<String, Object> parentContextMap = new java.util.HashMap<String, Object>();

	public String status = "";

	public static void main(String[] args) {
		final AggregateDates_job AggregateDates_jobClass = new AggregateDates_job();

		int exitCode = AggregateDates_jobClass.runJobInTOS(args);

		System.exit(exitCode);
	}

	public String[][] runJob(String[] args) {

		int exitCode = runJobInTOS(args);
		String[][] bufferValue = new String[][] { { Integer.toString(exitCode) } };

		return bufferValue;
	}

	public boolean hastBufferOutputComponent() {
		boolean hastBufferOutput = false;

		return hastBufferOutput;
	}

	public int runJobInTOS(String[] args) {
		// reset status
		status = "";

		String lastStr = "";
		for (String arg : args) {
			if (arg.equalsIgnoreCase("--context_param")) {
				lastStr = arg;
			} else if (lastStr.equals("")) {
				evalParam(arg);
			} else {
				evalParam(lastStr + " " + arg);
				lastStr = "";
			}
		}
		enableLogStash = "true".equalsIgnoreCase(System.getProperty("monitoring"));

		if (clientHost == null) {
			clientHost = defaultClientHost;
		}

		if (pid == null || "0".equals(pid)) {
			pid = TalendString.getAsciiRandomString(6);
		}

		if (rootPid == null) {
			rootPid = pid;
		}
		if (fatherPid == null) {
			fatherPid = pid;
		} else {
			isChildJob = true;
		}

		if (portStats != null) {
			// portStats = -1; //for testing
			if (portStats < 0 || portStats > 65535) {
				// issue:10869, the portStats is invalid, so this client socket can't open
				System.err.println("The statistics socket port " + portStats + " is invalid.");
				execStat = false;
			}
		} else {
			execStat = false;
		}

		try {
			// call job/subjob with an existing context, like: --context=production. if
			// without this parameter, there will use the default context instead.
			java.io.InputStream inContext = AggregateDates_job.class.getClassLoader()
					.getResourceAsStream("etl_project/aggregatedates_job_0_1/contexts/" + contextStr + ".properties");
			if (inContext == null) {
				inContext = AggregateDates_job.class.getClassLoader()
						.getResourceAsStream("config/contexts/" + contextStr + ".properties");
			}
			if (inContext != null) {
				// defaultProps is in order to keep the original context value
				if (context != null && context.isEmpty()) {
					defaultProps.load(inContext);
					context = new ContextProperties(defaultProps);
				}

				inContext.close();
			} else if (!isDefaultContext) {
				// print info and job continue to run, for case: context_param is not empty.
				System.err.println("Could not find the context " + contextStr);
			}

			if (!context_param.isEmpty()) {
				context.putAll(context_param);
				// set types for params from parentJobs
				for (Object key : context_param.keySet()) {
					String context_key = key.toString();
					String context_type = context_param.getContextType(context_key);
					context.setContextType(context_key, context_type);

				}
			}
			class ContextProcessing {
				private void processContext_0() {
					context.setContextType("postgres_DB_input_Login", "id_String");
					context.postgres_DB_input_Login = (String) context.getProperty("postgres_DB_input_Login");
					context.setContextType("postgres_DB_input_Database", "id_String");
					context.postgres_DB_input_Database = (String) context.getProperty("postgres_DB_input_Database");
					context.setContextType("postgres_DB_input_Password", "id_Password");
					String pwd_postgres_DB_input_Password_value = context.getProperty("postgres_DB_input_Password");
					context.postgres_DB_input_Password = null;
					if (pwd_postgres_DB_input_Password_value != null) {
						if (context_param.containsKey("postgres_DB_input_Password")) {// no need to decrypt if it come
																						// from program argument or
																						// parent job runtime
							context.postgres_DB_input_Password = pwd_postgres_DB_input_Password_value;
						} else if (!pwd_postgres_DB_input_Password_value.isEmpty()) {
							try {
								context.postgres_DB_input_Password = routines.system.PasswordEncryptUtil
										.decryptPassword(pwd_postgres_DB_input_Password_value);
								context.put("postgres_DB_input_Password", context.postgres_DB_input_Password);
							} catch (java.lang.RuntimeException e) {
								// do nothing
							}
						}
					}
					context.setContextType("postgres_DB_input_Server", "id_String");
					context.postgres_DB_input_Server = (String) context.getProperty("postgres_DB_input_Server");
					context.setContextType("postgres_DB_input_Schema", "id_String");
					context.postgres_DB_input_Schema = (String) context.getProperty("postgres_DB_input_Schema");
					context.setContextType("postgres_DB_input_Port", "id_String");
					context.postgres_DB_input_Port = (String) context.getProperty("postgres_DB_input_Port");
					context.setContextType("postgres_DB_input_AdditionalParams", "id_String");
					context.postgres_DB_input_AdditionalParams = (String) context
							.getProperty("postgres_DB_input_AdditionalParams");
					context.setContextType("INPUT_PATH", "id_String");
					context.INPUT_PATH = (String) context.getProperty("INPUT_PATH");
					context.setContextType("ClusterHadopp_User", "id_String");
					context.ClusterHadopp_User = (String) context.getProperty("ClusterHadopp_User");
					context.setContextType("ClusterHadopp_NameNodeUri", "id_String");
					context.ClusterHadopp_NameNodeUri = (String) context.getProperty("ClusterHadopp_NameNodeUri");
					context.setContextType("ClusterHadopp_hadoopConfSpecificJar", "id_String");
					context.ClusterHadopp_hadoopConfSpecificJar = (String) context
							.getProperty("ClusterHadopp_hadoopConfSpecificJar");
					context.setContextType("ClusterHadopp_ResourceManager", "id_String");
					context.ClusterHadopp_ResourceManager = (String) context
							.getProperty("ClusterHadopp_ResourceManager");
					context.setContextType("ClusterHadopp_ResourceManagerScheduler", "id_String");
					context.ClusterHadopp_ResourceManagerScheduler = (String) context
							.getProperty("ClusterHadopp_ResourceManagerScheduler");
					context.setContextType("ClusterHadopp_JobHistory", "id_String");
					context.ClusterHadopp_JobHistory = (String) context.getProperty("ClusterHadopp_JobHistory");
				}

				public void processAllContext() {
					processContext_0();
				}
			}

			new ContextProcessing().processAllContext();
		} catch (java.io.IOException ie) {
			System.err.println("Could not load context " + contextStr);
			ie.printStackTrace();
		}

		// get context value from parent directly
		if (parentContextMap != null && !parentContextMap.isEmpty()) {
			if (parentContextMap.containsKey("postgres_DB_input_Login")) {
				context.postgres_DB_input_Login = (String) parentContextMap.get("postgres_DB_input_Login");
			}
			if (parentContextMap.containsKey("postgres_DB_input_Database")) {
				context.postgres_DB_input_Database = (String) parentContextMap.get("postgres_DB_input_Database");
			}
			if (parentContextMap.containsKey("postgres_DB_input_Password")) {
				context.postgres_DB_input_Password = (java.lang.String) parentContextMap
						.get("postgres_DB_input_Password");
			}
			if (parentContextMap.containsKey("postgres_DB_input_Server")) {
				context.postgres_DB_input_Server = (String) parentContextMap.get("postgres_DB_input_Server");
			}
			if (parentContextMap.containsKey("postgres_DB_input_Schema")) {
				context.postgres_DB_input_Schema = (String) parentContextMap.get("postgres_DB_input_Schema");
			}
			if (parentContextMap.containsKey("postgres_DB_input_Port")) {
				context.postgres_DB_input_Port = (String) parentContextMap.get("postgres_DB_input_Port");
			}
			if (parentContextMap.containsKey("postgres_DB_input_AdditionalParams")) {
				context.postgres_DB_input_AdditionalParams = (String) parentContextMap
						.get("postgres_DB_input_AdditionalParams");
			}
			if (parentContextMap.containsKey("INPUT_PATH")) {
				context.INPUT_PATH = (String) parentContextMap.get("INPUT_PATH");
			}
			if (parentContextMap.containsKey("ClusterHadopp_User")) {
				context.ClusterHadopp_User = (String) parentContextMap.get("ClusterHadopp_User");
			}
			if (parentContextMap.containsKey("ClusterHadopp_NameNodeUri")) {
				context.ClusterHadopp_NameNodeUri = (String) parentContextMap.get("ClusterHadopp_NameNodeUri");
			}
			if (parentContextMap.containsKey("ClusterHadopp_hadoopConfSpecificJar")) {
				context.ClusterHadopp_hadoopConfSpecificJar = (String) parentContextMap
						.get("ClusterHadopp_hadoopConfSpecificJar");
			}
			if (parentContextMap.containsKey("ClusterHadopp_ResourceManager")) {
				context.ClusterHadopp_ResourceManager = (String) parentContextMap.get("ClusterHadopp_ResourceManager");
			}
			if (parentContextMap.containsKey("ClusterHadopp_ResourceManagerScheduler")) {
				context.ClusterHadopp_ResourceManagerScheduler = (String) parentContextMap
						.get("ClusterHadopp_ResourceManagerScheduler");
			}
			if (parentContextMap.containsKey("ClusterHadopp_JobHistory")) {
				context.ClusterHadopp_JobHistory = (String) parentContextMap.get("ClusterHadopp_JobHistory");
			}
		}

		// Resume: init the resumeUtil
		resumeEntryMethodName = ResumeUtil.getResumeEntryMethodName(resuming_checkpoint_path);
		resumeUtil = new ResumeUtil(resuming_logs_dir_path, isChildJob, rootPid);
		resumeUtil.initCommonInfo(pid, rootPid, fatherPid, projectName, jobName, contextStr, jobVersion);

		List<String> parametersToEncrypt = new java.util.ArrayList<String>();
		parametersToEncrypt.add("postgres_DB_input_Password");
		// Resume: jobStart
		resumeUtil.addLog("JOB_STARTED", "JOB:" + jobName, parent_part_launcher, Thread.currentThread().getId() + "",
				"", "", "", "", resumeUtil.convertToJsonText(context, parametersToEncrypt));

		if (execStat) {
			try {
				runStat.openSocket(!isChildJob);
				runStat.setAllPID(rootPid, fatherPid, pid, jobName);
				runStat.startThreadStat(clientHost, portStats);
				runStat.updateStatOnJob(RunStat.JOBSTART, fatherNode);
			} catch (java.io.IOException ioException) {
				ioException.printStackTrace();
			}
		}

		java.util.concurrent.ConcurrentHashMap<Object, Object> concurrentHashMap = new java.util.concurrent.ConcurrentHashMap<Object, Object>();
		globalMap.put("concurrentHashMap", concurrentHashMap);

		long startUsedMemory = Runtime.getRuntime().totalMemory() - Runtime.getRuntime().freeMemory();
		long endUsedMemory = 0;
		long end = 0;

		startTime = System.currentTimeMillis();

		System.err.println("Only one hadoop configuration is allowed in one job!");

		try {
			errorCode = null;
			tHadoopConfManager_tHDFSOutput_1Process(globalMap);
			if (!"failure".equals(status)) {
				status = "end";
			}
		} catch (TalendException e_tHadoopConfManager_tHDFSOutput_1) {
			globalMap.put("tHadoopConfManager_tHDFSOutput_1_SUBPROCESS_STATE", -1);

			e_tHadoopConfManager_tHDFSOutput_1.printStackTrace();

		}

		try {
			errorCode = null;
			Implicit_Context_RegexProcess(globalMap);
			if (!"failure".equals(status)) {
				status = "end";
			}
		} catch (TalendException e_Implicit_Context_Regex) {
			globalMap.put("Implicit_Context_Regex_SUBPROCESS_STATE", -1);

			e_Implicit_Context_Regex.printStackTrace();

		}

		this.globalResumeTicket = true;// to run tPreJob

		this.globalResumeTicket = false;// to run others jobs

		try {
			errorCode = null;
			tDBInput_1Process(globalMap);
			if (!"failure".equals(status)) {
				status = "end";
			}
		} catch (TalendException e_tDBInput_1) {
			globalMap.put("tDBInput_1_SUBPROCESS_STATE", -1);

			e_tDBInput_1.printStackTrace();

		}

		this.globalResumeTicket = true;// to run tPostJob

		end = System.currentTimeMillis();

		if (watch) {
			System.out.println((end - startTime) + " milliseconds");
		}

		endUsedMemory = Runtime.getRuntime().totalMemory() - Runtime.getRuntime().freeMemory();
		if (false) {
			System.out.println(
					(endUsedMemory - startUsedMemory) + " bytes memory increase when running : AggregateDates_job");
		}

		if (execStat) {
			runStat.updateStatOnJob(RunStat.JOBEND, fatherNode);
			runStat.stopThreadStat();
		}
		int returnCode = 0;
		if (errorCode == null) {
			returnCode = status != null && status.equals("failure") ? 1 : 0;
		} else {
			returnCode = errorCode.intValue();
		}
		resumeUtil.addLog("JOB_ENDED", "JOB:" + jobName, parent_part_launcher, Thread.currentThread().getId() + "", "",
				"" + returnCode, "", "", "");

		return returnCode;

	}

	// only for OSGi env
	public void destroy() {

	}

	private java.util.Map<String, Object> getSharedConnections4REST() {
		java.util.Map<String, Object> connections = new java.util.HashMap<String, Object>();

		return connections;
	}

	private void evalParam(String arg) {
		if (arg.startsWith("--resuming_logs_dir_path")) {
			resuming_logs_dir_path = arg.substring(25);
		} else if (arg.startsWith("--resuming_checkpoint_path")) {
			resuming_checkpoint_path = arg.substring(27);
		} else if (arg.startsWith("--parent_part_launcher")) {
			parent_part_launcher = arg.substring(23);
		} else if (arg.startsWith("--watch")) {
			watch = true;
		} else if (arg.startsWith("--stat_port=")) {
			String portStatsStr = arg.substring(12);
			if (portStatsStr != null && !portStatsStr.equals("null")) {
				portStats = Integer.parseInt(portStatsStr);
			}
		} else if (arg.startsWith("--trace_port=")) {
			portTraces = Integer.parseInt(arg.substring(13));
		} else if (arg.startsWith("--client_host=")) {
			clientHost = arg.substring(14);
		} else if (arg.startsWith("--context=")) {
			contextStr = arg.substring(10);
			isDefaultContext = false;
		} else if (arg.startsWith("--father_pid=")) {
			fatherPid = arg.substring(13);
		} else if (arg.startsWith("--root_pid=")) {
			rootPid = arg.substring(11);
		} else if (arg.startsWith("--father_node=")) {
			fatherNode = arg.substring(14);
		} else if (arg.startsWith("--pid=")) {
			pid = arg.substring(6);
		} else if (arg.startsWith("--context_type")) {
			String keyValue = arg.substring(15);
			int index = -1;
			if (keyValue != null && (index = keyValue.indexOf('=')) > -1) {
				if (fatherPid == null) {
					context_param.setContextType(keyValue.substring(0, index),
							replaceEscapeChars(keyValue.substring(index + 1)));
				} else { // the subjob won't escape the especial chars
					context_param.setContextType(keyValue.substring(0, index), keyValue.substring(index + 1));
				}

			}

		} else if (arg.startsWith("--context_param")) {
			String keyValue = arg.substring(16);
			int index = -1;
			if (keyValue != null && (index = keyValue.indexOf('=')) > -1) {
				if (fatherPid == null) {
					context_param.put(keyValue.substring(0, index), replaceEscapeChars(keyValue.substring(index + 1)));
				} else { // the subjob won't escape the especial chars
					context_param.put(keyValue.substring(0, index), keyValue.substring(index + 1));
				}
			}
		} else if (arg.startsWith("--log4jLevel=")) {
			log4jLevel = arg.substring(13);
		} else if (arg.startsWith("--monitoring") && arg.contains("=")) {// for trunjob call
			final int equal = arg.indexOf('=');
			final String key = arg.substring("--".length(), equal);
			System.setProperty(key, arg.substring(equal + 1));
		}
	}

	private static final String NULL_VALUE_EXPRESSION_IN_COMMAND_STRING_FOR_CHILD_JOB_ONLY = "<TALEND_NULL>";

	private final String[][] escapeChars = { { "\\\\", "\\" }, { "\\n", "\n" }, { "\\'", "\'" }, { "\\r", "\r" },
			{ "\\f", "\f" }, { "\\b", "\b" }, { "\\t", "\t" } };

	private String replaceEscapeChars(String keyValue) {

		if (keyValue == null || ("").equals(keyValue.trim())) {
			return keyValue;
		}

		StringBuilder result = new StringBuilder();
		int currIndex = 0;
		while (currIndex < keyValue.length()) {
			int index = -1;
			// judege if the left string includes escape chars
			for (String[] strArray : escapeChars) {
				index = keyValue.indexOf(strArray[0], currIndex);
				if (index >= 0) {

					result.append(keyValue.substring(currIndex, index + strArray[0].length()).replace(strArray[0],
							strArray[1]));
					currIndex = index + strArray[0].length();
					break;
				}
			}
			// if the left string doesn't include escape chars, append the left into the
			// result
			if (index < 0) {
				result.append(keyValue.substring(currIndex));
				currIndex = currIndex + keyValue.length();
			}
		}

		return result.toString();
	}

	public Integer getErrorCode() {
		return errorCode;
	}

	public String getStatus() {
		return status;
	}

	ResumeUtil resumeUtil = null;
}
/************************************************************************************************
 * 166317 characters generated by Talend Open Studio for Big Data on the 24
 * octobre 2025 20:55:04 CEST
 ************************************************************************************************/