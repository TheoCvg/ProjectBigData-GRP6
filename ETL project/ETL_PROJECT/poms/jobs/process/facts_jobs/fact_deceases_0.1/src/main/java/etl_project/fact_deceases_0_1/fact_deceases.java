// ============================================================================
//
// Copyright (c) 2006-2015, Talend Inc.
//
// This source code has been automatically generated by_Talend Open Studio for Big Data
// / Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
// http://www.apache.org/licenses/LICENSE-2.0
// 
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

package etl_project.fact_deceases_0_1;

import routines.Numeric;
import routines.DataOperation;
import routines.TalendDataGenerator;
import routines.TalendStringUtil;
import routines.TalendString;
import routines.StringHandling;
import routines.Relational;
import routines.TalendDate;
import routines.Mathematical;
import routines.system.*;
import routines.system.api.*;
import java.text.ParseException;
import java.text.SimpleDateFormat;
import java.util.Date;
import java.util.List;
import java.math.BigDecimal;
import java.io.ByteArrayOutputStream;
import java.io.ByteArrayInputStream;
import java.io.DataInputStream;
import java.io.DataOutputStream;
import java.io.ObjectOutputStream;
import java.io.ObjectInputStream;
import java.io.IOException;
import java.util.Comparator;

@SuppressWarnings("unused")

/**
 * Job: fact_deceases Purpose: <br>
 * Description: <br>
 * 
 * @author user@talend.com
 * @version 7.3.1.20200219_1130
 * @status
 */
public class fact_deceases implements TalendJob {

	protected static void logIgnoredError(String message, Throwable cause) {
		System.err.println(message);
		if (cause != null) {
			cause.printStackTrace();
		}

	}

	public final Object obj = new Object();

	// for transmiting parameters purpose
	private Object valueObject = null;

	public Object getValueObject() {
		return this.valueObject;
	}

	public void setValueObject(Object valueObject) {
		this.valueObject = valueObject;
	}

	private final static String defaultCharset = java.nio.charset.Charset.defaultCharset().name();

	private final static String utf8Charset = "UTF-8";

	// contains type for every context property
	public class PropertiesWithType extends java.util.Properties {
		private static final long serialVersionUID = 1L;
		private java.util.Map<String, String> propertyTypes = new java.util.HashMap<>();

		public PropertiesWithType(java.util.Properties properties) {
			super(properties);
		}

		public PropertiesWithType() {
			super();
		}

		public void setContextType(String key, String type) {
			propertyTypes.put(key, type);
		}

		public String getContextType(String key) {
			return propertyTypes.get(key);
		}
	}

	// create and load default properties
	private java.util.Properties defaultProps = new java.util.Properties();

	// create application properties with default
	public class ContextProperties extends PropertiesWithType {

		private static final long serialVersionUID = 1L;

		public ContextProperties(java.util.Properties properties) {
			super(properties);
		}

		public ContextProperties() {
			super();
		}

		public void synchronizeContext() {

			if (INPUT_PATH != null) {

				this.setProperty("INPUT_PATH", INPUT_PATH.toString());

			}

			if (ClusterHadopp_User != null) {

				this.setProperty("ClusterHadopp_User", ClusterHadopp_User.toString());

			}

			if (ClusterHadopp_NameNodeUri != null) {

				this.setProperty("ClusterHadopp_NameNodeUri", ClusterHadopp_NameNodeUri.toString());

			}

			if (ClusterHadopp_hadoopConfSpecificJar != null) {

				this.setProperty("ClusterHadopp_hadoopConfSpecificJar", ClusterHadopp_hadoopConfSpecificJar.toString());

			}

			if (ClusterHadopp_ResourceManager != null) {

				this.setProperty("ClusterHadopp_ResourceManager", ClusterHadopp_ResourceManager.toString());

			}

			if (ClusterHadopp_ResourceManagerScheduler != null) {

				this.setProperty("ClusterHadopp_ResourceManagerScheduler",
						ClusterHadopp_ResourceManagerScheduler.toString());

			}

			if (ClusterHadopp_JobHistory != null) {

				this.setProperty("ClusterHadopp_JobHistory", ClusterHadopp_JobHistory.toString());

			}

		}

		public String INPUT_PATH;

		public String getINPUT_PATH() {
			return this.INPUT_PATH;
		}

		public String ClusterHadopp_User;

		public String getClusterHadopp_User() {
			return this.ClusterHadopp_User;
		}

		public String ClusterHadopp_NameNodeUri;

		public String getClusterHadopp_NameNodeUri() {
			return this.ClusterHadopp_NameNodeUri;
		}

		public String ClusterHadopp_hadoopConfSpecificJar;

		public String getClusterHadopp_hadoopConfSpecificJar() {
			return this.ClusterHadopp_hadoopConfSpecificJar;
		}

		public String ClusterHadopp_ResourceManager;

		public String getClusterHadopp_ResourceManager() {
			return this.ClusterHadopp_ResourceManager;
		}

		public String ClusterHadopp_ResourceManagerScheduler;

		public String getClusterHadopp_ResourceManagerScheduler() {
			return this.ClusterHadopp_ResourceManagerScheduler;
		}

		public String ClusterHadopp_JobHistory;

		public String getClusterHadopp_JobHistory() {
			return this.ClusterHadopp_JobHistory;
		}
	}

	protected ContextProperties context = new ContextProperties(); // will be instanciated by MS.

	public ContextProperties getContext() {
		return this.context;
	}

	private final String jobVersion = "0.1";
	private final String jobName = "fact_deceases";
	private final String projectName = "ETL_PROJECT";
	public Integer errorCode = null;
	private String currentComponent = "";

	private final java.util.Map<String, Object> globalMap = new java.util.HashMap<String, Object>();
	private final static java.util.Map<String, Object> junitGlobalMap = new java.util.HashMap<String, Object>();

	private final java.util.Map<String, Long> start_Hash = new java.util.HashMap<String, Long>();
	private final java.util.Map<String, Long> end_Hash = new java.util.HashMap<String, Long>();
	private final java.util.Map<String, Boolean> ok_Hash = new java.util.HashMap<String, Boolean>();
	public final java.util.List<String[]> globalBuffer = new java.util.ArrayList<String[]>();

	private RunStat runStat = new RunStat();

	// OSGi DataSource
	private final static String KEY_DB_DATASOURCES = "KEY_DB_DATASOURCES";

	private final static String KEY_DB_DATASOURCES_RAW = "KEY_DB_DATASOURCES_RAW";

	public void setDataSources(java.util.Map<String, javax.sql.DataSource> dataSources) {
		java.util.Map<String, routines.system.TalendDataSource> talendDataSources = new java.util.HashMap<String, routines.system.TalendDataSource>();
		for (java.util.Map.Entry<String, javax.sql.DataSource> dataSourceEntry : dataSources.entrySet()) {
			talendDataSources.put(dataSourceEntry.getKey(),
					new routines.system.TalendDataSource(dataSourceEntry.getValue()));
		}
		globalMap.put(KEY_DB_DATASOURCES, talendDataSources);
		globalMap.put(KEY_DB_DATASOURCES_RAW, new java.util.HashMap<String, javax.sql.DataSource>(dataSources));
	}

	private final java.io.ByteArrayOutputStream baos = new java.io.ByteArrayOutputStream();
	private final java.io.PrintStream errorMessagePS = new java.io.PrintStream(new java.io.BufferedOutputStream(baos));

	public String getExceptionStackTrace() {
		if ("failure".equals(this.getStatus())) {
			errorMessagePS.flush();
			return baos.toString();
		}
		return null;
	}

	private Exception exception;

	public Exception getException() {
		if ("failure".equals(this.getStatus())) {
			return this.exception;
		}
		return null;
	}

	private class TalendException extends Exception {

		private static final long serialVersionUID = 1L;

		private java.util.Map<String, Object> globalMap = null;
		private Exception e = null;
		private String currentComponent = null;
		private String virtualComponentName = null;

		public void setVirtualComponentName(String virtualComponentName) {
			this.virtualComponentName = virtualComponentName;
		}

		private TalendException(Exception e, String errorComponent, final java.util.Map<String, Object> globalMap) {
			this.currentComponent = errorComponent;
			this.globalMap = globalMap;
			this.e = e;
		}

		public Exception getException() {
			return this.e;
		}

		public String getCurrentComponent() {
			return this.currentComponent;
		}

		public String getExceptionCauseMessage(Exception e) {
			Throwable cause = e;
			String message = null;
			int i = 10;
			while (null != cause && 0 < i--) {
				message = cause.getMessage();
				if (null == message) {
					cause = cause.getCause();
				} else {
					break;
				}
			}
			if (null == message) {
				message = e.getClass().getName();
			}
			return message;
		}

		@Override
		public void printStackTrace() {
			if (!(e instanceof TalendException || e instanceof TDieException)) {
				if (virtualComponentName != null && currentComponent.indexOf(virtualComponentName + "_") == 0) {
					globalMap.put(virtualComponentName + "_ERROR_MESSAGE", getExceptionCauseMessage(e));
				}
				globalMap.put(currentComponent + "_ERROR_MESSAGE", getExceptionCauseMessage(e));
				System.err.println("Exception in component " + currentComponent + " (" + jobName + ")");
			}
			if (!(e instanceof TDieException)) {
				if (e instanceof TalendException) {
					e.printStackTrace();
				} else {
					e.printStackTrace();
					e.printStackTrace(errorMessagePS);
					fact_deceases.this.exception = e;
				}
			}
			if (!(e instanceof TalendException)) {
				try {
					for (java.lang.reflect.Method m : this.getClass().getEnclosingClass().getMethods()) {
						if (m.getName().compareTo(currentComponent + "_error") == 0) {
							m.invoke(fact_deceases.this, new Object[] { e, currentComponent, globalMap });
							break;
						}
					}

					if (!(e instanceof TDieException)) {
					}
				} catch (Exception e) {
					this.e.printStackTrace();
				}
			}
		}
	}

	public void Implicit_Context_Regex_error(Exception exception, String errorComponent,
			final java.util.Map<String, Object> globalMap) throws TalendException {

		Implicit_Context_Context_error(exception, errorComponent, globalMap);

	}

	public void Implicit_Context_Context_error(Exception exception, String errorComponent,
			final java.util.Map<String, Object> globalMap) throws TalendException {

		end_Hash.put(errorComponent, System.currentTimeMillis());

		status = "failure";

		Implicit_Context_Regex_onSubJobError(exception, errorComponent, globalMap);
	}

	public void tFileInputDelimited_1_error(Exception exception, String errorComponent,
			final java.util.Map<String, Object> globalMap) throws TalendException {

		end_Hash.put(errorComponent, System.currentTimeMillis());

		status = "failure";

		tFileInputDelimited_1_onSubJobError(exception, errorComponent, globalMap);
	}

	public void tMap_1_error(Exception exception, String errorComponent, final java.util.Map<String, Object> globalMap)
			throws TalendException {

		end_Hash.put(errorComponent, System.currentTimeMillis());

		status = "failure";

		tFileInputDelimited_1_onSubJobError(exception, errorComponent, globalMap);
	}

	public void tHDFSOutput_1_error(Exception exception, String errorComponent,
			final java.util.Map<String, Object> globalMap) throws TalendException {

		end_Hash.put(errorComponent, System.currentTimeMillis());

		status = "failure";

		tFileInputDelimited_1_onSubJobError(exception, errorComponent, globalMap);
	}

	public void tHiveCreateTable_1_error(Exception exception, String errorComponent,
			final java.util.Map<String, Object> globalMap) throws TalendException {

		end_Hash.put(errorComponent, System.currentTimeMillis());

		status = "failure";

		tHiveCreateTable_1_onSubJobError(exception, errorComponent, globalMap);
	}

	public void tHiveInput_1_error(Exception exception, String errorComponent,
			final java.util.Map<String, Object> globalMap) throws TalendException {

		end_Hash.put(errorComponent, System.currentTimeMillis());

		status = "failure";

		tFileInputDelimited_1_onSubJobError(exception, errorComponent, globalMap);
	}

	public void tHiveInput_2_error(Exception exception, String errorComponent,
			final java.util.Map<String, Object> globalMap) throws TalendException {

		end_Hash.put(errorComponent, System.currentTimeMillis());

		status = "failure";

		tFileInputDelimited_1_onSubJobError(exception, errorComponent, globalMap);
	}

	public void tAdvancedHash_row2_error(Exception exception, String errorComponent,
			final java.util.Map<String, Object> globalMap) throws TalendException {

		end_Hash.put(errorComponent, System.currentTimeMillis());

		status = "failure";

		tFileInputDelimited_1_onSubJobError(exception, errorComponent, globalMap);
	}

	public void tAdvancedHash_row3_error(Exception exception, String errorComponent,
			final java.util.Map<String, Object> globalMap) throws TalendException {

		end_Hash.put(errorComponent, System.currentTimeMillis());

		status = "failure";

		tFileInputDelimited_1_onSubJobError(exception, errorComponent, globalMap);
	}

	public void tHadoopConfManager_tHDFSOutput_1_error(Exception exception, String errorComponent,
			final java.util.Map<String, Object> globalMap) throws TalendException {

		end_Hash.put(errorComponent, System.currentTimeMillis());

		status = "failure";

		tHadoopConfManager_tHDFSOutput_1_onSubJobError(exception, errorComponent, globalMap);
	}

	public void tHadoopConfManager_tHiveCreateTable_1_error(Exception exception, String errorComponent,
			final java.util.Map<String, Object> globalMap) throws TalendException {

		end_Hash.put(errorComponent, System.currentTimeMillis());

		status = "failure";

		tHadoopConfManager_tHiveCreateTable_1_onSubJobError(exception, errorComponent, globalMap);
	}

	public void tHadoopConfManager_tHiveInput_1_error(Exception exception, String errorComponent,
			final java.util.Map<String, Object> globalMap) throws TalendException {

		end_Hash.put(errorComponent, System.currentTimeMillis());

		status = "failure";

		tHadoopConfManager_tHiveInput_1_onSubJobError(exception, errorComponent, globalMap);
	}

	public void tHadoopConfManager_tHiveInput_2_error(Exception exception, String errorComponent,
			final java.util.Map<String, Object> globalMap) throws TalendException {

		end_Hash.put(errorComponent, System.currentTimeMillis());

		status = "failure";

		tHadoopConfManager_tHiveInput_2_onSubJobError(exception, errorComponent, globalMap);
	}

	public void Implicit_Context_Regex_onSubJobError(Exception exception, String errorComponent,
			final java.util.Map<String, Object> globalMap) throws TalendException {

		resumeUtil.addLog("SYSTEM_LOG", "NODE:" + errorComponent, "", Thread.currentThread().getId() + "", "FATAL", "",
				exception.getMessage(), ResumeUtil.getExceptionStackTrace(exception), "");

	}

	public void tFileInputDelimited_1_onSubJobError(Exception exception, String errorComponent,
			final java.util.Map<String, Object> globalMap) throws TalendException {

		resumeUtil.addLog("SYSTEM_LOG", "NODE:" + errorComponent, "", Thread.currentThread().getId() + "", "FATAL", "",
				exception.getMessage(), ResumeUtil.getExceptionStackTrace(exception), "");

	}

	public void tHiveCreateTable_1_onSubJobError(Exception exception, String errorComponent,
			final java.util.Map<String, Object> globalMap) throws TalendException {

		resumeUtil.addLog("SYSTEM_LOG", "NODE:" + errorComponent, "", Thread.currentThread().getId() + "", "FATAL", "",
				exception.getMessage(), ResumeUtil.getExceptionStackTrace(exception), "");

	}

	public void tHadoopConfManager_tHDFSOutput_1_onSubJobError(Exception exception, String errorComponent,
			final java.util.Map<String, Object> globalMap) throws TalendException {

		resumeUtil.addLog("SYSTEM_LOG", "NODE:" + errorComponent, "", Thread.currentThread().getId() + "", "FATAL", "",
				exception.getMessage(), ResumeUtil.getExceptionStackTrace(exception), "");

	}

	public void tHadoopConfManager_tHiveCreateTable_1_onSubJobError(Exception exception, String errorComponent,
			final java.util.Map<String, Object> globalMap) throws TalendException {

		resumeUtil.addLog("SYSTEM_LOG", "NODE:" + errorComponent, "", Thread.currentThread().getId() + "", "FATAL", "",
				exception.getMessage(), ResumeUtil.getExceptionStackTrace(exception), "");

	}

	public void tHadoopConfManager_tHiveInput_1_onSubJobError(Exception exception, String errorComponent,
			final java.util.Map<String, Object> globalMap) throws TalendException {

		resumeUtil.addLog("SYSTEM_LOG", "NODE:" + errorComponent, "", Thread.currentThread().getId() + "", "FATAL", "",
				exception.getMessage(), ResumeUtil.getExceptionStackTrace(exception), "");

	}

	public void tHadoopConfManager_tHiveInput_2_onSubJobError(Exception exception, String errorComponent,
			final java.util.Map<String, Object> globalMap) throws TalendException {

		resumeUtil.addLog("SYSTEM_LOG", "NODE:" + errorComponent, "", Thread.currentThread().getId() + "", "FATAL", "",
				exception.getMessage(), ResumeUtil.getExceptionStackTrace(exception), "");

	}

	public static class row_Implicit_Context_RegexStruct
			implements routines.system.IPersistableRow<row_Implicit_Context_RegexStruct> {
		final static byte[] commonByteArrayLock_ETL_PROJECT_fact_deceases = new byte[0];
		static byte[] commonByteArray_ETL_PROJECT_fact_deceases = new byte[0];

		public String key;

		public String getKey() {
			return this.key;
		}

		public String value;

		public String getValue() {
			return this.value;
		}

		private String readString(ObjectInputStream dis) throws IOException {
			String strReturn = null;
			int length = 0;
			length = dis.readInt();
			if (length == -1) {
				strReturn = null;
			} else {
				if (length > commonByteArray_ETL_PROJECT_fact_deceases.length) {
					if (length < 1024 && commonByteArray_ETL_PROJECT_fact_deceases.length == 0) {
						commonByteArray_ETL_PROJECT_fact_deceases = new byte[1024];
					} else {
						commonByteArray_ETL_PROJECT_fact_deceases = new byte[2 * length];
					}
				}
				dis.readFully(commonByteArray_ETL_PROJECT_fact_deceases, 0, length);
				strReturn = new String(commonByteArray_ETL_PROJECT_fact_deceases, 0, length, utf8Charset);
			}
			return strReturn;
		}

		private void writeString(String str, ObjectOutputStream dos) throws IOException {
			if (str == null) {
				dos.writeInt(-1);
			} else {
				byte[] byteArray = str.getBytes(utf8Charset);
				dos.writeInt(byteArray.length);
				dos.write(byteArray);
			}
		}

		public void readData(ObjectInputStream dis) {

			synchronized (commonByteArrayLock_ETL_PROJECT_fact_deceases) {

				try {

					int length = 0;

					this.key = readString(dis);

					this.value = readString(dis);

				} catch (IOException e) {
					throw new RuntimeException(e);

				}

			}

		}

		public void writeData(ObjectOutputStream dos) {
			try {

				// String

				writeString(this.key, dos);

				// String

				writeString(this.value, dos);

			} catch (IOException e) {
				throw new RuntimeException(e);
			}

		}

		public String toString() {

			StringBuilder sb = new StringBuilder();
			sb.append(super.toString());
			sb.append("[");
			sb.append("key=" + key);
			sb.append(",value=" + value);
			sb.append("]");

			return sb.toString();
		}

		/**
		 * Compare keys
		 */
		public int compareTo(row_Implicit_Context_RegexStruct other) {

			int returnValue = -1;

			return returnValue;
		}

		private int checkNullsAndCompare(Object object1, Object object2) {
			int returnValue = 0;
			if (object1 instanceof Comparable && object2 instanceof Comparable) {
				returnValue = ((Comparable) object1).compareTo(object2);
			} else if (object1 != null && object2 != null) {
				returnValue = compareStrings(object1.toString(), object2.toString());
			} else if (object1 == null && object2 != null) {
				returnValue = 1;
			} else if (object1 != null && object2 == null) {
				returnValue = -1;
			} else {
				returnValue = 0;
			}

			return returnValue;
		}

		private int compareStrings(String string1, String string2) {
			return string1.compareTo(string2);
		}

	}

	public void Implicit_Context_RegexProcess(final java.util.Map<String, Object> globalMap) throws TalendException {
		globalMap.put("Implicit_Context_Regex_SUBPROCESS_STATE", 0);

		final boolean execStat = this.execStat;
		String currentVirtualComponent = null;

		String iterateId = "";

		String currentComponent = "";
		java.util.Map<String, Object> resourceMap = new java.util.HashMap<String, Object>();

		try {
			// TDI-39566 avoid throwing an useless Exception
			boolean resumeIt = true;
			if (globalResumeTicket == false && resumeEntryMethodName != null) {
				String currentMethodName = new java.lang.Exception().getStackTrace()[0].getMethodName();
				resumeIt = resumeEntryMethodName.equals(currentMethodName);
			}
			if (resumeIt || globalResumeTicket) { // start the resume
				globalResumeTicket = true;

				row_Implicit_Context_RegexStruct row_Implicit_Context_Regex = new row_Implicit_Context_RegexStruct();

				/**
				 * [Implicit_Context_Context begin ] start
				 */

				ok_Hash.put("Implicit_Context_Context", false);
				start_Hash.put("Implicit_Context_Context", System.currentTimeMillis());

				currentVirtualComponent = "Implicit_Context_Context";

				currentComponent = "Implicit_Context_Context";

				if (execStat) {
					runStat.updateStatOnConnection(resourceMap, iterateId, 0, 0, "Main");
				}

				int tos_count_Implicit_Context_Context = 0;

				java.util.List<String> assignList_Implicit_Context_Context = new java.util.ArrayList<String>();
				java.util.List<String> newPropertyList_Implicit_Context_Context = new java.util.ArrayList<String>();
				java.util.List<String> noAssignList_Implicit_Context_Context = new java.util.ArrayList<String>();
				int nb_line_Implicit_Context_Context = 0;

				/**
				 * [Implicit_Context_Context begin ] stop
				 */

				/**
				 * [Implicit_Context_Regex begin ] start
				 */

				ok_Hash.put("Implicit_Context_Regex", false);
				start_Hash.put("Implicit_Context_Regex", System.currentTimeMillis());

				currentVirtualComponent = "Implicit_Context_Regex";

				currentComponent = "Implicit_Context_Regex";

				int tos_count_Implicit_Context_Regex = 0;

				int nb_line_Implicit_Context_Regex = 0;

				int footer_Implicit_Context_Regex = 0;
				boolean removeEmptyRowImplicit_Context_Regex = true;
				Object source_Implicit_Context_Regex = /** Start field Implicit_Context_Regex:FILENAME */
						"C:/Users/theoc/Desktop/notion/A4/Blocs/BigData/Projet/ProjectBigData-GRP6/ETL project/ETL_PROJECT/resources/config/config.properties"/**
																																								 * End
																																								 * field
																																								 * Implicit_Context_Regex:FILENAME
																																								 */
				;

				org.talend.fileprocess.TOSDelimitedReader inImplicit_Context_Regex = null;
				if (source_Implicit_Context_Regex instanceof String
						|| source_Implicit_Context_Regex instanceof java.io.InputStream) {
					inImplicit_Context_Regex = new org.talend.fileprocess.TOSDelimitedReader(/**
																								 * Start field
																								 * Implicit_Context_Regex:FILENAME
																								 */
							"C:/Users/theoc/Desktop/notion/A4/Blocs/BigData/Projet/ProjectBigData-GRP6/ETL project/ETL_PROJECT/resources/config/config.properties"/**
																																									 * End
																																									 * field
																																									 * Implicit_Context_Regex:FILENAME
																																									 */
							, "UTF-8", "", "\n", removeEmptyRowImplicit_Context_Regex);
				} else {
					throw new java.lang.Exception(
							"The source data should be specified as File Path or InputStream or java.io.Reader!");
				}
				String strImplicit_Context_Regex;
				int totalLineImplicit_Context_Regex = 0, currentLineImplicit_Context_Regex = 0,
						beginLineImplicit_Context_Regex = 0, lastLineImplicit_Context_Regex = -1,
						validRowCountImplicit_Context_Regex = 0;
				int limitImplicit_Context_Regex = -1;

				int headerImplicit_Context_Regex = 0;
				if (headerImplicit_Context_Regex > 0) {
					beginLineImplicit_Context_Regex = headerImplicit_Context_Regex + 1;
				}

				if (footer_Implicit_Context_Regex > 0) {
					while (inImplicit_Context_Regex.readRecord()) {
						strImplicit_Context_Regex = inImplicit_Context_Regex.getRowRecord();
						totalLineImplicit_Context_Regex++;
					}
					int lastLineTempImplicit_Context_Regex = totalLineImplicit_Context_Regex
							- footer_Implicit_Context_Regex < 0 ? 0
									: totalLineImplicit_Context_Regex - footer_Implicit_Context_Regex;
					if (lastLineImplicit_Context_Regex > 0) {
						lastLineImplicit_Context_Regex = lastLineImplicit_Context_Regex < lastLineTempImplicit_Context_Regex
								? lastLineImplicit_Context_Regex
								: lastLineTempImplicit_Context_Regex;
					} else {
						lastLineImplicit_Context_Regex = lastLineTempImplicit_Context_Regex;
					}
					inImplicit_Context_Regex.close();
					inImplicit_Context_Regex = new org.talend.fileprocess.TOSDelimitedReader(/**
																								 * Start field
																								 * Implicit_Context_Regex:FILENAME
																								 */
							"C:/Users/theoc/Desktop/notion/A4/Blocs/BigData/Projet/ProjectBigData-GRP6/ETL project/ETL_PROJECT/resources/config/config.properties"/**
																																									 * End
																																									 * field
																																									 * Implicit_Context_Regex:FILENAME
																																									 */
							, "UTF-8", "", "\n", removeEmptyRowImplicit_Context_Regex);
				}
				java.util.StringTokenizer strTokenImplicit_Context_Regex;
				java.util.regex.Pattern patternImplicit_Context_Regex = java.util.regex.Pattern
						.compile("^([^" + "=" + "]*)" + "=" + "(.*)$");
				java.util.regex.Matcher matcherImplicit_Context_Regex = null;

				while (inImplicit_Context_Regex.readRecord()) {
					strImplicit_Context_Regex = inImplicit_Context_Regex.getRowRecord();

					currentLineImplicit_Context_Regex++;
					if (currentLineImplicit_Context_Regex < beginLineImplicit_Context_Regex) {
						continue;
					}
					if (lastLineImplicit_Context_Regex > -1
							&& currentLineImplicit_Context_Regex > lastLineImplicit_Context_Regex) {
						break;
					}
					if (removeEmptyRowImplicit_Context_Regex && ("").equals(strImplicit_Context_Regex)) {
						continue;
					}
					if (limitImplicit_Context_Regex != -1
							&& validRowCountImplicit_Context_Regex >= limitImplicit_Context_Regex) {
						break;
					}

					matcherImplicit_Context_Regex = patternImplicit_Context_Regex.matcher(strImplicit_Context_Regex);
					int groupCountImplicit_Context_Regex = 0;
					boolean isMatchImplicit_Context_Regex = matcherImplicit_Context_Regex.find();
					if (isMatchImplicit_Context_Regex) {
						groupCountImplicit_Context_Regex = matcherImplicit_Context_Regex.groupCount();
					}
					row_Implicit_Context_Regex = null;

					boolean lineIsEmptyImplicit_Context_Regex = strImplicit_Context_Regex.length() == 0;

					String[] valueImplicit_Context_Regex = new String[2];
					String frontCharImplicit_Context_Regex, behindCharImplicit_Context_Regex;
					for (int i = 0; i < 2; i++) {
						valueImplicit_Context_Regex[i] = "";
						if (lineIsEmptyImplicit_Context_Regex) {
							continue;
						}
						if (i < groupCountImplicit_Context_Regex) {
							valueImplicit_Context_Regex[i] = matcherImplicit_Context_Regex.group(i + 1);
						}
					}
					validRowCountImplicit_Context_Regex++;

					boolean whetherReject_Implicit_Context_Regex = false;
					row_Implicit_Context_Regex = new row_Implicit_Context_RegexStruct();
					try {
						if (!isMatchImplicit_Context_Regex) {// line data not matched with given regex parameter
							throw new java.lang.Exception("Line doesn't match: " + strImplicit_Context_Regex);
						}

						if (valueImplicit_Context_Regex[0] != null && valueImplicit_Context_Regex[0].length() > 0) {
							row_Implicit_Context_Regex.key = valueImplicit_Context_Regex[0];
						} else {
							row_Implicit_Context_Regex.key = "";
						}

						if (valueImplicit_Context_Regex[1] != null && valueImplicit_Context_Regex[1].length() > 0) {
							row_Implicit_Context_Regex.value = valueImplicit_Context_Regex[1];
						} else {
							row_Implicit_Context_Regex.value = "";
						}

					} catch (java.lang.Exception e) {
						whetherReject_Implicit_Context_Regex = true;
						if (isMatchImplicit_Context_Regex) {
							System.err.println(e.getMessage());
						}
						row_Implicit_Context_Regex = null;
					}

					nb_line_Implicit_Context_Regex++;

					/**
					 * [Implicit_Context_Regex begin ] stop
					 */

					/**
					 * [Implicit_Context_Regex main ] start
					 */

					currentVirtualComponent = "Implicit_Context_Regex";

					currentComponent = "Implicit_Context_Regex";

					tos_count_Implicit_Context_Regex++;

					/**
					 * [Implicit_Context_Regex main ] stop
					 */

					/**
					 * [Implicit_Context_Regex process_data_begin ] start
					 */

					currentVirtualComponent = "Implicit_Context_Regex";

					currentComponent = "Implicit_Context_Regex";

					/**
					 * [Implicit_Context_Regex process_data_begin ] stop
					 */
// Start of branch "row_Implicit_Context_Regex"
					if (row_Implicit_Context_Regex != null) {

						/**
						 * [Implicit_Context_Context main ] start
						 */

						currentVirtualComponent = "Implicit_Context_Context";

						currentComponent = "Implicit_Context_Context";

						if (execStat) {
							runStat.updateStatOnConnection(iterateId, 1, 1, "Main");
						}

						//////////////////////////
						String tmp_key_Implicit_Context_Context = null;
						String key_Implicit_Context_Context = null;
						if (row_Implicit_Context_Regex.key != null) {
							tmp_key_Implicit_Context_Context = row_Implicit_Context_Regex.key.trim();
							if ((tmp_key_Implicit_Context_Context.startsWith("#")
									|| tmp_key_Implicit_Context_Context.startsWith("!"))) {
								tmp_key_Implicit_Context_Context = null;
							} else {
								row_Implicit_Context_Regex.key = tmp_key_Implicit_Context_Context;
							}
						}
						if (row_Implicit_Context_Regex.key != null) {
							key_Implicit_Context_Context = row_Implicit_Context_Regex.key;
						}
						String value_Implicit_Context_Context = null;
						if (row_Implicit_Context_Regex.value != null) {
							value_Implicit_Context_Context = row_Implicit_Context_Regex.value;
						}

						String currentValue_Implicit_Context_Context = value_Implicit_Context_Context;

						if (tmp_key_Implicit_Context_Context != null) {
							try {
								if (key_Implicit_Context_Context != null
										&& "INPUT_PATH".equals(key_Implicit_Context_Context)) {
									context.INPUT_PATH = value_Implicit_Context_Context;
								}

								if (key_Implicit_Context_Context != null
										&& "ClusterHadopp_User".equals(key_Implicit_Context_Context)) {
									context.ClusterHadopp_User = value_Implicit_Context_Context;
								}

								if (key_Implicit_Context_Context != null
										&& "ClusterHadopp_NameNodeUri".equals(key_Implicit_Context_Context)) {
									context.ClusterHadopp_NameNodeUri = value_Implicit_Context_Context;
								}

								if (key_Implicit_Context_Context != null
										&& "ClusterHadopp_hadoopConfSpecificJar".equals(key_Implicit_Context_Context)) {
									context.ClusterHadopp_hadoopConfSpecificJar = value_Implicit_Context_Context;
								}

								if (key_Implicit_Context_Context != null
										&& "ClusterHadopp_ResourceManager".equals(key_Implicit_Context_Context)) {
									context.ClusterHadopp_ResourceManager = value_Implicit_Context_Context;
								}

								if (key_Implicit_Context_Context != null && "ClusterHadopp_ResourceManagerScheduler"
										.equals(key_Implicit_Context_Context)) {
									context.ClusterHadopp_ResourceManagerScheduler = value_Implicit_Context_Context;
								}

								if (key_Implicit_Context_Context != null
										&& "ClusterHadopp_JobHistory".equals(key_Implicit_Context_Context)) {
									context.ClusterHadopp_JobHistory = value_Implicit_Context_Context;
								}

								if (context.getProperty(key_Implicit_Context_Context) != null) {
									assignList_Implicit_Context_Context.add(key_Implicit_Context_Context);
								} else {
									newPropertyList_Implicit_Context_Context.add(key_Implicit_Context_Context);
								}
								if (value_Implicit_Context_Context == null) {
									context.setProperty(key_Implicit_Context_Context, "");
								} else {
									context.setProperty(key_Implicit_Context_Context, value_Implicit_Context_Context);
								}
							} catch (java.lang.Exception e) {
								System.err.println("Setting a value for the key \"" + key_Implicit_Context_Context
										+ "\" has failed. Error message: " + e.getMessage());
							}
							nb_line_Implicit_Context_Context++;
						}
						//////////////////////////

						tos_count_Implicit_Context_Context++;

						/**
						 * [Implicit_Context_Context main ] stop
						 */

						/**
						 * [Implicit_Context_Context process_data_begin ] start
						 */

						currentVirtualComponent = "Implicit_Context_Context";

						currentComponent = "Implicit_Context_Context";

						/**
						 * [Implicit_Context_Context process_data_begin ] stop
						 */

						/**
						 * [Implicit_Context_Context process_data_end ] start
						 */

						currentVirtualComponent = "Implicit_Context_Context";

						currentComponent = "Implicit_Context_Context";

						/**
						 * [Implicit_Context_Context process_data_end ] stop
						 */

					} // End of branch "row_Implicit_Context_Regex"

					/**
					 * [Implicit_Context_Regex process_data_end ] start
					 */

					currentVirtualComponent = "Implicit_Context_Regex";

					currentComponent = "Implicit_Context_Regex";

					/**
					 * [Implicit_Context_Regex process_data_end ] stop
					 */

					/**
					 * [Implicit_Context_Regex end ] start
					 */

					currentVirtualComponent = "Implicit_Context_Regex";

					currentComponent = "Implicit_Context_Regex";

				}
				if (!(source_Implicit_Context_Regex instanceof java.io.InputStream)) {
					inImplicit_Context_Regex.close();
				}
				inImplicit_Context_Regex = null;
				globalMap.put("Implicit_Context_Regex_NB_LINE", nb_line_Implicit_Context_Regex);

				ok_Hash.put("Implicit_Context_Regex", true);
				end_Hash.put("Implicit_Context_Regex", System.currentTimeMillis());

				/**
				 * [Implicit_Context_Regex end ] stop
				 */

				/**
				 * [Implicit_Context_Context end ] start
				 */

				currentVirtualComponent = "Implicit_Context_Context";

				currentComponent = "Implicit_Context_Context";

				java.util.Enumeration<?> enu_Implicit_Context_Context = context.propertyNames();
				while (enu_Implicit_Context_Context.hasMoreElements()) {
					String key_Implicit_Context_Context = (String) enu_Implicit_Context_Context.nextElement();
					if (!assignList_Implicit_Context_Context.contains(key_Implicit_Context_Context)
							&& !newPropertyList_Implicit_Context_Context.contains(key_Implicit_Context_Context)) {
						noAssignList_Implicit_Context_Context.add(key_Implicit_Context_Context);
					}
				}
				for (Object obj_Implicit_Context_Context : newPropertyList_Implicit_Context_Context) {

					System.out.println("Warning: Parameter \"" + obj_Implicit_Context_Context
							+ "\" is a new parameter of Implicit_Context_Context");
				}
				for (Object obj_Implicit_Context_Context : noAssignList_Implicit_Context_Context) {

					System.out.println("Warning: Parameter \"" + obj_Implicit_Context_Context
							+ "\" has not been set by Implicit_Context_Context");

				}

				String newPropertyStr_Implicit_Context_Context = newPropertyList_Implicit_Context_Context.toString();
				String newProperty_Implicit_Context_Context = newPropertyStr_Implicit_Context_Context.substring(1,
						newPropertyStr_Implicit_Context_Context.length() - 1);

				String noAssignStr_Implicit_Context_Context = noAssignList_Implicit_Context_Context.toString();
				String noAssign_Implicit_Context_Context = noAssignStr_Implicit_Context_Context.substring(1,
						noAssignStr_Implicit_Context_Context.length() - 1);

				globalMap.put("Implicit_Context_Context_KEY_NOT_INCONTEXT", newProperty_Implicit_Context_Context);
				globalMap.put("Implicit_Context_Context_KEY_NOT_LOADED", noAssign_Implicit_Context_Context);

				globalMap.put("Implicit_Context_Context_NB_LINE", nb_line_Implicit_Context_Context);

				List<String> parametersToEncrypt_Implicit_Context_Context = new java.util.ArrayList<String>();

				resumeUtil.addLog("NODE", "NODE:Implicit_Context_Context", "", Thread.currentThread().getId() + "", "",
						"", "", "",
						resumeUtil.convertToJsonText(context, parametersToEncrypt_Implicit_Context_Context));

				if (execStat) {
					runStat.updateStat(resourceMap, iterateId, 2, 0, "Main");
				}

				ok_Hash.put("Implicit_Context_Context", true);
				end_Hash.put("Implicit_Context_Context", System.currentTimeMillis());

				/**
				 * [Implicit_Context_Context end ] stop
				 */

			} // end the resume

		} catch (java.lang.Exception e) {

			TalendException te = new TalendException(e, currentComponent, globalMap);

			te.setVirtualComponentName(currentVirtualComponent);

			throw te;
		} catch (java.lang.Error error) {

			runStat.stopThreadStat();

			throw error;
		} finally {

			try {

				/**
				 * [Implicit_Context_Regex finally ] start
				 */

				currentVirtualComponent = "Implicit_Context_Regex";

				currentComponent = "Implicit_Context_Regex";

				/**
				 * [Implicit_Context_Regex finally ] stop
				 */

				/**
				 * [Implicit_Context_Context finally ] start
				 */

				currentVirtualComponent = "Implicit_Context_Context";

				currentComponent = "Implicit_Context_Context";

				/**
				 * [Implicit_Context_Context finally ] stop
				 */

			} catch (java.lang.Exception e) {
				// ignore
			} catch (java.lang.Error error) {
				// ignore
			}
			resourceMap = null;
		}

		globalMap.put("Implicit_Context_Regex_SUBPROCESS_STATE", 1);
	}

	public static class f_deceaseStruct implements routines.system.IPersistableRow<f_deceaseStruct> {
		final static byte[] commonByteArrayLock_ETL_PROJECT_fact_deceases = new byte[0];
		static byte[] commonByteArray_ETL_PROJECT_fact_deceases = new byte[0];
		protected static final int DEFAULT_HASHCODE = 1;
		protected static final int PRIME = 31;
		protected int hashCode = DEFAULT_HASHCODE;
		public boolean hashCodeDirty = true;

		public String loopKey;

		public int Id_dec;

		public int getId_dec() {
			return this.Id_dec;
		}

		public String numero_acte_deces;

		public String getNumero_acte_deces() {
			return this.numero_acte_deces;
		}

		public Integer id_date;

		public Integer getId_date() {
			return this.id_date;
		}

		public Integer id_reg;

		public Integer getId_reg() {
			return this.id_reg;
		}

		@Override
		public int hashCode() {
			if (this.hashCodeDirty) {
				final int prime = PRIME;
				int result = DEFAULT_HASHCODE;

				result = prime * result + (int) this.Id_dec;

				this.hashCode = result;
				this.hashCodeDirty = false;
			}
			return this.hashCode;
		}

		@Override
		public boolean equals(Object obj) {
			if (this == obj)
				return true;
			if (obj == null)
				return false;
			if (getClass() != obj.getClass())
				return false;
			final f_deceaseStruct other = (f_deceaseStruct) obj;

			if (this.Id_dec != other.Id_dec)
				return false;

			return true;
		}

		public void copyDataTo(f_deceaseStruct other) {

			other.Id_dec = this.Id_dec;
			other.numero_acte_deces = this.numero_acte_deces;
			other.id_date = this.id_date;
			other.id_reg = this.id_reg;

		}

		public void copyKeysDataTo(f_deceaseStruct other) {

			other.Id_dec = this.Id_dec;

		}

		private String readString(ObjectInputStream dis) throws IOException {
			String strReturn = null;
			int length = 0;
			length = dis.readInt();
			if (length == -1) {
				strReturn = null;
			} else {
				if (length > commonByteArray_ETL_PROJECT_fact_deceases.length) {
					if (length < 1024 && commonByteArray_ETL_PROJECT_fact_deceases.length == 0) {
						commonByteArray_ETL_PROJECT_fact_deceases = new byte[1024];
					} else {
						commonByteArray_ETL_PROJECT_fact_deceases = new byte[2 * length];
					}
				}
				dis.readFully(commonByteArray_ETL_PROJECT_fact_deceases, 0, length);
				strReturn = new String(commonByteArray_ETL_PROJECT_fact_deceases, 0, length, utf8Charset);
			}
			return strReturn;
		}

		private void writeString(String str, ObjectOutputStream dos) throws IOException {
			if (str == null) {
				dos.writeInt(-1);
			} else {
				byte[] byteArray = str.getBytes(utf8Charset);
				dos.writeInt(byteArray.length);
				dos.write(byteArray);
			}
		}

		private Integer readInteger(ObjectInputStream dis) throws IOException {
			Integer intReturn;
			int length = 0;
			length = dis.readByte();
			if (length == -1) {
				intReturn = null;
			} else {
				intReturn = dis.readInt();
			}
			return intReturn;
		}

		private void writeInteger(Integer intNum, ObjectOutputStream dos) throws IOException {
			if (intNum == null) {
				dos.writeByte(-1);
			} else {
				dos.writeByte(0);
				dos.writeInt(intNum);
			}
		}

		public void readData(ObjectInputStream dis) {

			synchronized (commonByteArrayLock_ETL_PROJECT_fact_deceases) {

				try {

					int length = 0;

					this.Id_dec = dis.readInt();

					this.numero_acte_deces = readString(dis);

					this.id_date = readInteger(dis);

					this.id_reg = readInteger(dis);

				} catch (IOException e) {
					throw new RuntimeException(e);

				}

			}

		}

		public void writeData(ObjectOutputStream dos) {
			try {

				// int

				dos.writeInt(this.Id_dec);

				// String

				writeString(this.numero_acte_deces, dos);

				// Integer

				writeInteger(this.id_date, dos);

				// Integer

				writeInteger(this.id_reg, dos);

			} catch (IOException e) {
				throw new RuntimeException(e);
			}

		}

		public String toString() {

			StringBuilder sb = new StringBuilder();
			sb.append(super.toString());
			sb.append("[");
			sb.append("Id_dec=" + String.valueOf(Id_dec));
			sb.append(",numero_acte_deces=" + numero_acte_deces);
			sb.append(",id_date=" + String.valueOf(id_date));
			sb.append(",id_reg=" + String.valueOf(id_reg));
			sb.append("]");

			return sb.toString();
		}

		/**
		 * Compare keys
		 */
		public int compareTo(f_deceaseStruct other) {

			int returnValue = -1;

			returnValue = checkNullsAndCompare(this.Id_dec, other.Id_dec);
			if (returnValue != 0) {
				return returnValue;
			}

			return returnValue;
		}

		private int checkNullsAndCompare(Object object1, Object object2) {
			int returnValue = 0;
			if (object1 instanceof Comparable && object2 instanceof Comparable) {
				returnValue = ((Comparable) object1).compareTo(object2);
			} else if (object1 != null && object2 != null) {
				returnValue = compareStrings(object1.toString(), object2.toString());
			} else if (object1 == null && object2 != null) {
				returnValue = 1;
			} else if (object1 != null && object2 == null) {
				returnValue = -1;
			} else {
				returnValue = 0;
			}

			return returnValue;
		}

		private int compareStrings(String string1, String string2) {
			return string1.compareTo(string2);
		}

	}

	public static class row1Struct implements routines.system.IPersistableRow<row1Struct> {
		final static byte[] commonByteArrayLock_ETL_PROJECT_fact_deceases = new byte[0];
		static byte[] commonByteArray_ETL_PROJECT_fact_deceases = new byte[0];

		public String nom;

		public String getNom() {
			return this.nom;
		}

		public String prenom;

		public String getPrenom() {
			return this.prenom;
		}

		public String sexe;

		public String getSexe() {
			return this.sexe;
		}

		public String date_naissance;

		public String getDate_naissance() {
			return this.date_naissance;
		}

		public String code_lieu_naissance;

		public String getCode_lieu_naissance() {
			return this.code_lieu_naissance;
		}

		public String lieu_naissance;

		public String getLieu_naissance() {
			return this.lieu_naissance;
		}

		public String pays_naissance;

		public String getPays_naissance() {
			return this.pays_naissance;
		}

		public String date_deces;

		public String getDate_deces() {
			return this.date_deces;
		}

		public String code_lieu_deces;

		public String getCode_lieu_deces() {
			return this.code_lieu_deces;
		}

		public String numero_acte_deces;

		public String getNumero_acte_deces() {
			return this.numero_acte_deces;
		}

		private String readString(ObjectInputStream dis) throws IOException {
			String strReturn = null;
			int length = 0;
			length = dis.readInt();
			if (length == -1) {
				strReturn = null;
			} else {
				if (length > commonByteArray_ETL_PROJECT_fact_deceases.length) {
					if (length < 1024 && commonByteArray_ETL_PROJECT_fact_deceases.length == 0) {
						commonByteArray_ETL_PROJECT_fact_deceases = new byte[1024];
					} else {
						commonByteArray_ETL_PROJECT_fact_deceases = new byte[2 * length];
					}
				}
				dis.readFully(commonByteArray_ETL_PROJECT_fact_deceases, 0, length);
				strReturn = new String(commonByteArray_ETL_PROJECT_fact_deceases, 0, length, utf8Charset);
			}
			return strReturn;
		}

		private void writeString(String str, ObjectOutputStream dos) throws IOException {
			if (str == null) {
				dos.writeInt(-1);
			} else {
				byte[] byteArray = str.getBytes(utf8Charset);
				dos.writeInt(byteArray.length);
				dos.write(byteArray);
			}
		}

		public void readData(ObjectInputStream dis) {

			synchronized (commonByteArrayLock_ETL_PROJECT_fact_deceases) {

				try {

					int length = 0;

					this.nom = readString(dis);

					this.prenom = readString(dis);

					this.sexe = readString(dis);

					this.date_naissance = readString(dis);

					this.code_lieu_naissance = readString(dis);

					this.lieu_naissance = readString(dis);

					this.pays_naissance = readString(dis);

					this.date_deces = readString(dis);

					this.code_lieu_deces = readString(dis);

					this.numero_acte_deces = readString(dis);

				} catch (IOException e) {
					throw new RuntimeException(e);

				}

			}

		}

		public void writeData(ObjectOutputStream dos) {
			try {

				// String

				writeString(this.nom, dos);

				// String

				writeString(this.prenom, dos);

				// String

				writeString(this.sexe, dos);

				// String

				writeString(this.date_naissance, dos);

				// String

				writeString(this.code_lieu_naissance, dos);

				// String

				writeString(this.lieu_naissance, dos);

				// String

				writeString(this.pays_naissance, dos);

				// String

				writeString(this.date_deces, dos);

				// String

				writeString(this.code_lieu_deces, dos);

				// String

				writeString(this.numero_acte_deces, dos);

			} catch (IOException e) {
				throw new RuntimeException(e);
			}

		}

		public String toString() {

			StringBuilder sb = new StringBuilder();
			sb.append(super.toString());
			sb.append("[");
			sb.append("nom=" + nom);
			sb.append(",prenom=" + prenom);
			sb.append(",sexe=" + sexe);
			sb.append(",date_naissance=" + date_naissance);
			sb.append(",code_lieu_naissance=" + code_lieu_naissance);
			sb.append(",lieu_naissance=" + lieu_naissance);
			sb.append(",pays_naissance=" + pays_naissance);
			sb.append(",date_deces=" + date_deces);
			sb.append(",code_lieu_deces=" + code_lieu_deces);
			sb.append(",numero_acte_deces=" + numero_acte_deces);
			sb.append("]");

			return sb.toString();
		}

		/**
		 * Compare keys
		 */
		public int compareTo(row1Struct other) {

			int returnValue = -1;

			return returnValue;
		}

		private int checkNullsAndCompare(Object object1, Object object2) {
			int returnValue = 0;
			if (object1 instanceof Comparable && object2 instanceof Comparable) {
				returnValue = ((Comparable) object1).compareTo(object2);
			} else if (object1 != null && object2 != null) {
				returnValue = compareStrings(object1.toString(), object2.toString());
			} else if (object1 == null && object2 != null) {
				returnValue = 1;
			} else if (object1 != null && object2 == null) {
				returnValue = -1;
			} else {
				returnValue = 0;
			}

			return returnValue;
		}

		private int compareStrings(String string1, String string2) {
			return string1.compareTo(string2);
		}

	}

	public static class after_tFileInputDelimited_1Struct
			implements routines.system.IPersistableRow<after_tFileInputDelimited_1Struct> {
		final static byte[] commonByteArrayLock_ETL_PROJECT_fact_deceases = new byte[0];
		static byte[] commonByteArray_ETL_PROJECT_fact_deceases = new byte[0];

		public String nom;

		public String getNom() {
			return this.nom;
		}

		public String prenom;

		public String getPrenom() {
			return this.prenom;
		}

		public String sexe;

		public String getSexe() {
			return this.sexe;
		}

		public String date_naissance;

		public String getDate_naissance() {
			return this.date_naissance;
		}

		public String code_lieu_naissance;

		public String getCode_lieu_naissance() {
			return this.code_lieu_naissance;
		}

		public String lieu_naissance;

		public String getLieu_naissance() {
			return this.lieu_naissance;
		}

		public String pays_naissance;

		public String getPays_naissance() {
			return this.pays_naissance;
		}

		public String date_deces;

		public String getDate_deces() {
			return this.date_deces;
		}

		public String code_lieu_deces;

		public String getCode_lieu_deces() {
			return this.code_lieu_deces;
		}

		public String numero_acte_deces;

		public String getNumero_acte_deces() {
			return this.numero_acte_deces;
		}

		private String readString(ObjectInputStream dis) throws IOException {
			String strReturn = null;
			int length = 0;
			length = dis.readInt();
			if (length == -1) {
				strReturn = null;
			} else {
				if (length > commonByteArray_ETL_PROJECT_fact_deceases.length) {
					if (length < 1024 && commonByteArray_ETL_PROJECT_fact_deceases.length == 0) {
						commonByteArray_ETL_PROJECT_fact_deceases = new byte[1024];
					} else {
						commonByteArray_ETL_PROJECT_fact_deceases = new byte[2 * length];
					}
				}
				dis.readFully(commonByteArray_ETL_PROJECT_fact_deceases, 0, length);
				strReturn = new String(commonByteArray_ETL_PROJECT_fact_deceases, 0, length, utf8Charset);
			}
			return strReturn;
		}

		private void writeString(String str, ObjectOutputStream dos) throws IOException {
			if (str == null) {
				dos.writeInt(-1);
			} else {
				byte[] byteArray = str.getBytes(utf8Charset);
				dos.writeInt(byteArray.length);
				dos.write(byteArray);
			}
		}

		public void readData(ObjectInputStream dis) {

			synchronized (commonByteArrayLock_ETL_PROJECT_fact_deceases) {

				try {

					int length = 0;

					this.nom = readString(dis);

					this.prenom = readString(dis);

					this.sexe = readString(dis);

					this.date_naissance = readString(dis);

					this.code_lieu_naissance = readString(dis);

					this.lieu_naissance = readString(dis);

					this.pays_naissance = readString(dis);

					this.date_deces = readString(dis);

					this.code_lieu_deces = readString(dis);

					this.numero_acte_deces = readString(dis);

				} catch (IOException e) {
					throw new RuntimeException(e);

				}

			}

		}

		public void writeData(ObjectOutputStream dos) {
			try {

				// String

				writeString(this.nom, dos);

				// String

				writeString(this.prenom, dos);

				// String

				writeString(this.sexe, dos);

				// String

				writeString(this.date_naissance, dos);

				// String

				writeString(this.code_lieu_naissance, dos);

				// String

				writeString(this.lieu_naissance, dos);

				// String

				writeString(this.pays_naissance, dos);

				// String

				writeString(this.date_deces, dos);

				// String

				writeString(this.code_lieu_deces, dos);

				// String

				writeString(this.numero_acte_deces, dos);

			} catch (IOException e) {
				throw new RuntimeException(e);
			}

		}

		public String toString() {

			StringBuilder sb = new StringBuilder();
			sb.append(super.toString());
			sb.append("[");
			sb.append("nom=" + nom);
			sb.append(",prenom=" + prenom);
			sb.append(",sexe=" + sexe);
			sb.append(",date_naissance=" + date_naissance);
			sb.append(",code_lieu_naissance=" + code_lieu_naissance);
			sb.append(",lieu_naissance=" + lieu_naissance);
			sb.append(",pays_naissance=" + pays_naissance);
			sb.append(",date_deces=" + date_deces);
			sb.append(",code_lieu_deces=" + code_lieu_deces);
			sb.append(",numero_acte_deces=" + numero_acte_deces);
			sb.append("]");

			return sb.toString();
		}

		/**
		 * Compare keys
		 */
		public int compareTo(after_tFileInputDelimited_1Struct other) {

			int returnValue = -1;

			return returnValue;
		}

		private int checkNullsAndCompare(Object object1, Object object2) {
			int returnValue = 0;
			if (object1 instanceof Comparable && object2 instanceof Comparable) {
				returnValue = ((Comparable) object1).compareTo(object2);
			} else if (object1 != null && object2 != null) {
				returnValue = compareStrings(object1.toString(), object2.toString());
			} else if (object1 == null && object2 != null) {
				returnValue = 1;
			} else if (object1 != null && object2 == null) {
				returnValue = -1;
			} else {
				returnValue = 0;
			}

			return returnValue;
		}

		private int compareStrings(String string1, String string2) {
			return string1.compareTo(string2);
		}

	}

	public void tFileInputDelimited_1Process(final java.util.Map<String, Object> globalMap) throws TalendException {
		globalMap.put("tFileInputDelimited_1_SUBPROCESS_STATE", 0);

		final boolean execStat = this.execStat;

		String iterateId = "";

		String currentComponent = "";
		java.util.Map<String, Object> resourceMap = new java.util.HashMap<String, Object>();

		try {
			// TDI-39566 avoid throwing an useless Exception
			boolean resumeIt = true;
			if (globalResumeTicket == false && resumeEntryMethodName != null) {
				String currentMethodName = new java.lang.Exception().getStackTrace()[0].getMethodName();
				resumeIt = resumeEntryMethodName.equals(currentMethodName);
			}
			if (resumeIt || globalResumeTicket) { // start the resume
				globalResumeTicket = true;

				tHiveInput_1Process(globalMap);
				tHiveInput_2Process(globalMap);

				row1Struct row1 = new row1Struct();
				f_deceaseStruct f_decease = new f_deceaseStruct();

				/**
				 * [tHDFSOutput_1 begin ] start
				 */

				ok_Hash.put("tHDFSOutput_1", false);
				start_Hash.put("tHDFSOutput_1", System.currentTimeMillis());

				currentComponent = "tHDFSOutput_1";

				if (execStat) {
					runStat.updateStatOnConnection(resourceMap, iterateId, 0, 0, "f_decease");
				}

				int tos_count_tHDFSOutput_1 = 0;

				String username_tHDFSOutput_1 = "";
				org.apache.hadoop.fs.FileSystem fs_tHDFSOutput_1 = null;
				org.apache.hadoop.conf.Configuration conf_tHDFSOutput_1 = new org.apache.hadoop.conf.Configuration();

				conf_tHDFSOutput_1.set("fs.default.name", context.ClusterHadopp_NameNodeUri);

				conf_tHDFSOutput_1.set("dfs.client.use.datanode.hostname", "true");

				org.apache.hadoop.security.UserGroupInformation.setConfiguration(conf_tHDFSOutput_1);
				username_tHDFSOutput_1 = "cloudera";
				if (username_tHDFSOutput_1 == null || "".equals(username_tHDFSOutput_1)) {
					fs_tHDFSOutput_1 = org.apache.hadoop.fs.FileSystem.get(conf_tHDFSOutput_1);
				} else {
					System.setProperty("HADOOP_USER_NAME", username_tHDFSOutput_1);
					fs_tHDFSOutput_1 = org.apache.hadoop.fs.FileSystem.get(
							new java.net.URI(conf_tHDFSOutput_1.get("fs.default.name")), conf_tHDFSOutput_1,
							username_tHDFSOutput_1);
				}

				org.apache.hadoop.fs.Path path_tHDFSOutput_1 = new org.apache.hadoop.fs.Path(
						"/user/talend/warehouse/f_decease/f_decease.txt");
				int nb_line_tHDFSOutput_1 = 0;

				org.apache.hadoop.fs.FSDataOutputStream fsDataOutputStream_tHDFSOutput_1 = null;

				fsDataOutputStream_tHDFSOutput_1 = fs_tHDFSOutput_1.create(path_tHDFSOutput_1, true);

				java.io.Writer outtHDFSOutput_1 = null;
				outtHDFSOutput_1 = new java.io.BufferedWriter(
						new java.io.OutputStreamWriter(fsDataOutputStream_tHDFSOutput_1));

				/**
				 * [tHDFSOutput_1 begin ] stop
				 */

				/**
				 * [tMap_1 begin ] start
				 */

				ok_Hash.put("tMap_1", false);
				start_Hash.put("tMap_1", System.currentTimeMillis());

				currentComponent = "tMap_1";

				if (execStat) {
					runStat.updateStatOnConnection(resourceMap, iterateId, 0, 0, "row1");
				}

				int tos_count_tMap_1 = 0;

// ###############################
// # Lookup's keys initialization

				org.talend.designer.components.lookup.memory.AdvancedMemoryLookup<row2Struct> tHash_Lookup_row2 = (org.talend.designer.components.lookup.memory.AdvancedMemoryLookup<row2Struct>) ((org.talend.designer.components.lookup.memory.AdvancedMemoryLookup<row2Struct>) globalMap
						.get("tHash_Lookup_row2"));

				row2Struct row2HashKey = new row2Struct();
				row2Struct row2Default = new row2Struct();

				org.talend.designer.components.lookup.memory.AdvancedMemoryLookup<row3Struct> tHash_Lookup_row3 = (org.talend.designer.components.lookup.memory.AdvancedMemoryLookup<row3Struct>) ((org.talend.designer.components.lookup.memory.AdvancedMemoryLookup<row3Struct>) globalMap
						.get("tHash_Lookup_row3"));

				row3Struct row3HashKey = new row3Struct();
				row3Struct row3Default = new row3Struct();
// ###############################        

// ###############################
// # Vars initialization
				class Var__tMap_1__Struct {
				}
				Var__tMap_1__Struct Var__tMap_1 = new Var__tMap_1__Struct();
// ###############################

// ###############################
// # Outputs initialization
				f_deceaseStruct f_decease_tmp = new f_deceaseStruct();
// ###############################

				/**
				 * [tMap_1 begin ] stop
				 */

				/**
				 * [tFileInputDelimited_1 begin ] start
				 */

				ok_Hash.put("tFileInputDelimited_1", false);
				start_Hash.put("tFileInputDelimited_1", System.currentTimeMillis());

				currentComponent = "tFileInputDelimited_1";

				int tos_count_tFileInputDelimited_1 = 0;

				final routines.system.RowState rowstate_tFileInputDelimited_1 = new routines.system.RowState();

				int nb_line_tFileInputDelimited_1 = 0;
				org.talend.fileprocess.FileInputDelimited fid_tFileInputDelimited_1 = null;
				int limit_tFileInputDelimited_1 = -1;
				try {

					Object filename_tFileInputDelimited_1 = context.INPUT_PATH + "deces.csv";
					if (filename_tFileInputDelimited_1 instanceof java.io.InputStream) {

						int footer_value_tFileInputDelimited_1 = 0, random_value_tFileInputDelimited_1 = -1;
						if (footer_value_tFileInputDelimited_1 > 0 || random_value_tFileInputDelimited_1 > 0) {
							throw new java.lang.Exception(
									"When the input source is a stream,footer and random shouldn't be bigger than 0.");
						}

					}
					try {
						fid_tFileInputDelimited_1 = new org.talend.fileprocess.FileInputDelimited(
								context.INPUT_PATH + "deces.csv", "ISO-8859-15", ",", "\n", true, 1, 0,
								limit_tFileInputDelimited_1, -1, false);
					} catch (java.lang.Exception e) {

						System.err.println(e.getMessage());

					}

					while (fid_tFileInputDelimited_1 != null && fid_tFileInputDelimited_1.nextRecord()) {
						rowstate_tFileInputDelimited_1.reset();

						row1 = null;

						boolean whetherReject_tFileInputDelimited_1 = false;
						row1 = new row1Struct();
						try {

							int columnIndexWithD_tFileInputDelimited_1 = 0;

							columnIndexWithD_tFileInputDelimited_1 = 0;

							row1.nom = fid_tFileInputDelimited_1.get(columnIndexWithD_tFileInputDelimited_1);

							columnIndexWithD_tFileInputDelimited_1 = 1;

							row1.prenom = fid_tFileInputDelimited_1.get(columnIndexWithD_tFileInputDelimited_1);

							columnIndexWithD_tFileInputDelimited_1 = 2;

							row1.sexe = fid_tFileInputDelimited_1.get(columnIndexWithD_tFileInputDelimited_1);

							columnIndexWithD_tFileInputDelimited_1 = 3;

							row1.date_naissance = fid_tFileInputDelimited_1.get(columnIndexWithD_tFileInputDelimited_1);

							columnIndexWithD_tFileInputDelimited_1 = 4;

							row1.code_lieu_naissance = fid_tFileInputDelimited_1
									.get(columnIndexWithD_tFileInputDelimited_1);

							columnIndexWithD_tFileInputDelimited_1 = 5;

							row1.lieu_naissance = fid_tFileInputDelimited_1.get(columnIndexWithD_tFileInputDelimited_1);

							columnIndexWithD_tFileInputDelimited_1 = 6;

							row1.pays_naissance = fid_tFileInputDelimited_1.get(columnIndexWithD_tFileInputDelimited_1);

							columnIndexWithD_tFileInputDelimited_1 = 7;

							row1.date_deces = fid_tFileInputDelimited_1.get(columnIndexWithD_tFileInputDelimited_1);

							columnIndexWithD_tFileInputDelimited_1 = 8;

							row1.code_lieu_deces = fid_tFileInputDelimited_1
									.get(columnIndexWithD_tFileInputDelimited_1);

							columnIndexWithD_tFileInputDelimited_1 = 9;

							row1.numero_acte_deces = fid_tFileInputDelimited_1
									.get(columnIndexWithD_tFileInputDelimited_1);

							if (rowstate_tFileInputDelimited_1.getException() != null) {
								throw rowstate_tFileInputDelimited_1.getException();
							}

						} catch (java.lang.Exception e) {
							whetherReject_tFileInputDelimited_1 = true;

							System.err.println(e.getMessage());
							row1 = null;

						}

						/**
						 * [tFileInputDelimited_1 begin ] stop
						 */

						/**
						 * [tFileInputDelimited_1 main ] start
						 */

						currentComponent = "tFileInputDelimited_1";

						tos_count_tFileInputDelimited_1++;

						/**
						 * [tFileInputDelimited_1 main ] stop
						 */

						/**
						 * [tFileInputDelimited_1 process_data_begin ] start
						 */

						currentComponent = "tFileInputDelimited_1";

						/**
						 * [tFileInputDelimited_1 process_data_begin ] stop
						 */
// Start of branch "row1"
						if (row1 != null) {

							/**
							 * [tMap_1 main ] start
							 */

							currentComponent = "tMap_1";

							if (execStat) {
								runStat.updateStatOnConnection(iterateId, 1, 1, "row1");
							}

							boolean hasCasePrimitiveKeyWithNull_tMap_1 = false;

							// ###############################
							// # Input tables (lookups)
							boolean rejectedInnerJoin_tMap_1 = false;
							boolean mainRowRejected_tMap_1 = false;

							///////////////////////////////////////////////
							// Starting Lookup Table "row2"
							///////////////////////////////////////////////

							boolean forceLooprow2 = false;

							row2Struct row2ObjectFromLookup = null;

							if (!rejectedInnerJoin_tMap_1) { // G_TM_M_020

								hasCasePrimitiveKeyWithNull_tMap_1 = false;

								row2HashKey.date = (row1.date_deces == null || row1.date_deces.trim().isEmpty()) ? null
										: (row1.date_deces.trim().replace('-', '/').replace('.', '/')
												.matches("\\d{4}/\\d{2}/\\d{2}")
														? routines.TalendDate.parseDate("yyyy/MM/dd",
																row1.date_deces.trim().replace('-', '/').replace('.',
																		'/'))
														: (row1.date_deces.trim().replace('-', '/').replace('.', '/')
																.matches("\\d{4}/\\d{2}")
																		? routines.TalendDate.parseDate("yyyy/MM/dd",
																				row1.date_deces.trim().replace('-', '/')
																						.replace('.', '/') + "/01")
																		: (row1.date_deces.trim().matches("\\d{4}")
																				? routines.TalendDate.parseDate(
																						"yyyy/MM/dd",
																						row1.date_deces.trim()
																								+ "/01/01")
																				: null))) == null
																						? null
																						: new java.util.Date(
																								(row1.date_deces == null
																										|| row1.date_deces
																												.trim()
																												.isEmpty())
																														? null
																														: (row1.date_deces
																																.trim()
																																.replace(
																																		'-',
																																		'/')
																																.replace(
																																		'.',
																																		'/')
																																.matches(
																																		"\\d{4}/\\d{2}/\\d{2}")
																																				? routines.TalendDate
																																						.parseDate(
																																								"yyyy/MM/dd",
																																								row1.date_deces
																																										.trim()
																																										.replace(
																																												'-',
																																												'/')
																																										.replace(
																																												'.',
																																												'/'))
																																				: (row1.date_deces
																																						.trim()
																																						.replace(
																																								'-',
																																								'/')
																																						.replace(
																																								'.',
																																								'/')
																																						.matches(
																																								"\\d{4}/\\d{2}")
																																										? routines.TalendDate
																																												.parseDate(
																																														"yyyy/MM/dd",
																																														row1.date_deces
																																																.trim()
																																																.replace(
																																																		'-',
																																																		'/')
																																																.replace(
																																																		'.',
																																																		'/')
																																																+ "/01")
																																										: (row1.date_deces
																																												.trim()
																																												.matches(
																																														"\\d{4}")
																																																? routines.TalendDate
																																																		.parseDate(
																																																				"yyyy/MM/dd",
																																																				row1.date_deces
																																																						.trim()
																																																						+ "/01/01")
																																																: null)))
																																																		.getTime());

								row2HashKey.hashCodeDirty = true;

								tHash_Lookup_row2.lookup(row2HashKey);

							} // G_TM_M_020

							if (tHash_Lookup_row2 != null && tHash_Lookup_row2.getCount(row2HashKey) > 1) { // G 071

								// System.out.println("WARNING: UNIQUE MATCH is configured for the lookup 'row2'
								// and it contains more one result from keys : row2.date = '" + row2HashKey.date
								// + "'");
							} // G 071

							row2Struct row2 = null;

							row2Struct fromLookup_row2 = null;
							row2 = row2Default;

							if (tHash_Lookup_row2 != null && tHash_Lookup_row2.hasNext()) { // G 099

								fromLookup_row2 = tHash_Lookup_row2.next();

							} // G 099

							if (fromLookup_row2 != null) {
								row2 = fromLookup_row2;
							}

							///////////////////////////////////////////////
							// Starting Lookup Table "row3"
							///////////////////////////////////////////////

							boolean forceLooprow3 = false;

							row3Struct row3ObjectFromLookup = null;

							if (!rejectedInnerJoin_tMap_1) { // G_TM_M_020

								tHash_Lookup_row3.lookup(row3HashKey);

							} // G_TM_M_020

							if (tHash_Lookup_row3 != null && tHash_Lookup_row3.getCount(row3HashKey) > 1) { // G 071

								// System.out.println("WARNING: UNIQUE MATCH is configured for the lookup 'row3'
								// and it contains more one result from keys : ");
							} // G 071

							row3Struct row3 = null;

							row3Struct fromLookup_row3 = null;
							row3 = row3Default;

							if (tHash_Lookup_row3 != null && tHash_Lookup_row3.hasNext()) { // G 099

								fromLookup_row3 = tHash_Lookup_row3.next();

							} // G 099

							if (fromLookup_row3 != null) {
								row3 = fromLookup_row3;
							}

							// ###############################
							{ // start of Var scope

								// ###############################
								// # Vars tables

								Var__tMap_1__Struct Var = Var__tMap_1;// ###############################
								// ###############################
								// # Output tables

								f_decease = null;

// # Output table : 'f_decease'
								f_decease_tmp.Id_dec = Numeric.sequence("s1", 1, 1);
								f_decease_tmp.numero_acte_deces = row1.numero_acte_deces;
								f_decease_tmp.id_date = row2.id_date;
								f_decease_tmp.id_reg = row3.id_reg;
								f_decease = f_decease_tmp;
// ###############################

							} // end of Var scope

							rejectedInnerJoin_tMap_1 = false;

							tos_count_tMap_1++;

							/**
							 * [tMap_1 main ] stop
							 */

							/**
							 * [tMap_1 process_data_begin ] start
							 */

							currentComponent = "tMap_1";

							/**
							 * [tMap_1 process_data_begin ] stop
							 */
// Start of branch "f_decease"
							if (f_decease != null) {

								/**
								 * [tHDFSOutput_1 main ] start
								 */

								currentComponent = "tHDFSOutput_1";

								if (execStat) {
									runStat.updateStatOnConnection(iterateId, 1, 1, "f_decease");
								}

								StringBuilder sb_tHDFSOutput_1 = new StringBuilder();

								sb_tHDFSOutput_1.append(

										f_decease.Id_dec

								);

								sb_tHDFSOutput_1.append(";");

								if (f_decease.numero_acte_deces != null) {

									sb_tHDFSOutput_1.append(

											f_decease.numero_acte_deces

									);

								}

								sb_tHDFSOutput_1.append(";");

								if (f_decease.id_date != null) {

									sb_tHDFSOutput_1.append(

											f_decease.id_date

									);

								}

								sb_tHDFSOutput_1.append(";");

								if (f_decease.id_reg != null) {

									sb_tHDFSOutput_1.append(

											f_decease.id_reg

									);

								}

								sb_tHDFSOutput_1.append("\n");

								outtHDFSOutput_1.write(sb_tHDFSOutput_1.toString());

								nb_line_tHDFSOutput_1++;

								tos_count_tHDFSOutput_1++;

								/**
								 * [tHDFSOutput_1 main ] stop
								 */

								/**
								 * [tHDFSOutput_1 process_data_begin ] start
								 */

								currentComponent = "tHDFSOutput_1";

								/**
								 * [tHDFSOutput_1 process_data_begin ] stop
								 */

								/**
								 * [tHDFSOutput_1 process_data_end ] start
								 */

								currentComponent = "tHDFSOutput_1";

								/**
								 * [tHDFSOutput_1 process_data_end ] stop
								 */

							} // End of branch "f_decease"

							/**
							 * [tMap_1 process_data_end ] start
							 */

							currentComponent = "tMap_1";

							/**
							 * [tMap_1 process_data_end ] stop
							 */

						} // End of branch "row1"

						/**
						 * [tFileInputDelimited_1 process_data_end ] start
						 */

						currentComponent = "tFileInputDelimited_1";

						/**
						 * [tFileInputDelimited_1 process_data_end ] stop
						 */

						/**
						 * [tFileInputDelimited_1 end ] start
						 */

						currentComponent = "tFileInputDelimited_1";

					}
				} finally {
					if (!((Object) (context.INPUT_PATH + "deces.csv") instanceof java.io.InputStream)) {
						if (fid_tFileInputDelimited_1 != null) {
							fid_tFileInputDelimited_1.close();
						}
					}
					if (fid_tFileInputDelimited_1 != null) {
						globalMap.put("tFileInputDelimited_1_NB_LINE", fid_tFileInputDelimited_1.getRowNumber());

					}
				}

				ok_Hash.put("tFileInputDelimited_1", true);
				end_Hash.put("tFileInputDelimited_1", System.currentTimeMillis());

				/**
				 * [tFileInputDelimited_1 end ] stop
				 */

				/**
				 * [tMap_1 end ] start
				 */

				currentComponent = "tMap_1";

// ###############################
// # Lookup hashes releasing
				if (tHash_Lookup_row2 != null) {
					tHash_Lookup_row2.endGet();
				}
				globalMap.remove("tHash_Lookup_row2");

				if (tHash_Lookup_row3 != null) {
					tHash_Lookup_row3.endGet();
				}
				globalMap.remove("tHash_Lookup_row3");

// ###############################      

				if (execStat) {
					runStat.updateStat(resourceMap, iterateId, 2, 0, "row1");
				}

				ok_Hash.put("tMap_1", true);
				end_Hash.put("tMap_1", System.currentTimeMillis());

				/**
				 * [tMap_1 end ] stop
				 */

				/**
				 * [tHDFSOutput_1 end ] start
				 */

				currentComponent = "tHDFSOutput_1";

				if (outtHDFSOutput_1 != null) {
					outtHDFSOutput_1.close();
				}

				if (execStat) {
					runStat.updateStat(resourceMap, iterateId, 2, 0, "f_decease");
				}

				ok_Hash.put("tHDFSOutput_1", true);
				end_Hash.put("tHDFSOutput_1", System.currentTimeMillis());

				if (execStat) {
					runStat.updateStatOnConnection("OnComponentOk1", 0, "ok");
				}
				tHiveCreateTable_1Process(globalMap);

				/**
				 * [tHDFSOutput_1 end ] stop
				 */

			} // end the resume

		} catch (java.lang.Exception e) {

			TalendException te = new TalendException(e, currentComponent, globalMap);

			throw te;
		} catch (java.lang.Error error) {

			runStat.stopThreadStat();

			throw error;
		} finally {

			// free memory for "tMap_1"
			globalMap.remove("tHash_Lookup_row2");

			// free memory for "tMap_1"
			globalMap.remove("tHash_Lookup_row3");

			try {

				/**
				 * [tFileInputDelimited_1 finally ] start
				 */

				currentComponent = "tFileInputDelimited_1";

				/**
				 * [tFileInputDelimited_1 finally ] stop
				 */

				/**
				 * [tMap_1 finally ] start
				 */

				currentComponent = "tMap_1";

				/**
				 * [tMap_1 finally ] stop
				 */

				/**
				 * [tHDFSOutput_1 finally ] start
				 */

				currentComponent = "tHDFSOutput_1";

				/**
				 * [tHDFSOutput_1 finally ] stop
				 */

			} catch (java.lang.Exception e) {
				// ignore
			} catch (java.lang.Error error) {
				// ignore
			}
			resourceMap = null;
		}

		globalMap.put("tFileInputDelimited_1_SUBPROCESS_STATE", 1);
	}

	public void tHiveCreateTable_1Process(final java.util.Map<String, Object> globalMap) throws TalendException {
		globalMap.put("tHiveCreateTable_1_SUBPROCESS_STATE", 0);

		final boolean execStat = this.execStat;

		String iterateId = "";

		String currentComponent = "";
		java.util.Map<String, Object> resourceMap = new java.util.HashMap<String, Object>();

		try {
			// TDI-39566 avoid throwing an useless Exception
			boolean resumeIt = true;
			if (globalResumeTicket == false && resumeEntryMethodName != null) {
				String currentMethodName = new java.lang.Exception().getStackTrace()[0].getMethodName();
				resumeIt = resumeEntryMethodName.equals(currentMethodName);
			}
			if (resumeIt || globalResumeTicket) { // start the resume
				globalResumeTicket = true;

				/**
				 * [tHiveCreateTable_1 begin ] start
				 */

				ok_Hash.put("tHiveCreateTable_1", false);
				start_Hash.put("tHiveCreateTable_1", System.currentTimeMillis());

				currentComponent = "tHiveCreateTable_1";

				int tos_count_tHiveCreateTable_1 = 0;

				/**
				 * [tHiveCreateTable_1 begin ] stop
				 */

				/**
				 * [tHiveCreateTable_1 main ] start
				 */

				currentComponent = "tHiveCreateTable_1";

				java.sql.Connection conn_tHiveCreateTable_1 = null;
				globalMap.put("current_client_path_separator", System.getProperty("path.separator"));
				System.setProperty("path.separator", ":");
				String dbUser_tHiveCreateTable_1 = "cloudera";

				final String decryptedPassword_tHiveCreateTable_1 = routines.system.PasswordEncryptUtil
						.decryptPassword("enc:routine.encryption.key.v1:cFQ/TRelnJRt69y54dEdWNfQY+Lu/mSjIL6cdA==");

				String dbPwd_tHiveCreateTable_1 = decryptedPassword_tHiveCreateTable_1;

				globalMap.put("HADOOP_USER_NAME_tHiveCreateTable_1", System.getProperty("HADOOP_USER_NAME"));
				String url_tHiveCreateTable_1 = "jdbc:hive2://" + "quickstart.cloudera" + ":" + "10000" + "/" + "chu";
				String additionalJdbcSettings_tHiveCreateTable_1 = "";
				if (!"".equals(additionalJdbcSettings_tHiveCreateTable_1.trim())) {
					if (!additionalJdbcSettings_tHiveCreateTable_1.startsWith(";")) {
						additionalJdbcSettings_tHiveCreateTable_1 = ";" + additionalJdbcSettings_tHiveCreateTable_1;
					}
					url_tHiveCreateTable_1 += additionalJdbcSettings_tHiveCreateTable_1;
				}
				String driverClass_tHiveCreateTable_1 = "org.apache.hive.jdbc.HiveDriver";
				java.lang.Class.forName(driverClass_tHiveCreateTable_1);

				conn_tHiveCreateTable_1 = java.sql.DriverManager.getConnection(url_tHiveCreateTable_1,
						dbUser_tHiveCreateTable_1, dbPwd_tHiveCreateTable_1);

				java.sql.Statement init_tHiveCreateTable_1 = conn_tHiveCreateTable_1.createStatement();
				init_tHiveCreateTable_1.execute("SET dfs.client.use.datanode.hostname=true");

				init_tHiveCreateTable_1.close();

				String dbname_tHiveCreateTable_1 = "chu";
				if (dbname_tHiveCreateTable_1 != null && !"".equals(dbname_tHiveCreateTable_1.trim())
						&& !"default".equals(dbname_tHiveCreateTable_1.trim())) {
					java.sql.Statement goToDatabase_tHiveCreateTable_1 = conn_tHiveCreateTable_1.createStatement();
					goToDatabase_tHiveCreateTable_1.execute("use " + dbname_tHiveCreateTable_1);
					goToDatabase_tHiveCreateTable_1.close();
				}

				java.sql.Statement stmt_tHiveCreateTable_1 = conn_tHiveCreateTable_1.createStatement();
				String query_tHiveCreateTable_1 = "";
				String tableName_tHiveCreateTable_1 = "f_decease";
				String fieldChar_tHiveCreateTable_1 = ";";
				String location_tHiveCreateTable_1 = "/user/talend/warehouse/f_decease/";
				String querySQL_tHiveCreateTable_1 = "CREATE  TABLE IF NOT EXISTS " + tableName_tHiveCreateTable_1
						+ "(Id_dec INT,numero_acte_deces STRING,id_date INT,id_reg INT) ROW FORMAT DELIMITED  FIELDS TERMINATED BY '"
						+ fieldChar_tHiveCreateTable_1 + "' STORED AS TEXTFILE LOCATION '" + location_tHiveCreateTable_1
						+ "'";
				try {

					java.text.DateFormat dateStrFormat_tHiveCreateTable_1 = new java.text.SimpleDateFormat(
							"yyyyMMddHHmmss");
					final String queryIdentifier_tHiveCreateTable_1 = projectName + "_" + jobName + "_"
							+ jobVersion.replace(".", "_") + "_tHiveCreateTable_1_"
							+ dateStrFormat_tHiveCreateTable_1.format(new Date(startTime));
// For MapReduce Mode
					stmt_tHiveCreateTable_1.execute("set mapred.job.name=" + queryIdentifier_tHiveCreateTable_1);
					stmt_tHiveCreateTable_1.execute(querySQL_tHiveCreateTable_1);
				} catch (java.sql.SQLException e_tHiveCreateTable_1) {
					System.err.println(e_tHiveCreateTable_1.getMessage());
				}
				stmt_tHiveCreateTable_1.close();

				conn_tHiveCreateTable_1.close();

				globalMap.put("tHiveCreateTable_1_QUERY", querySQL_tHiveCreateTable_1);

				String currentClientPathSeparator_tHiveCreateTable_1 = (String) globalMap
						.get("current_client_path_separator");
				if (currentClientPathSeparator_tHiveCreateTable_1 != null) {
					System.setProperty("path.separator", currentClientPathSeparator_tHiveCreateTable_1);
					globalMap.put("current_client_path_separator", null);
				}

				String currentClientUsername_tHiveCreateTable_1 = (String) globalMap.get("current_client_user_name");
				if (currentClientUsername_tHiveCreateTable_1 != null) {
					System.setProperty("user.name", currentClientUsername_tHiveCreateTable_1);
					globalMap.put("current_client_user_name", null);
				}

				String originalHadoopUsername_tHiveCreateTable_1 = (String) globalMap
						.get("HADOOP_USER_NAME_tHiveCreateTable_1");
				if (originalHadoopUsername_tHiveCreateTable_1 != null) {
					System.setProperty("HADOOP_USER_NAME", originalHadoopUsername_tHiveCreateTable_1);
					globalMap.put("HADOOP_USER_NAME_tHiveCreateTable_1", null);
				} else {
					System.clearProperty("HADOOP_USER_NAME");
				}

				tos_count_tHiveCreateTable_1++;

				/**
				 * [tHiveCreateTable_1 main ] stop
				 */

				/**
				 * [tHiveCreateTable_1 process_data_begin ] start
				 */

				currentComponent = "tHiveCreateTable_1";

				/**
				 * [tHiveCreateTable_1 process_data_begin ] stop
				 */

				/**
				 * [tHiveCreateTable_1 process_data_end ] start
				 */

				currentComponent = "tHiveCreateTable_1";

				/**
				 * [tHiveCreateTable_1 process_data_end ] stop
				 */

				/**
				 * [tHiveCreateTable_1 end ] start
				 */

				currentComponent = "tHiveCreateTable_1";

				ok_Hash.put("tHiveCreateTable_1", true);
				end_Hash.put("tHiveCreateTable_1", System.currentTimeMillis());

				/**
				 * [tHiveCreateTable_1 end ] stop
				 */
			} // end the resume

		} catch (java.lang.Exception e) {

			TalendException te = new TalendException(e, currentComponent, globalMap);

			throw te;
		} catch (java.lang.Error error) {

			runStat.stopThreadStat();

			throw error;
		} finally {

			try {

				/**
				 * [tHiveCreateTable_1 finally ] start
				 */

				currentComponent = "tHiveCreateTable_1";

				/**
				 * [tHiveCreateTable_1 finally ] stop
				 */
			} catch (java.lang.Exception e) {
				// ignore
			} catch (java.lang.Error error) {
				// ignore
			}
			resourceMap = null;
		}

		globalMap.put("tHiveCreateTable_1_SUBPROCESS_STATE", 1);
	}

	public static class row2Struct implements routines.system.IPersistableComparableLookupRow<row2Struct> {
		final static byte[] commonByteArrayLock_ETL_PROJECT_fact_deceases = new byte[0];
		static byte[] commonByteArray_ETL_PROJECT_fact_deceases = new byte[0];
		protected static final int DEFAULT_HASHCODE = 1;
		protected static final int PRIME = 31;
		protected int hashCode = DEFAULT_HASHCODE;
		public boolean hashCodeDirty = true;

		public String loopKey;

		public Integer id_date;

		public Integer getId_date() {
			return this.id_date;
		}

		public java.util.Date date;

		public java.util.Date getDate() {
			return this.date;
		}

		public Integer year;

		public Integer getYear() {
			return this.year;
		}

		@Override
		public int hashCode() {
			if (this.hashCodeDirty) {
				final int prime = PRIME;
				int result = DEFAULT_HASHCODE;

				result = prime * result + ((this.date == null) ? 0 : this.date.hashCode());

				this.hashCode = result;
				this.hashCodeDirty = false;
			}
			return this.hashCode;
		}

		@Override
		public boolean equals(Object obj) {
			if (this == obj)
				return true;
			if (obj == null)
				return false;
			if (getClass() != obj.getClass())
				return false;
			final row2Struct other = (row2Struct) obj;

			if (this.date == null) {
				if (other.date != null)
					return false;

			} else if (!this.date.equals(other.date))

				return false;

			return true;
		}

		public void copyDataTo(row2Struct other) {

			other.id_date = this.id_date;
			other.date = this.date;
			other.year = this.year;

		}

		public void copyKeysDataTo(row2Struct other) {

			other.date = this.date;

		}

		private Integer readInteger(DataInputStream dis, ObjectInputStream ois) throws IOException {
			Integer intReturn;
			int length = 0;
			length = dis.readByte();
			if (length == -1) {
				intReturn = null;
			} else {
				intReturn = dis.readInt();
			}
			return intReturn;
		}

		private void writeInteger(Integer intNum, DataOutputStream dos, ObjectOutputStream oos) throws IOException {
			if (intNum == null) {
				dos.writeByte(-1);
			} else {
				dos.writeByte(0);
				dos.writeInt(intNum);
			}
		}

		private java.util.Date readDate(ObjectInputStream dis) throws IOException {
			java.util.Date dateReturn = null;
			int length = 0;
			length = dis.readByte();
			if (length == -1) {
				dateReturn = null;
			} else {
				dateReturn = new Date(dis.readLong());
			}
			return dateReturn;
		}

		private void writeDate(java.util.Date date1, ObjectOutputStream dos) throws IOException {
			if (date1 == null) {
				dos.writeByte(-1);
			} else {
				dos.writeByte(0);
				dos.writeLong(date1.getTime());
			}
		}

		public void readKeysData(ObjectInputStream dis) {

			synchronized (commonByteArrayLock_ETL_PROJECT_fact_deceases) {

				try {

					int length = 0;

					this.date = readDate(dis);

				} catch (IOException e) {
					throw new RuntimeException(e);

				}

			}

		}

		public void writeKeysData(ObjectOutputStream dos) {
			try {

				// java.util.Date

				writeDate(this.date, dos);

			} catch (IOException e) {
				throw new RuntimeException(e);
			}

		}

		/**
		 * Fill Values data by reading ObjectInputStream.
		 */
		public void readValuesData(DataInputStream dis, ObjectInputStream ois) {
			try {

				int length = 0;

				this.id_date = readInteger(dis, ois);

				this.year = readInteger(dis, ois);

			} catch (IOException e) {
				throw new RuntimeException(e);

			}

		}

		/**
		 * Return a byte array which represents Values data.
		 */
		public void writeValuesData(DataOutputStream dos, ObjectOutputStream oos) {
			try {

				writeInteger(this.id_date, dos, oos);

				writeInteger(this.year, dos, oos);

			} catch (IOException e) {
				throw new RuntimeException(e);
			}

		}

		public String toString() {

			StringBuilder sb = new StringBuilder();
			sb.append(super.toString());
			sb.append("[");
			sb.append("id_date=" + String.valueOf(id_date));
			sb.append(",date=" + String.valueOf(date));
			sb.append(",year=" + String.valueOf(year));
			sb.append("]");

			return sb.toString();
		}

		/**
		 * Compare keys
		 */
		public int compareTo(row2Struct other) {

			int returnValue = -1;

			returnValue = checkNullsAndCompare(this.date, other.date);
			if (returnValue != 0) {
				return returnValue;
			}

			return returnValue;
		}

		private int checkNullsAndCompare(Object object1, Object object2) {
			int returnValue = 0;
			if (object1 instanceof Comparable && object2 instanceof Comparable) {
				returnValue = ((Comparable) object1).compareTo(object2);
			} else if (object1 != null && object2 != null) {
				returnValue = compareStrings(object1.toString(), object2.toString());
			} else if (object1 == null && object2 != null) {
				returnValue = 1;
			} else if (object1 != null && object2 == null) {
				returnValue = -1;
			} else {
				returnValue = 0;
			}

			return returnValue;
		}

		private int compareStrings(String string1, String string2) {
			return string1.compareTo(string2);
		}

	}

	public void tHiveInput_1Process(final java.util.Map<String, Object> globalMap) throws TalendException {
		globalMap.put("tHiveInput_1_SUBPROCESS_STATE", 0);

		final boolean execStat = this.execStat;

		String iterateId = "";

		String currentComponent = "";
		java.util.Map<String, Object> resourceMap = new java.util.HashMap<String, Object>();

		try {
			// TDI-39566 avoid throwing an useless Exception
			boolean resumeIt = true;
			if (globalResumeTicket == false && resumeEntryMethodName != null) {
				String currentMethodName = new java.lang.Exception().getStackTrace()[0].getMethodName();
				resumeIt = resumeEntryMethodName.equals(currentMethodName);
			}
			if (resumeIt || globalResumeTicket) { // start the resume
				globalResumeTicket = true;

				row2Struct row2 = new row2Struct();

				/**
				 * [tAdvancedHash_row2 begin ] start
				 */

				ok_Hash.put("tAdvancedHash_row2", false);
				start_Hash.put("tAdvancedHash_row2", System.currentTimeMillis());

				currentComponent = "tAdvancedHash_row2";

				if (execStat) {
					runStat.updateStatOnConnection(resourceMap, iterateId, 0, 0, "row2");
				}

				int tos_count_tAdvancedHash_row2 = 0;

				// connection name:row2
				// source node:tHiveInput_1 - inputs:(after_tFileInputDelimited_1)
				// outputs:(row2,row2) | target node:tAdvancedHash_row2 - inputs:(row2)
				// outputs:()
				// linked node: tMap_1 - inputs:(row1,row2,row3) outputs:(f_decease)

				org.talend.designer.components.lookup.common.ICommonLookup.MATCHING_MODE matchingModeEnum_row2 = org.talend.designer.components.lookup.common.ICommonLookup.MATCHING_MODE.UNIQUE_MATCH;

				org.talend.designer.components.lookup.memory.AdvancedMemoryLookup<row2Struct> tHash_Lookup_row2 = org.talend.designer.components.lookup.memory.AdvancedMemoryLookup
						.<row2Struct>getLookup(matchingModeEnum_row2);

				globalMap.put("tHash_Lookup_row2", tHash_Lookup_row2);

				/**
				 * [tAdvancedHash_row2 begin ] stop
				 */

				/**
				 * [tHiveInput_1 begin ] start
				 */

				ok_Hash.put("tHiveInput_1", false);
				start_Hash.put("tHiveInput_1", System.currentTimeMillis());

				currentComponent = "tHiveInput_1";

				int tos_count_tHiveInput_1 = 0;

				System.setProperty("org.apache.commons.logging.Log", "org.apache.commons.logging.impl.NoOpLog");
				globalMap.put("current_client_path_separator", System.getProperty("path.separator"));
				System.setProperty("path.separator", ":");

				int nb_line_tHiveInput_1 = 0;
				java.sql.Connection conn_tHiveInput_1 = null;
				String driverClass_tHiveInput_1 = "org.apache.hive.jdbc.HiveDriver";
				java.lang.Class jdbcclazz_tHiveInput_1 = java.lang.Class.forName(driverClass_tHiveInput_1);
				String dbUser_tHiveInput_1 = "cloudera";

				final String decryptedPassword_tHiveInput_1 = routines.system.PasswordEncryptUtil
						.decryptPassword("enc:routine.encryption.key.v1:my+SnjaZty5NrJnr68SxWmzlMtUgyI/22+vXuA==");

				String dbPwd_tHiveInput_1 = decryptedPassword_tHiveInput_1;

				globalMap.put("HADOOP_USER_NAME_tHiveInput_1", System.getProperty("HADOOP_USER_NAME"));
				String url_tHiveInput_1 = "jdbc:hive2://" + "quickstart.cloudera" + ":" + "10000" + "/" + "chu";
				String additionalJdbcSettings_tHiveInput_1 = "";
				if (!"".equals(additionalJdbcSettings_tHiveInput_1.trim())) {
					if (!additionalJdbcSettings_tHiveInput_1.startsWith(";")) {
						additionalJdbcSettings_tHiveInput_1 = ";" + additionalJdbcSettings_tHiveInput_1;
					}
					url_tHiveInput_1 += additionalJdbcSettings_tHiveInput_1;
				}

				conn_tHiveInput_1 = java.sql.DriverManager.getConnection(url_tHiveInput_1, dbUser_tHiveInput_1,
						dbPwd_tHiveInput_1);

				java.sql.Statement init_tHiveInput_1 = conn_tHiveInput_1.createStatement();
				init_tHiveInput_1.execute("SET dfs.client.use.datanode.hostname=true");
				init_tHiveInput_1.execute("SET dfs.datanode.use.datanode.hostname=true");

				init_tHiveInput_1.close();

				String dbname_tHiveInput_1 = "chu";
				if (dbname_tHiveInput_1 != null && !"".equals(dbname_tHiveInput_1.trim())
						&& !"default".equals(dbname_tHiveInput_1.trim())) {
					java.sql.Statement goToDatabase_tHiveInput_1 = conn_tHiveInput_1.createStatement();
					goToDatabase_tHiveInput_1.execute("use " + dbname_tHiveInput_1);
					goToDatabase_tHiveInput_1.close();
				}

				java.sql.Statement stmt_tHiveInput_1 = conn_tHiveInput_1.createStatement();
				try {

					java.text.DateFormat dateStrFormat_tHiveInput_1 = new java.text.SimpleDateFormat("yyyyMMddHHmmss");
					final String queryIdentifier_tHiveInput_1 = projectName + "_" + jobName + "_"
							+ jobVersion.replace(".", "_") + "_tHiveInput_1_"
							+ dateStrFormat_tHiveInput_1.format(new Date(startTime));
// For MapReduce Mode
					stmt_tHiveInput_1.execute("set mapred.job.name=" + queryIdentifier_tHiveInput_1);
				} catch (Exception e) {
					e.printStackTrace();
				}

				String dbquery_tHiveInput_1 = "SELECT \n  d_dates.id_date, \n  d_dates.date, \n  d_dates.year\nFROM chu.d_dates";

				globalMap.put("tHiveInput_1_QUERY", dbquery_tHiveInput_1);
				java.sql.ResultSet rs_tHiveInput_1 = null;

				try {
					rs_tHiveInput_1 = stmt_tHiveInput_1.executeQuery(dbquery_tHiveInput_1);
					java.sql.ResultSetMetaData rsmd_tHiveInput_1 = rs_tHiveInput_1.getMetaData();
					int colQtyInRs_tHiveInput_1 = rsmd_tHiveInput_1.getColumnCount();

					String tmpContent_tHiveInput_1 = null;

					while (rs_tHiveInput_1.next()) {
						nb_line_tHiveInput_1++;

						if (colQtyInRs_tHiveInput_1 < 1) {
							row2.id_date = null;
						} else {

							row2.id_date = rs_tHiveInput_1.getInt(1);
							if (rs_tHiveInput_1.wasNull()) {
								row2.id_date = null;
							}
						}
						if (colQtyInRs_tHiveInput_1 < 2) {
							row2.date = null;
						} else {

							row2.date = routines.system.JDBCUtil.getDate(rs_tHiveInput_1, 2);
						}
						if (colQtyInRs_tHiveInput_1 < 3) {
							row2.year = null;
						} else {

							row2.year = rs_tHiveInput_1.getInt(3);
							if (rs_tHiveInput_1.wasNull()) {
								row2.year = null;
							}
						}

						/**
						 * [tHiveInput_1 begin ] stop
						 */

						/**
						 * [tHiveInput_1 main ] start
						 */

						currentComponent = "tHiveInput_1";

						tos_count_tHiveInput_1++;

						/**
						 * [tHiveInput_1 main ] stop
						 */

						/**
						 * [tHiveInput_1 process_data_begin ] start
						 */

						currentComponent = "tHiveInput_1";

						/**
						 * [tHiveInput_1 process_data_begin ] stop
						 */
// Start of branch "row2"
						if (row2 != null) {

							/**
							 * [tAdvancedHash_row2 main ] start
							 */

							currentComponent = "tAdvancedHash_row2";

							if (execStat) {
								runStat.updateStatOnConnection(iterateId, 1, 1, "row2");
							}

							row2Struct row2_HashRow = new row2Struct();

							row2_HashRow.id_date = row2.id_date;

							row2_HashRow.date = row2.date;

							row2_HashRow.year = row2.year;

							tHash_Lookup_row2.put(row2_HashRow);

							tos_count_tAdvancedHash_row2++;

							/**
							 * [tAdvancedHash_row2 main ] stop
							 */

							/**
							 * [tAdvancedHash_row2 process_data_begin ] start
							 */

							currentComponent = "tAdvancedHash_row2";

							/**
							 * [tAdvancedHash_row2 process_data_begin ] stop
							 */

							/**
							 * [tAdvancedHash_row2 process_data_end ] start
							 */

							currentComponent = "tAdvancedHash_row2";

							/**
							 * [tAdvancedHash_row2 process_data_end ] stop
							 */

						} // End of branch "row2"

						/**
						 * [tHiveInput_1 process_data_end ] start
						 */

						currentComponent = "tHiveInput_1";

						/**
						 * [tHiveInput_1 process_data_end ] stop
						 */

						/**
						 * [tHiveInput_1 end ] start
						 */

						currentComponent = "tHiveInput_1";

					}
				} finally {
					stmt_tHiveInput_1.close();

					conn_tHiveInput_1.close();

				}
				globalMap.put("tHiveInput_1_NB_LINE", nb_line_tHiveInput_1);

				String currentClientPathSeparator_tHiveInput_1 = (String) globalMap
						.get("current_client_path_separator");
				if (currentClientPathSeparator_tHiveInput_1 != null) {
					System.setProperty("path.separator", currentClientPathSeparator_tHiveInput_1);
					globalMap.put("current_client_path_separator", null);
				}

				String currentClientUsername_tHiveInput_1 = (String) globalMap.get("current_client_user_name");
				if (currentClientUsername_tHiveInput_1 != null) {
					System.setProperty("user.name", currentClientUsername_tHiveInput_1);
					globalMap.put("current_client_user_name", null);
				}

				String originalHadoopUsername_tHiveInput_1 = (String) globalMap.get("HADOOP_USER_NAME_tHiveInput_1");
				if (originalHadoopUsername_tHiveInput_1 != null) {
					System.setProperty("HADOOP_USER_NAME", originalHadoopUsername_tHiveInput_1);
					globalMap.put("HADOOP_USER_NAME_tHiveInput_1", null);
				} else {
					System.clearProperty("HADOOP_USER_NAME");
				}

				ok_Hash.put("tHiveInput_1", true);
				end_Hash.put("tHiveInput_1", System.currentTimeMillis());

				/**
				 * [tHiveInput_1 end ] stop
				 */

				/**
				 * [tAdvancedHash_row2 end ] start
				 */

				currentComponent = "tAdvancedHash_row2";

				tHash_Lookup_row2.endPut();

				if (execStat) {
					runStat.updateStat(resourceMap, iterateId, 2, 0, "row2");
				}

				ok_Hash.put("tAdvancedHash_row2", true);
				end_Hash.put("tAdvancedHash_row2", System.currentTimeMillis());

				/**
				 * [tAdvancedHash_row2 end ] stop
				 */

			} // end the resume

		} catch (java.lang.Exception e) {

			TalendException te = new TalendException(e, currentComponent, globalMap);

			throw te;
		} catch (java.lang.Error error) {

			runStat.stopThreadStat();

			throw error;
		} finally {

			try {

				/**
				 * [tHiveInput_1 finally ] start
				 */

				currentComponent = "tHiveInput_1";

				/**
				 * [tHiveInput_1 finally ] stop
				 */

				/**
				 * [tAdvancedHash_row2 finally ] start
				 */

				currentComponent = "tAdvancedHash_row2";

				/**
				 * [tAdvancedHash_row2 finally ] stop
				 */

			} catch (java.lang.Exception e) {
				// ignore
			} catch (java.lang.Error error) {
				// ignore
			}
			resourceMap = null;
		}

		globalMap.put("tHiveInput_1_SUBPROCESS_STATE", 1);
	}

	public static class row3Struct implements routines.system.IPersistableRow<row3Struct> {
		final static byte[] commonByteArrayLock_ETL_PROJECT_fact_deceases = new byte[0];
		static byte[] commonByteArray_ETL_PROJECT_fact_deceases = new byte[0];

		public Integer id_reg;

		public Integer getId_reg() {
			return this.id_reg;
		}

		private Integer readInteger(ObjectInputStream dis) throws IOException {
			Integer intReturn;
			int length = 0;
			length = dis.readByte();
			if (length == -1) {
				intReturn = null;
			} else {
				intReturn = dis.readInt();
			}
			return intReturn;
		}

		private void writeInteger(Integer intNum, ObjectOutputStream dos) throws IOException {
			if (intNum == null) {
				dos.writeByte(-1);
			} else {
				dos.writeByte(0);
				dos.writeInt(intNum);
			}
		}

		public void readData(ObjectInputStream dis) {

			synchronized (commonByteArrayLock_ETL_PROJECT_fact_deceases) {

				try {

					int length = 0;

					this.id_reg = readInteger(dis);

				} catch (IOException e) {
					throw new RuntimeException(e);

				}

			}

		}

		public void writeData(ObjectOutputStream dos) {
			try {

				// Integer

				writeInteger(this.id_reg, dos);

			} catch (IOException e) {
				throw new RuntimeException(e);
			}

		}

		public String toString() {

			StringBuilder sb = new StringBuilder();
			sb.append(super.toString());
			sb.append("[");
			sb.append("id_reg=" + String.valueOf(id_reg));
			sb.append("]");

			return sb.toString();
		}

		/**
		 * Compare keys
		 */
		public int compareTo(row3Struct other) {

			int returnValue = -1;

			return returnValue;
		}

		private int checkNullsAndCompare(Object object1, Object object2) {
			int returnValue = 0;
			if (object1 instanceof Comparable && object2 instanceof Comparable) {
				returnValue = ((Comparable) object1).compareTo(object2);
			} else if (object1 != null && object2 != null) {
				returnValue = compareStrings(object1.toString(), object2.toString());
			} else if (object1 == null && object2 != null) {
				returnValue = 1;
			} else if (object1 != null && object2 == null) {
				returnValue = -1;
			} else {
				returnValue = 0;
			}

			return returnValue;
		}

		private int compareStrings(String string1, String string2) {
			return string1.compareTo(string2);
		}

	}

	public void tHiveInput_2Process(final java.util.Map<String, Object> globalMap) throws TalendException {
		globalMap.put("tHiveInput_2_SUBPROCESS_STATE", 0);

		final boolean execStat = this.execStat;

		String iterateId = "";

		String currentComponent = "";
		java.util.Map<String, Object> resourceMap = new java.util.HashMap<String, Object>();

		try {
			// TDI-39566 avoid throwing an useless Exception
			boolean resumeIt = true;
			if (globalResumeTicket == false && resumeEntryMethodName != null) {
				String currentMethodName = new java.lang.Exception().getStackTrace()[0].getMethodName();
				resumeIt = resumeEntryMethodName.equals(currentMethodName);
			}
			if (resumeIt || globalResumeTicket) { // start the resume
				globalResumeTicket = true;

				row3Struct row3 = new row3Struct();

				/**
				 * [tAdvancedHash_row3 begin ] start
				 */

				ok_Hash.put("tAdvancedHash_row3", false);
				start_Hash.put("tAdvancedHash_row3", System.currentTimeMillis());

				currentComponent = "tAdvancedHash_row3";

				if (execStat) {
					runStat.updateStatOnConnection(resourceMap, iterateId, 0, 0, "row3");
				}

				int tos_count_tAdvancedHash_row3 = 0;

				// connection name:row3
				// source node:tHiveInput_2 - inputs:(after_tFileInputDelimited_1)
				// outputs:(row3,row3) | target node:tAdvancedHash_row3 - inputs:(row3)
				// outputs:()
				// linked node: tMap_1 - inputs:(row1,row2,row3) outputs:(f_decease)

				org.talend.designer.components.lookup.common.ICommonLookup.MATCHING_MODE matchingModeEnum_row3 = org.talend.designer.components.lookup.common.ICommonLookup.MATCHING_MODE.UNIQUE_MATCH;

				org.talend.designer.components.lookup.memory.AdvancedMemoryLookup<row3Struct> tHash_Lookup_row3 = org.talend.designer.components.lookup.memory.AdvancedMemoryLookup
						.<row3Struct>getLookup(matchingModeEnum_row3);

				globalMap.put("tHash_Lookup_row3", tHash_Lookup_row3);

				/**
				 * [tAdvancedHash_row3 begin ] stop
				 */

				/**
				 * [tHiveInput_2 begin ] start
				 */

				ok_Hash.put("tHiveInput_2", false);
				start_Hash.put("tHiveInput_2", System.currentTimeMillis());

				currentComponent = "tHiveInput_2";

				int tos_count_tHiveInput_2 = 0;

				System.setProperty("org.apache.commons.logging.Log", "org.apache.commons.logging.impl.NoOpLog");
				globalMap.put("current_client_path_separator", System.getProperty("path.separator"));
				System.setProperty("path.separator", ":");

				int nb_line_tHiveInput_2 = 0;
				java.sql.Connection conn_tHiveInput_2 = null;
				String driverClass_tHiveInput_2 = "org.apache.hive.jdbc.HiveDriver";
				java.lang.Class jdbcclazz_tHiveInput_2 = java.lang.Class.forName(driverClass_tHiveInput_2);
				String dbUser_tHiveInput_2 = "cloudera";

				final String decryptedPassword_tHiveInput_2 = routines.system.PasswordEncryptUtil
						.decryptPassword("enc:routine.encryption.key.v1:MdrN8nJvb+8OgERZyF9Fev7UjMDQvtPGPCWG4Q==");

				String dbPwd_tHiveInput_2 = decryptedPassword_tHiveInput_2;

				globalMap.put("HADOOP_USER_NAME_tHiveInput_2", System.getProperty("HADOOP_USER_NAME"));
				String url_tHiveInput_2 = "jdbc:hive2://" + "quickstart.cloudera" + ":" + "10000" + "/" + "chu";
				String additionalJdbcSettings_tHiveInput_2 = "";
				if (!"".equals(additionalJdbcSettings_tHiveInput_2.trim())) {
					if (!additionalJdbcSettings_tHiveInput_2.startsWith(";")) {
						additionalJdbcSettings_tHiveInput_2 = ";" + additionalJdbcSettings_tHiveInput_2;
					}
					url_tHiveInput_2 += additionalJdbcSettings_tHiveInput_2;
				}

				conn_tHiveInput_2 = java.sql.DriverManager.getConnection(url_tHiveInput_2, dbUser_tHiveInput_2,
						dbPwd_tHiveInput_2);

				java.sql.Statement init_tHiveInput_2 = conn_tHiveInput_2.createStatement();
				init_tHiveInput_2.execute("SET dfs.client.use.datanode.hostname=true");
				init_tHiveInput_2.execute("SET dfs.datanode.use.datanode.hostname=true");

				init_tHiveInput_2.close();

				String dbname_tHiveInput_2 = "chu";
				if (dbname_tHiveInput_2 != null && !"".equals(dbname_tHiveInput_2.trim())
						&& !"default".equals(dbname_tHiveInput_2.trim())) {
					java.sql.Statement goToDatabase_tHiveInput_2 = conn_tHiveInput_2.createStatement();
					goToDatabase_tHiveInput_2.execute("use " + dbname_tHiveInput_2);
					goToDatabase_tHiveInput_2.close();
				}

				java.sql.Statement stmt_tHiveInput_2 = conn_tHiveInput_2.createStatement();
				try {

					java.text.DateFormat dateStrFormat_tHiveInput_2 = new java.text.SimpleDateFormat("yyyyMMddHHmmss");
					final String queryIdentifier_tHiveInput_2 = projectName + "_" + jobName + "_"
							+ jobVersion.replace(".", "_") + "_tHiveInput_2_"
							+ dateStrFormat_tHiveInput_2.format(new Date(startTime));
// For MapReduce Mode
					stmt_tHiveInput_2.execute("set mapred.job.name=" + queryIdentifier_tHiveInput_2);
				} catch (Exception e) {
					e.printStackTrace();
				}

				String dbquery_tHiveInput_2 = "SELECT \n  d_regions.id_reg, \n  d_regions.country1, \n  d_regions.postcode1, \n  d_regions.town1, \n  d_regions.region1, \n "
						+ " d_regions.departement1, \n  d_regions.inseecode\nFROM chu.d_regions";

				globalMap.put("tHiveInput_2_QUERY", dbquery_tHiveInput_2);
				java.sql.ResultSet rs_tHiveInput_2 = null;

				try {
					rs_tHiveInput_2 = stmt_tHiveInput_2.executeQuery(dbquery_tHiveInput_2);
					java.sql.ResultSetMetaData rsmd_tHiveInput_2 = rs_tHiveInput_2.getMetaData();
					int colQtyInRs_tHiveInput_2 = rsmd_tHiveInput_2.getColumnCount();

					String tmpContent_tHiveInput_2 = null;

					while (rs_tHiveInput_2.next()) {
						nb_line_tHiveInput_2++;

						if (colQtyInRs_tHiveInput_2 < 1) {
							row3.id_reg = null;
						} else {

							row3.id_reg = rs_tHiveInput_2.getInt(1);
							if (rs_tHiveInput_2.wasNull()) {
								row3.id_reg = null;
							}
						}

						/**
						 * [tHiveInput_2 begin ] stop
						 */

						/**
						 * [tHiveInput_2 main ] start
						 */

						currentComponent = "tHiveInput_2";

						tos_count_tHiveInput_2++;

						/**
						 * [tHiveInput_2 main ] stop
						 */

						/**
						 * [tHiveInput_2 process_data_begin ] start
						 */

						currentComponent = "tHiveInput_2";

						/**
						 * [tHiveInput_2 process_data_begin ] stop
						 */
// Start of branch "row3"
						if (row3 != null) {

							/**
							 * [tAdvancedHash_row3 main ] start
							 */

							currentComponent = "tAdvancedHash_row3";

							if (execStat) {
								runStat.updateStatOnConnection(iterateId, 1, 1, "row3");
							}

							row3Struct row3_HashRow = new row3Struct();

							row3_HashRow.id_reg = row3.id_reg;

							tHash_Lookup_row3.put(row3_HashRow);

							tos_count_tAdvancedHash_row3++;

							/**
							 * [tAdvancedHash_row3 main ] stop
							 */

							/**
							 * [tAdvancedHash_row3 process_data_begin ] start
							 */

							currentComponent = "tAdvancedHash_row3";

							/**
							 * [tAdvancedHash_row3 process_data_begin ] stop
							 */

							/**
							 * [tAdvancedHash_row3 process_data_end ] start
							 */

							currentComponent = "tAdvancedHash_row3";

							/**
							 * [tAdvancedHash_row3 process_data_end ] stop
							 */

						} // End of branch "row3"

						/**
						 * [tHiveInput_2 process_data_end ] start
						 */

						currentComponent = "tHiveInput_2";

						/**
						 * [tHiveInput_2 process_data_end ] stop
						 */

						/**
						 * [tHiveInput_2 end ] start
						 */

						currentComponent = "tHiveInput_2";

					}
				} finally {
					stmt_tHiveInput_2.close();

					conn_tHiveInput_2.close();

				}
				globalMap.put("tHiveInput_2_NB_LINE", nb_line_tHiveInput_2);

				String currentClientPathSeparator_tHiveInput_2 = (String) globalMap
						.get("current_client_path_separator");
				if (currentClientPathSeparator_tHiveInput_2 != null) {
					System.setProperty("path.separator", currentClientPathSeparator_tHiveInput_2);
					globalMap.put("current_client_path_separator", null);
				}

				String currentClientUsername_tHiveInput_2 = (String) globalMap.get("current_client_user_name");
				if (currentClientUsername_tHiveInput_2 != null) {
					System.setProperty("user.name", currentClientUsername_tHiveInput_2);
					globalMap.put("current_client_user_name", null);
				}

				String originalHadoopUsername_tHiveInput_2 = (String) globalMap.get("HADOOP_USER_NAME_tHiveInput_2");
				if (originalHadoopUsername_tHiveInput_2 != null) {
					System.setProperty("HADOOP_USER_NAME", originalHadoopUsername_tHiveInput_2);
					globalMap.put("HADOOP_USER_NAME_tHiveInput_2", null);
				} else {
					System.clearProperty("HADOOP_USER_NAME");
				}

				ok_Hash.put("tHiveInput_2", true);
				end_Hash.put("tHiveInput_2", System.currentTimeMillis());

				/**
				 * [tHiveInput_2 end ] stop
				 */

				/**
				 * [tAdvancedHash_row3 end ] start
				 */

				currentComponent = "tAdvancedHash_row3";

				tHash_Lookup_row3.endPut();

				if (execStat) {
					runStat.updateStat(resourceMap, iterateId, 2, 0, "row3");
				}

				ok_Hash.put("tAdvancedHash_row3", true);
				end_Hash.put("tAdvancedHash_row3", System.currentTimeMillis());

				/**
				 * [tAdvancedHash_row3 end ] stop
				 */

			} // end the resume

		} catch (java.lang.Exception e) {

			TalendException te = new TalendException(e, currentComponent, globalMap);

			throw te;
		} catch (java.lang.Error error) {

			runStat.stopThreadStat();

			throw error;
		} finally {

			try {

				/**
				 * [tHiveInput_2 finally ] start
				 */

				currentComponent = "tHiveInput_2";

				/**
				 * [tHiveInput_2 finally ] stop
				 */

				/**
				 * [tAdvancedHash_row3 finally ] start
				 */

				currentComponent = "tAdvancedHash_row3";

				/**
				 * [tAdvancedHash_row3 finally ] stop
				 */

			} catch (java.lang.Exception e) {
				// ignore
			} catch (java.lang.Error error) {
				// ignore
			}
			resourceMap = null;
		}

		globalMap.put("tHiveInput_2_SUBPROCESS_STATE", 1);
	}

	public void tHadoopConfManager_tHDFSOutput_1Process(final java.util.Map<String, Object> globalMap)
			throws TalendException {
		globalMap.put("tHadoopConfManager_tHDFSOutput_1_SUBPROCESS_STATE", 0);

		final boolean execStat = this.execStat;

		String iterateId = "";

		String currentComponent = "";
		java.util.Map<String, Object> resourceMap = new java.util.HashMap<String, Object>();

		try {
			// TDI-39566 avoid throwing an useless Exception
			boolean resumeIt = true;
			if (globalResumeTicket == false && resumeEntryMethodName != null) {
				String currentMethodName = new java.lang.Exception().getStackTrace()[0].getMethodName();
				resumeIt = resumeEntryMethodName.equals(currentMethodName);
			}
			if (resumeIt || globalResumeTicket) { // start the resume
				globalResumeTicket = true;

				/**
				 * [tHadoopConfManager_tHDFSOutput_1 begin ] start
				 */

				ok_Hash.put("tHadoopConfManager_tHDFSOutput_1", false);
				start_Hash.put("tHadoopConfManager_tHDFSOutput_1", System.currentTimeMillis());

				currentComponent = "tHadoopConfManager_tHDFSOutput_1";

				int tos_count_tHadoopConfManager_tHDFSOutput_1 = 0;

				String libPath_tHadoopConfManager_tHDFSOutput_1 = "";

				class DealJobLibrary_tHadoopConfManager_tHDFSOutput_1 {

					public String getConfJarName(String confLib, String extraId) {
						String confJarName = confLib;
						if (extraId != null && extraId.length() > 0) {
							String jarName = confLib.substring(0, confLib.lastIndexOf("."));
							String jarExt = confLib.substring(confLib.lastIndexOf("."));
							confJarName = jarName + "_" + extraId + jarExt;
						}
						return confJarName;
					}

					public String replaceJarPathsFromCrcMap(String originalClassPathLine) throws java.lang.Exception {
						String classPathLine = "";
						String crcMapPath = new java.io.File("../crcMap").getCanonicalPath();
						if (isNeedAddLibsPath(crcMapPath)) {
							java.util.Map<String, String> crcMap = null;
							java.io.ObjectInputStream ois = new java.io.ObjectInputStream(
									new java.io.FileInputStream(crcMapPath));
							crcMap = (java.util.Map<String, String>) ois.readObject();
							ois.close();
							classPathLine = addLibsPath(originalClassPathLine, crcMap);
						} else {
							classPathLine = originalClassPathLine;
						}
						return classPathLine;
					}

					private boolean isNeedAddLibsPath(String crcMapPath) {
						if (!(new java.io.File(crcMapPath).exists())) {// when not use cache
							return false;
						}
						return true;
					}

					private String addLibsPath(String line, java.util.Map<String, String> crcMap) {
						for (java.util.Map.Entry<String, String> entry : crcMap.entrySet()) {
							line = adaptLibPaths(line, entry);
						}
						return line;
					}

					private String adaptLibPaths(String line, java.util.Map.Entry<String, String> entry) {
						String jarName = entry.getValue();
						String crc = entry.getKey();
						String libStringFinder = "../lib/" + jarName;
						if (line.contains(libStringFinder)) {
							line = line.replace(libStringFinder, "../../../cache/lib/" + crc + "/" + jarName);
						} else if (line.contains(":$ROOT_PATH/" + jarName + ":")) {
							line = line.replace(":$ROOT_PATH/" + jarName + ":",
									":$ROOT_PATH/../../../cache/lib/" + crc + "/" + jarName + ":");
						} else if (line.contains(";" + jarName + ";")) {
							line = line.replace(";" + jarName + ";",
									";../../../cache/lib/" + crc + "/" + jarName + ";");
						}
						return line;
					}

				}

				DealJobLibrary_tHadoopConfManager_tHDFSOutput_1 dealJobLibrary = new DealJobLibrary_tHadoopConfManager_tHDFSOutput_1();
				String confJarName = dealJobLibrary.getConfJarName("hadoop-conf-ClusterHadopp.jar", this.contextStr);

				libPath_tHadoopConfManager_tHDFSOutput_1 = new java.io.File(
						"C:/Users/theoc/Desktop/notion/A4/Blocs/BigData/Projet/ProjectBigData-GRP6/ETL project/ETL_PROJECT/temp/lib/"
								+ confJarName).getAbsolutePath();
				libPath_tHadoopConfManager_tHDFSOutput_1 = dealJobLibrary
						.replaceJarPathsFromCrcMap(libPath_tHadoopConfManager_tHDFSOutput_1);

				java.net.URLClassLoader currentLoadertHadoopConfManager_tHDFSOutput_1 = (java.net.URLClassLoader) Thread
						.currentThread().getContextClassLoader();
				java.lang.reflect.Method method_tHadoopConfManager_tHDFSOutput_1 = java.net.URLClassLoader.class
						.getDeclaredMethod("addURL", new Class[] { java.net.URL.class });
				method_tHadoopConfManager_tHDFSOutput_1.setAccessible(true);
				method_tHadoopConfManager_tHDFSOutput_1.invoke(currentLoadertHadoopConfManager_tHDFSOutput_1,
						new Object[] { new java.io.File(libPath_tHadoopConfManager_tHDFSOutput_1).toURL() });

				/**
				 * [tHadoopConfManager_tHDFSOutput_1 begin ] stop
				 */

				/**
				 * [tHadoopConfManager_tHDFSOutput_1 main ] start
				 */

				currentComponent = "tHadoopConfManager_tHDFSOutput_1";

				tos_count_tHadoopConfManager_tHDFSOutput_1++;

				/**
				 * [tHadoopConfManager_tHDFSOutput_1 main ] stop
				 */

				/**
				 * [tHadoopConfManager_tHDFSOutput_1 process_data_begin ] start
				 */

				currentComponent = "tHadoopConfManager_tHDFSOutput_1";

				/**
				 * [tHadoopConfManager_tHDFSOutput_1 process_data_begin ] stop
				 */

				/**
				 * [tHadoopConfManager_tHDFSOutput_1 process_data_end ] start
				 */

				currentComponent = "tHadoopConfManager_tHDFSOutput_1";

				/**
				 * [tHadoopConfManager_tHDFSOutput_1 process_data_end ] stop
				 */

				/**
				 * [tHadoopConfManager_tHDFSOutput_1 end ] start
				 */

				currentComponent = "tHadoopConfManager_tHDFSOutput_1";

				ok_Hash.put("tHadoopConfManager_tHDFSOutput_1", true);
				end_Hash.put("tHadoopConfManager_tHDFSOutput_1", System.currentTimeMillis());

				/**
				 * [tHadoopConfManager_tHDFSOutput_1 end ] stop
				 */
			} // end the resume

		} catch (java.lang.Exception e) {

			TalendException te = new TalendException(e, currentComponent, globalMap);

			throw te;
		} catch (java.lang.Error error) {

			runStat.stopThreadStat();

			throw error;
		} finally {

			try {

				/**
				 * [tHadoopConfManager_tHDFSOutput_1 finally ] start
				 */

				currentComponent = "tHadoopConfManager_tHDFSOutput_1";

				/**
				 * [tHadoopConfManager_tHDFSOutput_1 finally ] stop
				 */
			} catch (java.lang.Exception e) {
				// ignore
			} catch (java.lang.Error error) {
				// ignore
			}
			resourceMap = null;
		}

		globalMap.put("tHadoopConfManager_tHDFSOutput_1_SUBPROCESS_STATE", 1);
	}

	public void tHadoopConfManager_tHiveCreateTable_1Process(final java.util.Map<String, Object> globalMap)
			throws TalendException {
		globalMap.put("tHadoopConfManager_tHiveCreateTable_1_SUBPROCESS_STATE", 0);

		final boolean execStat = this.execStat;

		String iterateId = "";

		String currentComponent = "";
		java.util.Map<String, Object> resourceMap = new java.util.HashMap<String, Object>();

		try {
			// TDI-39566 avoid throwing an useless Exception
			boolean resumeIt = true;
			if (globalResumeTicket == false && resumeEntryMethodName != null) {
				String currentMethodName = new java.lang.Exception().getStackTrace()[0].getMethodName();
				resumeIt = resumeEntryMethodName.equals(currentMethodName);
			}
			if (resumeIt || globalResumeTicket) { // start the resume
				globalResumeTicket = true;

				/**
				 * [tHadoopConfManager_tHiveCreateTable_1 begin ] start
				 */

				ok_Hash.put("tHadoopConfManager_tHiveCreateTable_1", false);
				start_Hash.put("tHadoopConfManager_tHiveCreateTable_1", System.currentTimeMillis());

				currentComponent = "tHadoopConfManager_tHiveCreateTable_1";

				int tos_count_tHadoopConfManager_tHiveCreateTable_1 = 0;

				String libPath_tHadoopConfManager_tHiveCreateTable_1 = "";

				class DealJobLibrary_tHadoopConfManager_tHiveCreateTable_1 {

					public String getConfJarName(String confLib, String extraId) {
						String confJarName = confLib;
						if (extraId != null && extraId.length() > 0) {
							String jarName = confLib.substring(0, confLib.lastIndexOf("."));
							String jarExt = confLib.substring(confLib.lastIndexOf("."));
							confJarName = jarName + "_" + extraId + jarExt;
						}
						return confJarName;
					}

					public String replaceJarPathsFromCrcMap(String originalClassPathLine) throws java.lang.Exception {
						String classPathLine = "";
						String crcMapPath = new java.io.File("../crcMap").getCanonicalPath();
						if (isNeedAddLibsPath(crcMapPath)) {
							java.util.Map<String, String> crcMap = null;
							java.io.ObjectInputStream ois = new java.io.ObjectInputStream(
									new java.io.FileInputStream(crcMapPath));
							crcMap = (java.util.Map<String, String>) ois.readObject();
							ois.close();
							classPathLine = addLibsPath(originalClassPathLine, crcMap);
						} else {
							classPathLine = originalClassPathLine;
						}
						return classPathLine;
					}

					private boolean isNeedAddLibsPath(String crcMapPath) {
						if (!(new java.io.File(crcMapPath).exists())) {// when not use cache
							return false;
						}
						return true;
					}

					private String addLibsPath(String line, java.util.Map<String, String> crcMap) {
						for (java.util.Map.Entry<String, String> entry : crcMap.entrySet()) {
							line = adaptLibPaths(line, entry);
						}
						return line;
					}

					private String adaptLibPaths(String line, java.util.Map.Entry<String, String> entry) {
						String jarName = entry.getValue();
						String crc = entry.getKey();
						String libStringFinder = "../lib/" + jarName;
						if (line.contains(libStringFinder)) {
							line = line.replace(libStringFinder, "../../../cache/lib/" + crc + "/" + jarName);
						} else if (line.contains(":$ROOT_PATH/" + jarName + ":")) {
							line = line.replace(":$ROOT_PATH/" + jarName + ":",
									":$ROOT_PATH/../../../cache/lib/" + crc + "/" + jarName + ":");
						} else if (line.contains(";" + jarName + ";")) {
							line = line.replace(";" + jarName + ";",
									";../../../cache/lib/" + crc + "/" + jarName + ";");
						}
						return line;
					}

				}

				DealJobLibrary_tHadoopConfManager_tHiveCreateTable_1 dealJobLibrary = new DealJobLibrary_tHadoopConfManager_tHiveCreateTable_1();
				String confJarName = dealJobLibrary.getConfJarName("hadoop-conf-ClusterHadopp.jar", this.contextStr);

				libPath_tHadoopConfManager_tHiveCreateTable_1 = new java.io.File(
						"C:/Users/theoc/Desktop/notion/A4/Blocs/BigData/Projet/ProjectBigData-GRP6/ETL project/ETL_PROJECT/temp/lib/"
								+ confJarName).getAbsolutePath();
				libPath_tHadoopConfManager_tHiveCreateTable_1 = dealJobLibrary
						.replaceJarPathsFromCrcMap(libPath_tHadoopConfManager_tHiveCreateTable_1);

				java.net.URLClassLoader currentLoadertHadoopConfManager_tHiveCreateTable_1 = (java.net.URLClassLoader) Thread
						.currentThread().getContextClassLoader();
				java.lang.reflect.Method method_tHadoopConfManager_tHiveCreateTable_1 = java.net.URLClassLoader.class
						.getDeclaredMethod("addURL", new Class[] { java.net.URL.class });
				method_tHadoopConfManager_tHiveCreateTable_1.setAccessible(true);
				method_tHadoopConfManager_tHiveCreateTable_1.invoke(currentLoadertHadoopConfManager_tHiveCreateTable_1,
						new Object[] { new java.io.File(libPath_tHadoopConfManager_tHiveCreateTable_1).toURL() });

				/**
				 * [tHadoopConfManager_tHiveCreateTable_1 begin ] stop
				 */

				/**
				 * [tHadoopConfManager_tHiveCreateTable_1 main ] start
				 */

				currentComponent = "tHadoopConfManager_tHiveCreateTable_1";

				tos_count_tHadoopConfManager_tHiveCreateTable_1++;

				/**
				 * [tHadoopConfManager_tHiveCreateTable_1 main ] stop
				 */

				/**
				 * [tHadoopConfManager_tHiveCreateTable_1 process_data_begin ] start
				 */

				currentComponent = "tHadoopConfManager_tHiveCreateTable_1";

				/**
				 * [tHadoopConfManager_tHiveCreateTable_1 process_data_begin ] stop
				 */

				/**
				 * [tHadoopConfManager_tHiveCreateTable_1 process_data_end ] start
				 */

				currentComponent = "tHadoopConfManager_tHiveCreateTable_1";

				/**
				 * [tHadoopConfManager_tHiveCreateTable_1 process_data_end ] stop
				 */

				/**
				 * [tHadoopConfManager_tHiveCreateTable_1 end ] start
				 */

				currentComponent = "tHadoopConfManager_tHiveCreateTable_1";

				ok_Hash.put("tHadoopConfManager_tHiveCreateTable_1", true);
				end_Hash.put("tHadoopConfManager_tHiveCreateTable_1", System.currentTimeMillis());

				/**
				 * [tHadoopConfManager_tHiveCreateTable_1 end ] stop
				 */
			} // end the resume

		} catch (java.lang.Exception e) {

			TalendException te = new TalendException(e, currentComponent, globalMap);

			throw te;
		} catch (java.lang.Error error) {

			runStat.stopThreadStat();

			throw error;
		} finally {

			try {

				/**
				 * [tHadoopConfManager_tHiveCreateTable_1 finally ] start
				 */

				currentComponent = "tHadoopConfManager_tHiveCreateTable_1";

				/**
				 * [tHadoopConfManager_tHiveCreateTable_1 finally ] stop
				 */
			} catch (java.lang.Exception e) {
				// ignore
			} catch (java.lang.Error error) {
				// ignore
			}
			resourceMap = null;
		}

		globalMap.put("tHadoopConfManager_tHiveCreateTable_1_SUBPROCESS_STATE", 1);
	}

	public void tHadoopConfManager_tHiveInput_1Process(final java.util.Map<String, Object> globalMap)
			throws TalendException {
		globalMap.put("tHadoopConfManager_tHiveInput_1_SUBPROCESS_STATE", 0);

		final boolean execStat = this.execStat;

		String iterateId = "";

		String currentComponent = "";
		java.util.Map<String, Object> resourceMap = new java.util.HashMap<String, Object>();

		try {
			// TDI-39566 avoid throwing an useless Exception
			boolean resumeIt = true;
			if (globalResumeTicket == false && resumeEntryMethodName != null) {
				String currentMethodName = new java.lang.Exception().getStackTrace()[0].getMethodName();
				resumeIt = resumeEntryMethodName.equals(currentMethodName);
			}
			if (resumeIt || globalResumeTicket) { // start the resume
				globalResumeTicket = true;

				/**
				 * [tHadoopConfManager_tHiveInput_1 begin ] start
				 */

				ok_Hash.put("tHadoopConfManager_tHiveInput_1", false);
				start_Hash.put("tHadoopConfManager_tHiveInput_1", System.currentTimeMillis());

				currentComponent = "tHadoopConfManager_tHiveInput_1";

				int tos_count_tHadoopConfManager_tHiveInput_1 = 0;

				String libPath_tHadoopConfManager_tHiveInput_1 = "";

				class DealJobLibrary_tHadoopConfManager_tHiveInput_1 {

					public String getConfJarName(String confLib, String extraId) {
						String confJarName = confLib;
						if (extraId != null && extraId.length() > 0) {
							String jarName = confLib.substring(0, confLib.lastIndexOf("."));
							String jarExt = confLib.substring(confLib.lastIndexOf("."));
							confJarName = jarName + "_" + extraId + jarExt;
						}
						return confJarName;
					}

					public String replaceJarPathsFromCrcMap(String originalClassPathLine) throws java.lang.Exception {
						String classPathLine = "";
						String crcMapPath = new java.io.File("../crcMap").getCanonicalPath();
						if (isNeedAddLibsPath(crcMapPath)) {
							java.util.Map<String, String> crcMap = null;
							java.io.ObjectInputStream ois = new java.io.ObjectInputStream(
									new java.io.FileInputStream(crcMapPath));
							crcMap = (java.util.Map<String, String>) ois.readObject();
							ois.close();
							classPathLine = addLibsPath(originalClassPathLine, crcMap);
						} else {
							classPathLine = originalClassPathLine;
						}
						return classPathLine;
					}

					private boolean isNeedAddLibsPath(String crcMapPath) {
						if (!(new java.io.File(crcMapPath).exists())) {// when not use cache
							return false;
						}
						return true;
					}

					private String addLibsPath(String line, java.util.Map<String, String> crcMap) {
						for (java.util.Map.Entry<String, String> entry : crcMap.entrySet()) {
							line = adaptLibPaths(line, entry);
						}
						return line;
					}

					private String adaptLibPaths(String line, java.util.Map.Entry<String, String> entry) {
						String jarName = entry.getValue();
						String crc = entry.getKey();
						String libStringFinder = "../lib/" + jarName;
						if (line.contains(libStringFinder)) {
							line = line.replace(libStringFinder, "../../../cache/lib/" + crc + "/" + jarName);
						} else if (line.contains(":$ROOT_PATH/" + jarName + ":")) {
							line = line.replace(":$ROOT_PATH/" + jarName + ":",
									":$ROOT_PATH/../../../cache/lib/" + crc + "/" + jarName + ":");
						} else if (line.contains(";" + jarName + ";")) {
							line = line.replace(";" + jarName + ";",
									";../../../cache/lib/" + crc + "/" + jarName + ";");
						}
						return line;
					}

				}

				DealJobLibrary_tHadoopConfManager_tHiveInput_1 dealJobLibrary = new DealJobLibrary_tHadoopConfManager_tHiveInput_1();
				String confJarName = dealJobLibrary.getConfJarName("hadoop-conf-ClusterHadopp.jar", this.contextStr);

				libPath_tHadoopConfManager_tHiveInput_1 = new java.io.File(
						"C:/Users/theoc/Desktop/notion/A4/Blocs/BigData/Projet/ProjectBigData-GRP6/ETL project/ETL_PROJECT/temp/lib/"
								+ confJarName).getAbsolutePath();
				libPath_tHadoopConfManager_tHiveInput_1 = dealJobLibrary
						.replaceJarPathsFromCrcMap(libPath_tHadoopConfManager_tHiveInput_1);

				java.net.URLClassLoader currentLoadertHadoopConfManager_tHiveInput_1 = (java.net.URLClassLoader) Thread
						.currentThread().getContextClassLoader();
				java.lang.reflect.Method method_tHadoopConfManager_tHiveInput_1 = java.net.URLClassLoader.class
						.getDeclaredMethod("addURL", new Class[] { java.net.URL.class });
				method_tHadoopConfManager_tHiveInput_1.setAccessible(true);
				method_tHadoopConfManager_tHiveInput_1.invoke(currentLoadertHadoopConfManager_tHiveInput_1,
						new Object[] { new java.io.File(libPath_tHadoopConfManager_tHiveInput_1).toURL() });

				/**
				 * [tHadoopConfManager_tHiveInput_1 begin ] stop
				 */

				/**
				 * [tHadoopConfManager_tHiveInput_1 main ] start
				 */

				currentComponent = "tHadoopConfManager_tHiveInput_1";

				tos_count_tHadoopConfManager_tHiveInput_1++;

				/**
				 * [tHadoopConfManager_tHiveInput_1 main ] stop
				 */

				/**
				 * [tHadoopConfManager_tHiveInput_1 process_data_begin ] start
				 */

				currentComponent = "tHadoopConfManager_tHiveInput_1";

				/**
				 * [tHadoopConfManager_tHiveInput_1 process_data_begin ] stop
				 */

				/**
				 * [tHadoopConfManager_tHiveInput_1 process_data_end ] start
				 */

				currentComponent = "tHadoopConfManager_tHiveInput_1";

				/**
				 * [tHadoopConfManager_tHiveInput_1 process_data_end ] stop
				 */

				/**
				 * [tHadoopConfManager_tHiveInput_1 end ] start
				 */

				currentComponent = "tHadoopConfManager_tHiveInput_1";

				ok_Hash.put("tHadoopConfManager_tHiveInput_1", true);
				end_Hash.put("tHadoopConfManager_tHiveInput_1", System.currentTimeMillis());

				/**
				 * [tHadoopConfManager_tHiveInput_1 end ] stop
				 */
			} // end the resume

		} catch (java.lang.Exception e) {

			TalendException te = new TalendException(e, currentComponent, globalMap);

			throw te;
		} catch (java.lang.Error error) {

			runStat.stopThreadStat();

			throw error;
		} finally {

			try {

				/**
				 * [tHadoopConfManager_tHiveInput_1 finally ] start
				 */

				currentComponent = "tHadoopConfManager_tHiveInput_1";

				/**
				 * [tHadoopConfManager_tHiveInput_1 finally ] stop
				 */
			} catch (java.lang.Exception e) {
				// ignore
			} catch (java.lang.Error error) {
				// ignore
			}
			resourceMap = null;
		}

		globalMap.put("tHadoopConfManager_tHiveInput_1_SUBPROCESS_STATE", 1);
	}

	public void tHadoopConfManager_tHiveInput_2Process(final java.util.Map<String, Object> globalMap)
			throws TalendException {
		globalMap.put("tHadoopConfManager_tHiveInput_2_SUBPROCESS_STATE", 0);

		final boolean execStat = this.execStat;

		String iterateId = "";

		String currentComponent = "";
		java.util.Map<String, Object> resourceMap = new java.util.HashMap<String, Object>();

		try {
			// TDI-39566 avoid throwing an useless Exception
			boolean resumeIt = true;
			if (globalResumeTicket == false && resumeEntryMethodName != null) {
				String currentMethodName = new java.lang.Exception().getStackTrace()[0].getMethodName();
				resumeIt = resumeEntryMethodName.equals(currentMethodName);
			}
			if (resumeIt || globalResumeTicket) { // start the resume
				globalResumeTicket = true;

				/**
				 * [tHadoopConfManager_tHiveInput_2 begin ] start
				 */

				ok_Hash.put("tHadoopConfManager_tHiveInput_2", false);
				start_Hash.put("tHadoopConfManager_tHiveInput_2", System.currentTimeMillis());

				currentComponent = "tHadoopConfManager_tHiveInput_2";

				int tos_count_tHadoopConfManager_tHiveInput_2 = 0;

				String libPath_tHadoopConfManager_tHiveInput_2 = "";

				class DealJobLibrary_tHadoopConfManager_tHiveInput_2 {

					public String getConfJarName(String confLib, String extraId) {
						String confJarName = confLib;
						if (extraId != null && extraId.length() > 0) {
							String jarName = confLib.substring(0, confLib.lastIndexOf("."));
							String jarExt = confLib.substring(confLib.lastIndexOf("."));
							confJarName = jarName + "_" + extraId + jarExt;
						}
						return confJarName;
					}

					public String replaceJarPathsFromCrcMap(String originalClassPathLine) throws java.lang.Exception {
						String classPathLine = "";
						String crcMapPath = new java.io.File("../crcMap").getCanonicalPath();
						if (isNeedAddLibsPath(crcMapPath)) {
							java.util.Map<String, String> crcMap = null;
							java.io.ObjectInputStream ois = new java.io.ObjectInputStream(
									new java.io.FileInputStream(crcMapPath));
							crcMap = (java.util.Map<String, String>) ois.readObject();
							ois.close();
							classPathLine = addLibsPath(originalClassPathLine, crcMap);
						} else {
							classPathLine = originalClassPathLine;
						}
						return classPathLine;
					}

					private boolean isNeedAddLibsPath(String crcMapPath) {
						if (!(new java.io.File(crcMapPath).exists())) {// when not use cache
							return false;
						}
						return true;
					}

					private String addLibsPath(String line, java.util.Map<String, String> crcMap) {
						for (java.util.Map.Entry<String, String> entry : crcMap.entrySet()) {
							line = adaptLibPaths(line, entry);
						}
						return line;
					}

					private String adaptLibPaths(String line, java.util.Map.Entry<String, String> entry) {
						String jarName = entry.getValue();
						String crc = entry.getKey();
						String libStringFinder = "../lib/" + jarName;
						if (line.contains(libStringFinder)) {
							line = line.replace(libStringFinder, "../../../cache/lib/" + crc + "/" + jarName);
						} else if (line.contains(":$ROOT_PATH/" + jarName + ":")) {
							line = line.replace(":$ROOT_PATH/" + jarName + ":",
									":$ROOT_PATH/../../../cache/lib/" + crc + "/" + jarName + ":");
						} else if (line.contains(";" + jarName + ";")) {
							line = line.replace(";" + jarName + ";",
									";../../../cache/lib/" + crc + "/" + jarName + ";");
						}
						return line;
					}

				}

				DealJobLibrary_tHadoopConfManager_tHiveInput_2 dealJobLibrary = new DealJobLibrary_tHadoopConfManager_tHiveInput_2();
				String confJarName = dealJobLibrary.getConfJarName("hadoop-conf-ClusterHadopp.jar", this.contextStr);

				libPath_tHadoopConfManager_tHiveInput_2 = new java.io.File(
						"C:/Users/theoc/Desktop/notion/A4/Blocs/BigData/Projet/ProjectBigData-GRP6/ETL project/ETL_PROJECT/temp/lib/"
								+ confJarName).getAbsolutePath();
				libPath_tHadoopConfManager_tHiveInput_2 = dealJobLibrary
						.replaceJarPathsFromCrcMap(libPath_tHadoopConfManager_tHiveInput_2);

				java.net.URLClassLoader currentLoadertHadoopConfManager_tHiveInput_2 = (java.net.URLClassLoader) Thread
						.currentThread().getContextClassLoader();
				java.lang.reflect.Method method_tHadoopConfManager_tHiveInput_2 = java.net.URLClassLoader.class
						.getDeclaredMethod("addURL", new Class[] { java.net.URL.class });
				method_tHadoopConfManager_tHiveInput_2.setAccessible(true);
				method_tHadoopConfManager_tHiveInput_2.invoke(currentLoadertHadoopConfManager_tHiveInput_2,
						new Object[] { new java.io.File(libPath_tHadoopConfManager_tHiveInput_2).toURL() });

				/**
				 * [tHadoopConfManager_tHiveInput_2 begin ] stop
				 */

				/**
				 * [tHadoopConfManager_tHiveInput_2 main ] start
				 */

				currentComponent = "tHadoopConfManager_tHiveInput_2";

				tos_count_tHadoopConfManager_tHiveInput_2++;

				/**
				 * [tHadoopConfManager_tHiveInput_2 main ] stop
				 */

				/**
				 * [tHadoopConfManager_tHiveInput_2 process_data_begin ] start
				 */

				currentComponent = "tHadoopConfManager_tHiveInput_2";

				/**
				 * [tHadoopConfManager_tHiveInput_2 process_data_begin ] stop
				 */

				/**
				 * [tHadoopConfManager_tHiveInput_2 process_data_end ] start
				 */

				currentComponent = "tHadoopConfManager_tHiveInput_2";

				/**
				 * [tHadoopConfManager_tHiveInput_2 process_data_end ] stop
				 */

				/**
				 * [tHadoopConfManager_tHiveInput_2 end ] start
				 */

				currentComponent = "tHadoopConfManager_tHiveInput_2";

				ok_Hash.put("tHadoopConfManager_tHiveInput_2", true);
				end_Hash.put("tHadoopConfManager_tHiveInput_2", System.currentTimeMillis());

				/**
				 * [tHadoopConfManager_tHiveInput_2 end ] stop
				 */
			} // end the resume

		} catch (java.lang.Exception e) {

			TalendException te = new TalendException(e, currentComponent, globalMap);

			throw te;
		} catch (java.lang.Error error) {

			runStat.stopThreadStat();

			throw error;
		} finally {

			try {

				/**
				 * [tHadoopConfManager_tHiveInput_2 finally ] start
				 */

				currentComponent = "tHadoopConfManager_tHiveInput_2";

				/**
				 * [tHadoopConfManager_tHiveInput_2 finally ] stop
				 */
			} catch (java.lang.Exception e) {
				// ignore
			} catch (java.lang.Error error) {
				// ignore
			}
			resourceMap = null;
		}

		globalMap.put("tHadoopConfManager_tHiveInput_2_SUBPROCESS_STATE", 1);
	}

	public String resuming_logs_dir_path = null;
	public String resuming_checkpoint_path = null;
	public String parent_part_launcher = null;
	private String resumeEntryMethodName = null;
	private boolean globalResumeTicket = false;

	public boolean watch = false;
	// portStats is null, it means don't execute the statistics
	public Integer portStats = null;
	public int portTraces = 4334;
	public String clientHost;
	public String defaultClientHost = "localhost";
	public String contextStr = "Default";
	public boolean isDefaultContext = true;
	public String pid = "0";
	public String rootPid = null;
	public String fatherPid = null;
	public String fatherNode = null;
	public long startTime = 0;
	public boolean isChildJob = false;
	public String log4jLevel = "";

	private boolean enableLogStash;

	private boolean execStat = true;

	private ThreadLocal<java.util.Map<String, String>> threadLocal = new ThreadLocal<java.util.Map<String, String>>() {
		protected java.util.Map<String, String> initialValue() {
			java.util.Map<String, String> threadRunResultMap = new java.util.HashMap<String, String>();
			threadRunResultMap.put("errorCode", null);
			threadRunResultMap.put("status", "");
			return threadRunResultMap;
		};
	};

	private PropertiesWithType context_param = new PropertiesWithType();
	public java.util.Map<String, Object> parentContextMap = new java.util.HashMap<String, Object>();

	public String status = "";

	public static void main(String[] args) {
		final fact_deceases fact_deceasesClass = new fact_deceases();

		int exitCode = fact_deceasesClass.runJobInTOS(args);

		System.exit(exitCode);
	}

	public String[][] runJob(String[] args) {

		int exitCode = runJobInTOS(args);
		String[][] bufferValue = new String[][] { { Integer.toString(exitCode) } };

		return bufferValue;
	}

	public boolean hastBufferOutputComponent() {
		boolean hastBufferOutput = false;

		return hastBufferOutput;
	}

	public int runJobInTOS(String[] args) {
		// reset status
		status = "";

		String lastStr = "";
		for (String arg : args) {
			if (arg.equalsIgnoreCase("--context_param")) {
				lastStr = arg;
			} else if (lastStr.equals("")) {
				evalParam(arg);
			} else {
				evalParam(lastStr + " " + arg);
				lastStr = "";
			}
		}
		enableLogStash = "true".equalsIgnoreCase(System.getProperty("monitoring"));

		if (clientHost == null) {
			clientHost = defaultClientHost;
		}

		if (pid == null || "0".equals(pid)) {
			pid = TalendString.getAsciiRandomString(6);
		}

		if (rootPid == null) {
			rootPid = pid;
		}
		if (fatherPid == null) {
			fatherPid = pid;
		} else {
			isChildJob = true;
		}

		if (portStats != null) {
			// portStats = -1; //for testing
			if (portStats < 0 || portStats > 65535) {
				// issue:10869, the portStats is invalid, so this client socket can't open
				System.err.println("The statistics socket port " + portStats + " is invalid.");
				execStat = false;
			}
		} else {
			execStat = false;
		}

		try {
			// call job/subjob with an existing context, like: --context=production. if
			// without this parameter, there will use the default context instead.
			java.io.InputStream inContext = fact_deceases.class.getClassLoader()
					.getResourceAsStream("etl_project/fact_deceases_0_1/contexts/" + contextStr + ".properties");
			if (inContext == null) {
				inContext = fact_deceases.class.getClassLoader()
						.getResourceAsStream("config/contexts/" + contextStr + ".properties");
			}
			if (inContext != null) {
				// defaultProps is in order to keep the original context value
				if (context != null && context.isEmpty()) {
					defaultProps.load(inContext);
					context = new ContextProperties(defaultProps);
				}

				inContext.close();
			} else if (!isDefaultContext) {
				// print info and job continue to run, for case: context_param is not empty.
				System.err.println("Could not find the context " + contextStr);
			}

			if (!context_param.isEmpty()) {
				context.putAll(context_param);
				// set types for params from parentJobs
				for (Object key : context_param.keySet()) {
					String context_key = key.toString();
					String context_type = context_param.getContextType(context_key);
					context.setContextType(context_key, context_type);

				}
			}
			class ContextProcessing {
				private void processContext_0() {
					context.setContextType("INPUT_PATH", "id_String");
					context.INPUT_PATH = (String) context.getProperty("INPUT_PATH");
					context.setContextType("ClusterHadopp_User", "id_String");
					context.ClusterHadopp_User = (String) context.getProperty("ClusterHadopp_User");
					context.setContextType("ClusterHadopp_NameNodeUri", "id_String");
					context.ClusterHadopp_NameNodeUri = (String) context.getProperty("ClusterHadopp_NameNodeUri");
					context.setContextType("ClusterHadopp_hadoopConfSpecificJar", "id_String");
					context.ClusterHadopp_hadoopConfSpecificJar = (String) context
							.getProperty("ClusterHadopp_hadoopConfSpecificJar");
					context.setContextType("ClusterHadopp_ResourceManager", "id_String");
					context.ClusterHadopp_ResourceManager = (String) context
							.getProperty("ClusterHadopp_ResourceManager");
					context.setContextType("ClusterHadopp_ResourceManagerScheduler", "id_String");
					context.ClusterHadopp_ResourceManagerScheduler = (String) context
							.getProperty("ClusterHadopp_ResourceManagerScheduler");
					context.setContextType("ClusterHadopp_JobHistory", "id_String");
					context.ClusterHadopp_JobHistory = (String) context.getProperty("ClusterHadopp_JobHistory");
				}

				public void processAllContext() {
					processContext_0();
				}
			}

			new ContextProcessing().processAllContext();
		} catch (java.io.IOException ie) {
			System.err.println("Could not load context " + contextStr);
			ie.printStackTrace();
		}

		// get context value from parent directly
		if (parentContextMap != null && !parentContextMap.isEmpty()) {
			if (parentContextMap.containsKey("INPUT_PATH")) {
				context.INPUT_PATH = (String) parentContextMap.get("INPUT_PATH");
			}
			if (parentContextMap.containsKey("ClusterHadopp_User")) {
				context.ClusterHadopp_User = (String) parentContextMap.get("ClusterHadopp_User");
			}
			if (parentContextMap.containsKey("ClusterHadopp_NameNodeUri")) {
				context.ClusterHadopp_NameNodeUri = (String) parentContextMap.get("ClusterHadopp_NameNodeUri");
			}
			if (parentContextMap.containsKey("ClusterHadopp_hadoopConfSpecificJar")) {
				context.ClusterHadopp_hadoopConfSpecificJar = (String) parentContextMap
						.get("ClusterHadopp_hadoopConfSpecificJar");
			}
			if (parentContextMap.containsKey("ClusterHadopp_ResourceManager")) {
				context.ClusterHadopp_ResourceManager = (String) parentContextMap.get("ClusterHadopp_ResourceManager");
			}
			if (parentContextMap.containsKey("ClusterHadopp_ResourceManagerScheduler")) {
				context.ClusterHadopp_ResourceManagerScheduler = (String) parentContextMap
						.get("ClusterHadopp_ResourceManagerScheduler");
			}
			if (parentContextMap.containsKey("ClusterHadopp_JobHistory")) {
				context.ClusterHadopp_JobHistory = (String) parentContextMap.get("ClusterHadopp_JobHistory");
			}
		}

		// Resume: init the resumeUtil
		resumeEntryMethodName = ResumeUtil.getResumeEntryMethodName(resuming_checkpoint_path);
		resumeUtil = new ResumeUtil(resuming_logs_dir_path, isChildJob, rootPid);
		resumeUtil.initCommonInfo(pid, rootPid, fatherPid, projectName, jobName, contextStr, jobVersion);

		List<String> parametersToEncrypt = new java.util.ArrayList<String>();
		// Resume: jobStart
		resumeUtil.addLog("JOB_STARTED", "JOB:" + jobName, parent_part_launcher, Thread.currentThread().getId() + "",
				"", "", "", "", resumeUtil.convertToJsonText(context, parametersToEncrypt));

		if (execStat) {
			try {
				runStat.openSocket(!isChildJob);
				runStat.setAllPID(rootPid, fatherPid, pid, jobName);
				runStat.startThreadStat(clientHost, portStats);
				runStat.updateStatOnJob(RunStat.JOBSTART, fatherNode);
			} catch (java.io.IOException ioException) {
				ioException.printStackTrace();
			}
		}

		java.util.concurrent.ConcurrentHashMap<Object, Object> concurrentHashMap = new java.util.concurrent.ConcurrentHashMap<Object, Object>();
		globalMap.put("concurrentHashMap", concurrentHashMap);

		long startUsedMemory = Runtime.getRuntime().totalMemory() - Runtime.getRuntime().freeMemory();
		long endUsedMemory = 0;
		long end = 0;

		startTime = System.currentTimeMillis();

		System.err.println("Only one hadoop configuration is allowed in one job!");

		try {
			errorCode = null;
			tHadoopConfManager_tHDFSOutput_1Process(globalMap);
			if (!"failure".equals(status)) {
				status = "end";
			}
		} catch (TalendException e_tHadoopConfManager_tHDFSOutput_1) {
			globalMap.put("tHadoopConfManager_tHDFSOutput_1_SUBPROCESS_STATE", -1);

			e_tHadoopConfManager_tHDFSOutput_1.printStackTrace();

		}

		try {
			errorCode = null;
			Implicit_Context_RegexProcess(globalMap);
			if (!"failure".equals(status)) {
				status = "end";
			}
		} catch (TalendException e_Implicit_Context_Regex) {
			globalMap.put("Implicit_Context_Regex_SUBPROCESS_STATE", -1);

			e_Implicit_Context_Regex.printStackTrace();

		}

		this.globalResumeTicket = true;// to run tPreJob

		this.globalResumeTicket = false;// to run others jobs

		try {
			errorCode = null;
			tFileInputDelimited_1Process(globalMap);
			if (!"failure".equals(status)) {
				status = "end";
			}
		} catch (TalendException e_tFileInputDelimited_1) {
			globalMap.put("tFileInputDelimited_1_SUBPROCESS_STATE", -1);

			e_tFileInputDelimited_1.printStackTrace();

		}

		this.globalResumeTicket = true;// to run tPostJob

		end = System.currentTimeMillis();

		if (watch) {
			System.out.println((end - startTime) + " milliseconds");
		}

		endUsedMemory = Runtime.getRuntime().totalMemory() - Runtime.getRuntime().freeMemory();
		if (false) {
			System.out
					.println((endUsedMemory - startUsedMemory) + " bytes memory increase when running : fact_deceases");
		}

		if (execStat) {
			runStat.updateStatOnJob(RunStat.JOBEND, fatherNode);
			runStat.stopThreadStat();
		}
		int returnCode = 0;
		if (errorCode == null) {
			returnCode = status != null && status.equals("failure") ? 1 : 0;
		} else {
			returnCode = errorCode.intValue();
		}
		resumeUtil.addLog("JOB_ENDED", "JOB:" + jobName, parent_part_launcher, Thread.currentThread().getId() + "", "",
				"" + returnCode, "", "", "");

		return returnCode;

	}

	// only for OSGi env
	public void destroy() {

	}

	private java.util.Map<String, Object> getSharedConnections4REST() {
		java.util.Map<String, Object> connections = new java.util.HashMap<String, Object>();

		return connections;
	}

	private void evalParam(String arg) {
		if (arg.startsWith("--resuming_logs_dir_path")) {
			resuming_logs_dir_path = arg.substring(25);
		} else if (arg.startsWith("--resuming_checkpoint_path")) {
			resuming_checkpoint_path = arg.substring(27);
		} else if (arg.startsWith("--parent_part_launcher")) {
			parent_part_launcher = arg.substring(23);
		} else if (arg.startsWith("--watch")) {
			watch = true;
		} else if (arg.startsWith("--stat_port=")) {
			String portStatsStr = arg.substring(12);
			if (portStatsStr != null && !portStatsStr.equals("null")) {
				portStats = Integer.parseInt(portStatsStr);
			}
		} else if (arg.startsWith("--trace_port=")) {
			portTraces = Integer.parseInt(arg.substring(13));
		} else if (arg.startsWith("--client_host=")) {
			clientHost = arg.substring(14);
		} else if (arg.startsWith("--context=")) {
			contextStr = arg.substring(10);
			isDefaultContext = false;
		} else if (arg.startsWith("--father_pid=")) {
			fatherPid = arg.substring(13);
		} else if (arg.startsWith("--root_pid=")) {
			rootPid = arg.substring(11);
		} else if (arg.startsWith("--father_node=")) {
			fatherNode = arg.substring(14);
		} else if (arg.startsWith("--pid=")) {
			pid = arg.substring(6);
		} else if (arg.startsWith("--context_type")) {
			String keyValue = arg.substring(15);
			int index = -1;
			if (keyValue != null && (index = keyValue.indexOf('=')) > -1) {
				if (fatherPid == null) {
					context_param.setContextType(keyValue.substring(0, index),
							replaceEscapeChars(keyValue.substring(index + 1)));
				} else { // the subjob won't escape the especial chars
					context_param.setContextType(keyValue.substring(0, index), keyValue.substring(index + 1));
				}

			}

		} else if (arg.startsWith("--context_param")) {
			String keyValue = arg.substring(16);
			int index = -1;
			if (keyValue != null && (index = keyValue.indexOf('=')) > -1) {
				if (fatherPid == null) {
					context_param.put(keyValue.substring(0, index), replaceEscapeChars(keyValue.substring(index + 1)));
				} else { // the subjob won't escape the especial chars
					context_param.put(keyValue.substring(0, index), keyValue.substring(index + 1));
				}
			}
		} else if (arg.startsWith("--log4jLevel=")) {
			log4jLevel = arg.substring(13);
		} else if (arg.startsWith("--monitoring") && arg.contains("=")) {// for trunjob call
			final int equal = arg.indexOf('=');
			final String key = arg.substring("--".length(), equal);
			System.setProperty(key, arg.substring(equal + 1));
		}
	}

	private static final String NULL_VALUE_EXPRESSION_IN_COMMAND_STRING_FOR_CHILD_JOB_ONLY = "<TALEND_NULL>";

	private final String[][] escapeChars = { { "\\\\", "\\" }, { "\\n", "\n" }, { "\\'", "\'" }, { "\\r", "\r" },
			{ "\\f", "\f" }, { "\\b", "\b" }, { "\\t", "\t" } };

	private String replaceEscapeChars(String keyValue) {

		if (keyValue == null || ("").equals(keyValue.trim())) {
			return keyValue;
		}

		StringBuilder result = new StringBuilder();
		int currIndex = 0;
		while (currIndex < keyValue.length()) {
			int index = -1;
			// judege if the left string includes escape chars
			for (String[] strArray : escapeChars) {
				index = keyValue.indexOf(strArray[0], currIndex);
				if (index >= 0) {

					result.append(keyValue.substring(currIndex, index + strArray[0].length()).replace(strArray[0],
							strArray[1]));
					currIndex = index + strArray[0].length();
					break;
				}
			}
			// if the left string doesn't include escape chars, append the left into the
			// result
			if (index < 0) {
				result.append(keyValue.substring(currIndex));
				currIndex = currIndex + keyValue.length();
			}
		}

		return result.toString();
	}

	public Integer getErrorCode() {
		return errorCode;
	}

	public String getStatus() {
		return status;
	}

	ResumeUtil resumeUtil = null;
}
/************************************************************************************************
 * 159348 characters generated by Talend Open Studio for Big Data on the 30
 * octobre 2025 14:45:36 CET
 ************************************************************************************************/